---
title: "Fire_Analysis"
author: "Alex Honeyman"
date: "12/15/2020"
output: html_document
---

#########################################################################################
################################                        #################################
################################       ANALYSIS         #################################
################################                        #################################
#########################################################################################

#### Instructions ####
#You will need to manually run the two code chunks below.
#1) Change the file path to the main data folder that you downloaded.
#2) If you have not already done so, install all of the needed packages with the provided code. This code chunk is commented so that it does not run automatically. Follow the instructions to uncomment + run it, and then RE-COMMENT the chunk.
#The pipeline is now ready to run, hands off, by clicking "Session" in the RStudio menu bar, and then clicking "Restart R and Clear Output", and then click "Run All" in the "Run" dropdown menu at the top of the RNotebook. One should use the "caffeinate" command in Mac Terminal to prevent the computer from sleeping if the user will be away while the code runs for ~ 1 hour (on a 2018 MacBook Pro). If one gets an error that they are out of vector space / memory, then their computer does not have enough RAM to run this pipeline.
#Special Case (a possible edit to make depending on your R version): After following the above instructions, if when you 'Run All' you get an error saying that "X1" is not a real variable during model generation, there are a few small changes you will need to manually make (for some dependencies in R, the default new column name is s1 instead of X1): After line 1819, change all instances of "X1" to "s1" (there are about a dozen, and one can search for them with 'Command + f'). DO NOT change "X1" to "s1" in any lines above line 1819. Save the RMarkdown, and then Run All code again.
#R Package versions: A record of all package versions used for our manuscript is below the chunk in this notebook where libraries are loaded.

#CHANGE THIS: Set whatever your file path is to the main data folder 'Honeyman_2022_SLfire'; your folder destination below will be 'Honeyman_2022_SLfire' instead of 'fire_1_051421_2'.
```{r}

#Wherever you downloaded the main data folder for this manuscript, enter that file path here so that the code can execute automatically.
path_to_data <- "/Users/alexhoneyman/Documents/MICROBES_ARE_HUNGRY/Data and Code for Projects/fire_1_051421_2"

```

#IF NEEDED, install packages: Uncomment everything in this code chunk (select all, and then press 'Shift + command + c') and then run the code chunk. Be sure to recomment this chunk once you have installed everything.
### Comments for installations ###: 1) You do not need to restart R prior to updating the loaded packages (click 'No'); 2) When asked to update all / some / none of the CRAN dependencies, type 'a' and then hit ENTER to select 'all'; 3) If asked to install packages that need compilation from CRAN, enter 'no' (the binary will be used instead); 4) When installing the GitHub package and you are asked about updating packages, enter the option for CRAN-only; 5) Say "Yes" to downgrading packages to the Bioconductor 3.11 version (this is a stable version for dada2), and then say "No / none" to updating packages that have a more recent version than what is in Bioconductor 3.11.
```{r}
# #This line will install CRAN repository packages. Follow instructions above this chunk.
# install.packages(c("ggplot2", "tidyverse", "cowplot", "plotmo", "xtable", "ggridges", "viridis", "hrbrthemes", "gt", "gtsummary", "r2rtf", "glmnet", "car", "RColorBrewer", "wesanderson", "DT", "data.table", "svglite", "vegan", "picante", "gridExtra", "heatmaply"))
# 
# #Installing GitHub packages. Follow instructions above this chunk.
# install.packages("remotes")
# remotes::install_github("MadsAlbertsen/ampvis2")
# 
# #Installing Bioconductor packages. Follow instructions above this chunk.
# BiocManager::install(version = "3.11")
# BiocManager::install("phyloseq")
# BiocManager::install("dada2")
# BiocManager::install("Biostrings")
# BiocManager::install("DESeq2")
# BiocManager::install("decontam")
# BiocManager::install("microbiome")

```

#Time the running of the entire workbook; at the end of the workbook, one can see how long it took to run the pipeline.
```{r}

full_pipe_start <- Sys.time()

```

#Loading necessary libraries.
```{r, message=FALSE, warning=FALSE, include=FALSE}
library(ggplot2); packageVersion("ggplot2")
library(phyloseq); packageVersion("phyloseq")
library(dada2); packageVersion("dada2")
library(tidyverse); packageVersion("tidyverse") #Note that we removed the loading of individual tidyverse packages (like tidyr). Loading the entire conglomerate of tidyverse packages at once gets the right dependencies loaded.
library(Biostrings); packageVersion("Biostrings")
library(ampvis2); packageVersion("ampvis2")
library("DESeq2"); packageVersion("DESeq2")
library("cowplot"); packageVersion("cowplot")
library(plotmo); packageVersion("plotmo")
library(xtable); packageVersion("xtable")
library(ggridges); packageVersion("ggridges")
library(viridis); packageVersion("viridis")
library(hrbrthemes); packageVersion("hrbrthemes")
library(decontam); packageVersion("decontam")
library(gt); packageVersion("gt")
library(gtsummary); packageVersion("gtsummary")
library(r2rtf); packageVersion("r2rtf")
library(glmnet); packageVersion("glmnet")
library(car); packageVersion("car")
library("microbiome"); packageVersion("microbiome")
library("RColorBrewer"); packageVersion("RColorBrewer")
library("wesanderson"); packageVersion("wesanderson")
library("DT"); packageVersion("DT")
library("data.table"); packageVersion("data.table")
library("svglite"); packageVersion("svglite")
library("vegan"); packageVersion("vegan")
library("grid"); packageVersion("grid")
library("picante"); packageVersion("picante")
library("gridExtra"); packageVersion("gridExtra")
library(heatmaply); packageVersion("heatmaply")

### Below is a record of the R and R Studio versions used in our publication ###
# R version 4.0.5 (2021-03-31) -- "Shake and Throw"
# Copyright (C) 2021 The R Foundation for Statistical Computing
# Platform: x86_64-apple-darwin17.0 (64-bit)
# RStudio Version 1.4.1106
# © 2009-2021 RStudio, PBC
# "Tiger Daylily" (2389bc24, 2021-02-11) for macOS
# Mozilla/5.0 (Macintosh; Intel Mac OS X 10_16_0) AppleWebKit/537.36 (KHTML, like Gecko) QtWebEngine/5.12.8 Chrome/69.0.3497.128 Safari/537.36

### Below is a record package versions used in our publication ###
# > library(ggplot2); packageVersion("ggplot2")
# [1] ‘3.3.3’
# > library(phyloseq); packageVersion("phyloseq")
# [1] ‘1.32.0’
# > library(dada2); packageVersion("dada2")
# [1] ‘1.16.0’
# > library(tidyverse); packageVersion("tidyverse") #Note that we removed the loading of individual tidyverse packages (like tidyr). Loading the entire conglomerate of tidyverse packages at once gets the right dependencies loaded.
# [1] ‘1.3.1’
# > library(Biostrings); packageVersion("Biostrings")
# [1] ‘2.56.0’
# > library(ampvis2); packageVersion("ampvis2")
# [1] ‘2.6.5’
# > library("DESeq2"); packageVersion("DESeq2")
# [1] ‘1.28.1’
# > library("cowplot"); packageVersion("cowplot")
# [1] ‘1.1.1’
# > library(plotmo); packageVersion("plotmo")
# [1] ‘3.6.0’
# > library(xtable); packageVersion("xtable")
# [1] ‘1.8.4’
# > library(ggridges); packageVersion("ggridges")
# [1] ‘0.5.3’
# > library(viridis); packageVersion("viridis")
# [1] ‘0.6.0’
# > library(hrbrthemes); packageVersion("hrbrthemes")
# [1] ‘0.8.0’
# > library(decontam); packageVersion("decontam")
# [1] ‘1.8.0’
# > library(ggridges); packageVersion("ggridges")
# [1] ‘0.5.3’
# > library(gt); packageVersion("gt")
# [1] ‘0.2.2’
# > library(gtsummary); packageVersion("gtsummary")
# [1] ‘1.4.0’
# > library(r2rtf); packageVersion("r2rtf")
# [1] ‘0.2.0’
# > library(glmnet); packageVersion("glmnet")
# [1] ‘4.1.1’
# > library(car); packageVersion("car")
# [1] ‘3.0.10’
# > library(cowplot); packageVersion("cowplot")
# [1] ‘1.1.1’
# > library("microbiome"); packageVersion("microbiome")
# [1] ‘1.10.0’
# > library("RColorBrewer"); packageVersion("RColorBrewer")
# [1] ‘1.1.2’
# > library("wesanderson"); packageVersion("wesanderson")
# [1] ‘0.3.6’
# > library("DT"); packageVersion("DT")
# [1] ‘0.18’
# > library("data.table"); packageVersion("data.table")
# [1] ‘1.14.0’
# > library("svglite"); packageVersion("svglite")
# [1] ‘2.0.0’
# > library("vegan"); packageVersion("vegan")
# [1] ‘2.5.7’
# > library("grid"); packageVersion("grid")
# [1] ‘4.0.5’
# > library("picante"); packageVersion("picante")
# [1] ‘1.8.2’
# > library("gridExtra"); packageVersion("gridExtra")
# [1] ‘2.3’
# > library(heatmaply); packageVersion("heatmaply")
# [1] ‘1.2.1’
```

#################################################################################################
### Reading in BA and EUKS ps objects, and merging them into one final, composite, ps object  ###
#################################################################################################

#Read in the BA and EUKS ps objects.
```{r}

fire_ps_BA <- readRDS(paste0(path_to_data,"/Final_phyloseq/fire_ps_BA.rds"))

#Here, we import the phyloseq object where paired-end reads were merged via the justConcatenate = TRUE argument in mergePairs(). This is necessary to call taxonomy on eukaryotes.
fire_ps_EUKS <- readRDS(paste0(path_to_data,"/Final_phyloseq/fire_ps_EUKS.rds"))

```

#Excluding ASVs and eASVs (Eukaryotic ASVs) by taxonomy (so that individual objects, by domain, can be made), and then merging the two different phyloseq objects into one composite phyloseq object named 'fire_ps' which is to be used in all downstream analyses.
#Note that the objective here is to use the '_BA' ps object for bacterial / archaeal taxonomy calls and the '_EUKS' ps object for eukaryotic taxonomy calls.
#We will also remove sequenced samples from the dataset that were part of a dilution series to optimize PCR reactions.
```{r}
#Remove Eukaryotes from the Bacteria / Archaea (BA) phyloseq object.
fire_ps_BA_sub = subset_taxa(fire_ps_BA, Kingdom!="Eukaryota")
#Remove Bacteria and Archaea from the Eukaryota (EUKS) phyloseq object.
fire_ps_EUKS_sub = subset_taxa(fire_ps_EUKS, Kingdom=="Eukaryota")

#Merging the BA and EUKS ps objects into one composite ps object.
fire_ps <- merge_phyloseq(fire_ps_BA_sub, fire_ps_EUKS_sub)

## Removing chloroplasts and mitochondria. ##
#Special Note** The subset_taxa() function, in addition to tossing out all that you have included inside the '!=' operator, the function will remove all NA classifications at that particular taxonomic rank. This is why unless you also include '| (is.na(Order))', or similar, tens of thousands of reads will be thrown out because they were NA taxonomy at that particular rank. So, if one is suddenly losing tens of thousands of reads after a simple subset of one taxonomic rank-- that should be a red flag that this is occurring. Below, we have verified that the new ps objects that we generate indeed removed the desired taxa, but also retain all NA reads at those particular taxonomic ranks.
fire_ps_NoChlor <- subset_taxa(fire_ps, ((Order!="Chloroplast") | (is.na(Order))))
fire_ps_NoChlorMito <- subset_taxa(fire_ps_NoChlor, ((Family!="Mitochondria") | (is.na(Family))))
fire_ps <- fire_ps_NoChlorMito #Copying over the subsetted ps object into the original name so that it can propagate into code below.

#COMMENTS# ON THE FINAL TAXONOMY:
#Eukaryota are indeed classified by the Silva database via the dada2 taxonomy assignment algorithm (https://github.com/benjjneb/dada2/issues/366). However, none of our eASVs have taxonomy beyond kingdom (domain). This may be due to low confidence after bootstrapping, or possibly the reverse-complement needs to be taken (see link). Nonetheless, when we blasted an example eASV we indeed got eukaryotic hits with % matches down to the species level. We will need to consider more deeply what these hits actually mean for fungal taxonomy, and how BLAST handles 'N' nucleotides which were introduced with the justConcatenate = TRUE argument in the mergePairs() function for the EUKS objects. Also, reference the classifier paper that was implemented for the assignTaxonomy() function in dada2 (https://aem.asm.org/content/73/16/5261.short).

#Here, we remove a few samples from the total dataframe that were dilution experiments of the same sample (and hence are redundant). Note that the below three samples were one of the lines of evidence that sufficient sequencing depth can be obtained by diluting out PCR inhibitors prior to PCR.
fire_ps <- subset_samples(fire_ps, ((sam_name != "H1_D1_R3_1") & (sam_name != "H1_D1_R3_2") & (sam_name != "H2_D1_R3_2") & (sam_name != "H2_D1_R3_3"))) #Note that we retain "H1_D1_R3_3" and "H2_D1_R3_1" because these samples had the deepest sequencing of the 3 dilutions tried for each of the two samples.

#For each of "H1_D1_R3" and "H2_D1_R3" samples, three dilutions of input DNA were tried (No dilution, 1:10, and 1:100). For the dilution series on both samples, "_1" appended to the sample name indicates no dilution, "_2" indicates 1:10, and "_3" indicates 1:100.

```

#Merging geochemistry data as metadata within the fire phyloseq object.
```{r}
#First, use the environment tab in R Studio to import the geochemistry dataset in Excel format. Check the box to use the first row as names. Note that the version that we import had some header note rows trimmed from the top of the spreadsheet such that the first row is now the variable names.
#VERSION NOTE: On 3/17/21, the NEW_SBS classifications for each plot (determined via Zoom call looking at photos w/ Chuck) were copied over to the Honeyman_SoilLeachate_012921_modifiedForR_import Excel file; the 'field_SBS' data was replaced with the new, final, SBS classifications (the variable is still called 'field_SBS'). That Excel file was saved, re-imported to R, and then the commented two lines of code immediately below were run. This updated the geochem_raw.RDS file on the computer such that when the full code pipeline is run, the metadata file with the new, final, SBS classifications is the one that is imported as a .RDS file and then used. The new / final SBS variable will propagate through the rest of the pipeline.

#Store the imported geochemistry file into a new, shorter, name.
#geochem_raw <- Honeyman_SoilLeachate_012921_modifiedForR_import #Uncomment this line if you import the Excel file instead of auto-importing the file as a .RDS (see 2 lines down).
#saveRDS(geochem_raw, file = paste0(path_to_data,"/Metadata/Geochemistry/fromR/geochem_raw.RDS")) #If modifications are made to the imported file before this line, then uncomment here and re-save the file as a .RDS for easier import at a later time.
geochem_raw <- readRDS(file = paste0(path_to_data,"/Metadata/Geochemistry/fromR/geochem_raw.RDS")) #Read in a raw geochemistry file that was saved as a .RDS to the computer.
#**NOTE** The line of code below is necessary because the field_SBS data were updated with conversations with Chuck; need to propagate these changes to the Gross_group_type which depends on SBS. Since the Gross_group_type was a variable addition for ease of use during bio analyses, we can directly copy field_SBS over for these geochem data since there are no biological controls, etc., that would alter text transforming from one variable to the other.
geochem_raw$Gross_group_type <- geochem_raw$field_SBS
geochem_raw_skinny <- geochem_raw[,19:60] #Only taking the actual measurement values from the dataframe.
geochem_raw_skinny$sam_name <- geochem_raw$Sample #Creating a sample name variable that has the same colname as sample names in phyloseq objects (need to do this so that we can merge dataframes later). Note that the sample name was trimmed out in the line above, so it's also good for this reason that we add it back in.
geochem_raw <- geochem_raw_skinny #Copying over to the first variable name that we used so that it can propogate into code below.

#Fixing up the variable names.
colnames(geochem_raw) <- gsub("\\...*","",colnames(geochem_raw)) #Removing some extra characters that arose due to importing from Excel columns that have drop-down menus. Note that periods mean 'any character' and we have to use the escape command (\\) for gsub() to recognize that we mean a literal period and not the period command.

#Making a dataframe that is a copy of the sample_data from the phyloseq object; we will merge on this dataframe before updating the phyloseq object with said merged sample_data dataframe.
temp_sam_df <- data.frame(sample_data(fire_ps))
temp_sam_df$full_sam_name <- temp_sam_df$sam_name #Saving the original, full, sample name into another variable so that we can restore the row.names later (merging will eliminate row.names).
temp_sam_df$sam_name <- gsub("_R._", "_", temp_sam_df$sam_name) #Removing any RX parts of samples names (R1, R2, R3).
temp_sam_df$sam_name <- gsub("_R.", "", temp_sam_df$sam_name) #We have to run a similar command as the line of code directly above to handle cases where the replicate number was at the end of the sample name (instead of in the middle somewhere).
temp_sam_df$sam_name <- gsub("H1_D1_3", "H1_D1", temp_sam_df$sam_name) #Removing the dilution series indicator from this sample.
temp_sam_df$sam_name <- gsub("H2_D1_1", "H2_D1", temp_sam_df$sam_name) #Removing the dilution series indicator from this sample.

#Merging the sample_data from the phyloseq object with the geochemsitry df that we prepared in this code chunk. Note that left_join() means that we are using the first argument as the template df; all samples from the template df are included in the final df. Further, the merged df will have redundant geochemistry measurements across R1, R2, and R3 microbiome replicates (this was intended!); we do this because individual microbiome samples are an example 'drawn' from the composite soil sample that we determined geochemsitry from.
joined_meta_df <- left_join(temp_sam_df, geochem_raw, by = "sam_name")
row.names(joined_meta_df) <- joined_meta_df$full_sam_name

#Updating the phyloseq object with the merged metadata-geochemistry sample_data df.
sample_data(fire_ps) <- sample_data(joined_meta_df)

#Saving the final, composite, geochem-included ps object.
#saveRDS(fire_ps, paste0(path_to_data,"/Final_phyloseq/fire_ps.rds")) #We comment this line since the ps object is already generated and saved. If any changes are made, then un-comment this line to re-save the ps object at generation. This line of code was re-run on 4/14/21, ensuring that the fire_ps object saved to the computer is indeed the one with updated field_SBS metadata after talking with Chuck. Note that the pipeline was already using the correct, new, field_SBS data due to importing updated geochemistry data earlier in the pipeline, but here was just copy fire_ps (now updated) to the computer in case we want to import that ps object directly for some future use.

```


##########################################################
### Reading in the final Phyloseq object  ################
##########################################################

#Read in the final, composite, phyloseq object for all downstream data analysis.
```{r}

#We comment the below line since the final ps object ('fire_ps') is generated at the top of this pipeline. If for some reason we want to just load the already-generated final ps object from the computer, then use the code line below.
#fire_ps <- readRDS(paste0(path_to_data,"/Final_phyloseq/fire_ps.rds"))

```

##########################################################################
### Subsetting phyloseq objects by fire and time series time point #######
##########################################################################

#Subsetting the total fire dataset into different fires and different time points. Downstream, this is helpful for running different decontamination parameters depending on sequencing run, sampling campaign, etc. Note that after subsetting samples by the 'fire' and 'time_point' variables, one still needs to prune any ASVs AND Samples with 0 reads; code to do so is implemented here for each subset phyloseq object; i.e., the '_no0s' phyloseq object at the end of each code paragraph is what should be used down-pipeline.
```{r}

##########################
#### All Fire Samples ####
##########################

#Making a ps subset that is all fire samples.
fire_all <- fire_ps
#We need to remove any ASVs with 0 counts and any samples with 0 counts before running the algorithm. This needs to be done anytime there is subsetting of data since phyloseq will not remove variables that no longer occur in the data once we subset.
#We need to prune any ASVs that have 0 reads since they are not helpful to the statistical model (these 0 ASVs are only here because sample subsetting with phyloseq does not remove ASVs that are no longer present in any of the subset samples).
fire_all_no0s <- filter_taxa(fire_all, function(x) sum(x) > 0, prune = TRUE)
#We also need to remove any samples that had 0 sequences returned (this is generally a sane thing to do).
fire_all_no0s = prune_samples(sample_sums(fire_all_no0s)>0, fire_all_no0s)

##########################
## Decker Fire Samples ###
##########################

#Making a ps subset that is only the Decker Fire (all timepoints).
Decker_AllTimes <- subset_samples(fire_ps, fire == "Decker Fire")
#We need to remove any ASVs with 0 counts and any samples with 0 counts before running the algorithm. This needs to be done anytime there is subsetting of data since phyloseq will not remove variables that no longer occur in the data once we subset.
#We need to prune any ASVs that have 0 reads since they are not helpful to the statistical model (these 0 ASVs are only here becuase sample subsetting with phyloseq does not remove ASVs that are no longer present in any of the subset samples).
Decker_AllTimes_no0s <- filter_taxa(Decker_AllTimes, function(x) sum(x) > 0, prune = TRUE)
#We also need to remove any samples that had 0 sequences returned (this is generally a sane thing to do).
Decker_AllTimes_no0s = prune_samples(sample_sums(Decker_AllTimes_no0s)>0, Decker_AllTimes_no0s)

#Making a ps subset that is only the Decker Fire at timepoint 1.
Decker1 <- subset_samples(fire_ps, fire == "Decker Fire" & time_point == 1)
#We need to remove any ASVs with 0 counts and any samples with 0 counts before running the algorithm. This needs to be done anytime there is subsetting of data since phyloseq will not remove variables that no longer occur in the data once we subset.
#We need to prune any ASVs that have 0 reads since they are not helpful to the statistical model (these 0 ASVs are only here becuase sample subsetting with phyloseq does not remove ASVs that are no longer present in any of the subset samples).
Decker1_no0s <- filter_taxa(Decker1, function(x) sum(x) > 0, prune = TRUE)
#We also need to remove any samples that had 0 sequences returned (this is generally a sane thing to do).
Decker1_no0s = prune_samples(sample_sums(Decker1_no0s)>0, Decker1_no0s)

#Making a ps subset that is only the Decker Fire at timepoint 2.
Decker2 <- subset_samples(fire_ps, fire == "Decker Fire" & time_point == 2)
#We need to remove any ASVs with 0 counts and any samples with 0 counts before running the algorithm. This needs to be done anytime there is subsetting of data since phyloseq will not remove variables that no longer occur in the data once we subset.
#We need to prune any ASVs that have 0 reads since they are not helpful to the statistical model (these 0 ASVs are only here becuase sample subsetting with phyloseq does not remove ASVs that are no longer present in any of the subset samples).
Decker2_no0s <- filter_taxa(Decker2, function(x) sum(x) > 0, prune = TRUE)
#We also need to remove any samples that had 0 sequences returned (this is generally a sane thing to do).
Decker2_no0s = prune_samples(sample_sums(Decker2_no0s)>0, Decker2_no0s)

#Making a ps subset that is only the Decker Fire at timepoint 3.
Decker3 <- subset_samples(fire_ps, fire == "Decker Fire" & time_point == 3)
#We need to remove any ASVs with 0 counts and any samples with 0 counts before running the algorithm. This needs to be done anytime there is subsetting of data since phyloseq will not remove variables that no longer occur in the data once we subset.
#We need to prune any ASVs that have 0 reads since they are not helpful to the statistical model (these 0 ASVs are only here becuase sample subsetting with phyloseq does not remove ASVs that are no longer present in any of the subset samples).
Decker3_no0s <- filter_taxa(Decker3, function(x) sum(x) > 0, prune = TRUE)
#We also need to remove any samples that had 0 sequences returned (this is generally a sane thing to do).
Decker3_no0s = prune_samples(sample_sums(Decker3_no0s)>0, Decker3_no0s)

##########################
#### 416 Fire Samples ####
##########################

#Making a ps subset that is only the 416 Fire (all timepoints).
F416_AllTimes <- subset_samples(fire_ps, fire == "416 Fire")
#We need to remove any ASVs with 0 counts and any samples with 0 counts before running the algorithm. This needs to be done anytime there is subsetting of data since phyloseq will not remove variables that no longer occur in the data once we subset.
#We need to prune any ASVs that have 0 reads since they are not helpful to the statistical model (these 0 ASVs are only here becuase sample subsetting with phyloseq does not remove ASVs that are no longer present in any of the subset samples).
F416_AllTimes_no0s <- filter_taxa(F416_AllTimes, function(x) sum(x) > 0, prune = TRUE)
#We also need to remove any samples that had 0 sequences returned (this is generally a sane thing to do).
F416_AllTimes_no0s = prune_samples(sample_sums(F416_AllTimes_no0s)>0, F416_AllTimes_no0s)

#Making a ps subset that is only the 416 Fire at timepoint 1.
F416_1 <- subset_samples(fire_ps, fire == "416 Fire" & time_point == 1)
#We need to remove any ASVs with 0 counts and any samples with 0 counts before running the algorithm. This needs to be done anytime there is subsetting of data since phyloseq will not remove variables that no longer occur in the data once we subset.
#We need to prune any ASVs that have 0 reads since they are not helpful to the statistical model (these 0 ASVs are only here becuase sample subsetting with phyloseq does not remove ASVs that are no longer present in any of the subset samples).
F416_1_no0s <- filter_taxa(F416_1, function(x) sum(x) > 0, prune = TRUE)
#We also need to remove any samples that had 0 sequences returned (this is generally a sane thing to do).
F416_1_no0s = prune_samples(sample_sums(F416_1_no0s)>0, F416_1_no0s)

#Making a ps subset that is only the 416 Fire at timepoint 2.
F416_2 <- subset_samples(fire_ps, fire == "416 Fire" & time_point == 2)
#We need to remove any ASVs with 0 counts and any samples with 0 counts before running the algorithm. This needs to be done anytime there is subsetting of data since phyloseq will not remove variables that no longer occur in the data once we subset.
#We need to prune any ASVs that have 0 reads since they are not helpful to the statistical model (these 0 ASVs are only here becuase sample subsetting with phyloseq does not remove ASVs that are no longer present in any of the subset samples).
F416_2_no0s <- filter_taxa(F416_2, function(x) sum(x) > 0, prune = TRUE)
#We also need to remove any samples that had 0 sequences returned (this is generally a sane thing to do).
F416_2_no0s = prune_samples(sample_sums(F416_2_no0s)>0, F416_2_no0s)

#Making a ps subset that is only the 416 Fire at timepoint 3.
F416_3 <- subset_samples(fire_ps, fire == "416 Fire" & time_point == 3)
#We need to remove any ASVs with 0 counts and any samples with 0 counts before running the algorithm. This needs to be done anytime there is subsetting of data since phyloseq will not remove variables that no longer occur in the data once we subset.
#We need to prune any ASVs that have 0 reads since they are not helpful to the statistical model (these 0 ASVs are only here becuase sample subsetting with phyloseq does not remove ASVs that are no longer present in any of the subset samples).
F416_3_no0s <- filter_taxa(F416_3, function(x) sum(x) > 0, prune = TRUE)
#We also need to remove any samples that had 0 sequences returned (this is generally a sane thing to do).
F416_3_no0s = prune_samples(sample_sums(F416_3_no0s)>0, F416_3_no0s)

```


###############################################################################################
##### Investigating, Identifying and Removing Contaminating Reads (Decontamination) ###########
###############################################################################################

#Plotting recovered reads from sequencing as a function of negative control vs. not negative control (here, positive PCR controls are indicated as 'Samples').
```{r}
plotReads <- function(ps, control_var){
  #Parameters:
    #ps (ps object) <- the phyloseq object that you wish to plot.
    #control_var (str) <- the variable name in the sample metadata of the ps object that denotes whether a sample is a true sample or a negative control.
  
  #Returns:
    #A plot showing the sequencing depth of all samples from the ps object, color-coded by whether or not it is a negative control.

  library(decontam); packageVersion("decontam")
  
  df <- as.data.frame(sample_data(ps)) # Put sample_data into a ggplot-friendly data.frame
  df$LibrarySize <- sample_sums(ps)
  df <- df[order(df$LibrarySize),]
  df$Index <- seq(nrow(df))
  ggplot(data=df, aes_string(x='Index', y='LibrarySize', color=control_var)) + geom_point()
}


#Thought: The number of reads that we get from sequenced controls should reflect what is 'fair' as far as what is amplified during PCR. e.g., the same volume of negative control should be pooled as the lowest concentration DNA sample. We have done this for all of the fire sequencing runs.

```

#Generating plots of sequencing depth for samples vs. controls for each fire sampling campaign.
```{r}

plotReads(Decker1_no0s, 'sample_or_NegControl')
plotReads(Decker2_no0s, 'sample_or_NegControl')
plotReads(Decker3_no0s, 'sample_or_NegControl')
plotReads(F416_1_no0s, 'sample_or_NegControl')
plotReads(F416_2_no0s, 'sample_or_NegControl')
plotReads(F416_3_no0s, 'sample_or_NegControl')

```


#Identifying contaminants via the "Prevalence Method" as defined by the decontam package.
```{r}
IDcontam <- function(ps, p_threshold){
#Parameters:
  #ps (ps object) <- the ps object from which you wish to ID contaminants.
#Comments:
  #The variable name that we will use from the sample_data() must be named 'sample_or_NegControl', and the levels of that variable must be 'Sample' and 'Control'.
#Returns:
  #prints a table of how many contaminants vs. not contaminants were found.
  #prints a graph showing the prevalence of ASVs by whether they were a contaminant or not. i.e.,  the x and y values represnt how many samples a particular ASV was observed in.
  #Prints a verification test showing that the dimensions of the returned phyloseq object are what we expect them to be.
  #Returns a phyloseq object that has been trimmed of contaminant sequences. Remember that in this code chunk, we used the approach of finding contaminant sequences such that the isContaminant variable will have a TRUE is the sequence was a contaminant and ultimately removed.
  
  #Creating a boolean indicator for negative control vs. sample
  sample_data(ps)$is.neg <- sample_data(ps)$sample_or_NegControl == "Control"
  
  #Running the model.
  contamdf.prev <- isContaminant(ps, method="prevalence", neg="is.neg", threshold = p_threshold) #consider isNOTcontaminant for HIGH severity and / or low-biomass samples. Maybe assign a read # threshold at which point we use the isNOTcontaminant function instead?
  hist(contamdf.prev$p, breaks = 20) #A histogram of the scores so that we can manually pick the P* threshold.
  axis(side=1,at=seq(0,1,0.05))
  
  #Printing a table summarizing estimated contamination numbers.
  print(table(contamdf.prev$contaminant))
  
  # Make phyloseq object of presence-absence in negative controls and true samples
  ps.pa <- transform_sample_counts(ps, function(abund) 1*(abund>0))
  ps.pa.neg <- prune_samples(sample_data(ps.pa)$sample_or_NegControl == "Control", ps.pa)
  ps.pa.pos <- prune_samples(sample_data(ps.pa)$sample_or_NegControl == "Sample", ps.pa)
  # Make data.frame of prevalence in positive and negative samples
  df.pa <- data.frame(pa.pos=taxa_sums(ps.pa.pos), pa.neg=taxa_sums(ps.pa.neg),
                        contaminant=contamdf.prev$contaminant)
  print(ggplot(data=df.pa, aes(x=pa.neg, y=pa.pos, color=contaminant)) + geom_point() +
    xlab("Prevalence (Negative Controls)") + ylab("Prevalence (True Samples + Pos Ctls)"))
  
  #A logical vector for whether or not an ASV should be retained.
  IScontam_logical <- contamdf.prev$contaminant #Here, contaminating ASVs are TRUE.
  ISNOT_contam_logical <- !IScontam_logical #Here, non-contaminating ASVs are TRUE.
  
  #Generating a 'contaminant-free' phyloseq object.
  ps_decon <- prune_taxa(ISNOT_contam_logical, ps)
  
  #Some checks to make sure things add up.
  print(dim(otu_table(ps_decon))[2] == table(ISNOT_contam_logical)[2]) #Checking that the # of 'good' ASVs matches the number of ASVs in the decon phyloseq object (it should be pruned of contaminants).
  
  return(ps_decon)
  
}


```

#As an alternative to identifying contaminants, determining what are NOT contaminants (the null hypothesis is that they are contaminants). This is good for low biomass samples; perhaps this should be conducted on High Severity plots from the Decker Fire and first collection of the 416 Fire?
```{r}

IDnotContam <- function(ps, p_threshold){
  #Parameters: 
    #ps (phyloseq object): The phyloseq object, preferably of low biomass / sequencing depth, that you want to ID what is NOT a contaminant from.
  #Comments:
    #As in the IDcontam function defined earlier in the notebook, the name of the sample_data() variable that defines samples and negative controls must be named 'sample_or_NegControl' and it must have factor levels of 'Control' and 'Sample'.
  #Returns:
    #Prints a table that defines what are NOT contaminants (TRUE values in the table).
    #Prints a graph that shows the prevalence of ASVs across samples, color coded by NOTcontaminant or contaminant. i.e., the x and y values indicate how many samples observed that ASV.
    #Prints a verification test that the dimensions of the returned phyloseq object are what we expect them to be.
    #Returns a phyloseq object that has had the contaminating sequences removed. Remember that in this code, we have used the appraoch of identifying NOTcontaminants, and then removing those ASVs that do not have a TRUE value for the NOTcontaminant variable.

  library(decontam); packageVersion("decontam")
  
  #Creating a boolean indicator for negative control vs. sample
  sample_data(ps)$is.neg <- sample_data(ps)$sample_or_NegControl == "Control"
  
  #Running the model 
  NOTcontamdf.prev <- isNotContaminant(otu_table(ps), sample_data(ps)$is.neg, threshold = p_threshold)
  
  #Printing a table summarizing estimated NOTcontamination numbers.
  print(table(NOTcontamdf.prev))
  
  #Alternative chunk to the chunk below. Here, we also plot contaminant vs. not contaminant, but we have to make some changes since in the preceeding code chunk NOTcontaminants were identified instead of contaminants.
  
  # Make phyloseq object of presence-absence in negative controls and true samples
  ps.pa <- transform_sample_counts(ps, function(abund) 1*(abund>0))
  ps.pa.neg <- prune_samples(sample_data(ps.pa)$sample_or_NegControl == "Control", ps.pa)
  ps.pa.pos <- prune_samples(sample_data(ps.pa)$sample_or_NegControl == "Sample", ps.pa)
  # Make data.frame of prevalence in positive and negative samples
  df.pa <- data.frame(pa.pos=taxa_sums(ps.pa.pos), pa.neg=taxa_sums(ps.pa.neg),
                        NOTcontaminant=data.frame(NOTcontamdf.prev)$NOTcontamdf.prev)
  print(ggplot(data=df.pa, aes(x=pa.neg, y=pa.pos, color=NOTcontaminant)) + geom_point() +
    xlab("Prevalence (Negative Controls)") + ylab("Prevalence (True Samples + Pos Ctls)"))
  
  #Again, we write some alternative code to trim contaminants from the ps object. Here, we need to remove ASVs that have a FALSE boolean in the NOTcontaminant variable.

  #A logical vector for whether or not an ASV should be retained.
  ISNOT_contam_logical <- data.frame(NOTcontamdf.prev)$NOTcontamdf.prev #Here, non contaminants are TRUE.
  
  #Generating a 'contaminant-free' phyloseq object.
  ps_decon <- prune_taxa(ISNOT_contam_logical, ps)
  #Adding the final sequencing depth as a variable to the meta data.
  sample_data(ps_decon)$seq_depth <- sample_sums(ps_decon)
  
  #Some checks to make sure things add up.
  print(dim(otu_table(ps_decon))[2] == table(ISNOT_contam_logical)[2]) #Checking that the # of 'good' ASVs matches the number of ASVs in the decon phyloseq object (it should be pruned of contaminants).
  
  return(ps_decon)
  
}


```

#Decontamination of each run. One function call per sequencing run with associated decontamination decisions.
#REMEMBER, if parameter decisions are changed here we will need to re-examine the number of taxa that are passed into the ampvis objects since the number of unique taxa will change. This is due to the need for ampvis to be told how many taxa to 'show' in heatmaps. There should be a way to generalize the code so that we don't have to worry about this, but in the meantime remember to think about it until code is written to solve the issue.
```{r}

#If sampled within one year of burning, we choose the IDnotContam() method, and for samples taken > 1 year after burning we select the IDcontam() method. Empirically, we found with PCR that there are far more contaminants and low biomass within one year after burning.

F416_1_decon <- IDnotContam(F416_1_no0s, p_threshold = 0.5) #The default p_threshold is 0.5 in the 'isNotContaminant()' function, but we include it here as an argument anyway just to be explicit. Note that the 'isNotContaminant()' function returns a logical vector and scores are not available from which to manually determine a p_threshold; so, we will just use the default.
F416_2_decon <- IDcontam(F416_2_no0s, p_threshold = 0.5) #p_threshold was manually determined by examining a histogram of model scores.
F416_3_decon <- IDcontam(F416_3_no0s, p_threshold = 0.55) #p_threshold was manually determined by examining a histogram of model scores.
Decker1_decon <- IDnotContam(Decker1_no0s, p_threshold = 0.5) #Same comment as the first 'isNotContaminant()' call above.
Decker2_decon <- IDnotContam(Decker2_no0s, p_threshold = 0.5) #Same comment as the first 'isNotContaminant()' call above.
Decker3_decon <- IDnotContam(Decker3_no0s, p_threshold = 0.5) #Same comment as the first 'isNotContaminant()' call above.

#########
#Representative plot function for publication. Need to re-define the function so that just the plot is returned.
#########

decon_pub_fig <- function(ps, p_threshold){
  #Parameters:
      #ps (phyloseq object): The phyloseq object that one wants to decontaminate and investigate the decision boundaries between contaminants and non-contaminants.
      #p_threshold (numeric): The decision threshold value that is passed to isNotContaminant() from the Decontam package.
  
  #Returns:
      #Plot (ggplot object) of prevalences of ASVs; axes are by true samples or negatives. Classified contamination or not-contamination are color-coded.
  
  library(decontam); packageVersion("decontam")
  #Creating a boolean indicator for negative control vs. sample
  sample_data(ps)$is.neg <- sample_data(ps)$sample_or_NegControl == "Control"
  #Running the model 
  NOTcontamdf.prev <- isNotContaminant(otu_table(ps), sample_data(ps)$is.neg, threshold = p_threshold)
  #Printing a table summarizing estimated NOTcontamination numbers.
  print(table(NOTcontamdf.prev))
  #Alternative chunk to the chunk below. Here, we also plot contaminant vs. not contaminant, but we have to make some changes since in the preceeding code chunk NOTcontaminants were identified instead of contaminants.
  # Make phyloseq object of presence-absence in negative controls and true samples
  ps.pa <- transform_sample_counts(ps, function(abund) 1*(abund>0))
  ps.pa.neg <- prune_samples(sample_data(ps.pa)$sample_or_NegControl == "Control", ps.pa)
  ps.pa.pos <- prune_samples(sample_data(ps.pa)$sample_or_NegControl == "Sample", ps.pa)
  # Make data.frame of prevalence in positive and negative samples
  df.pa <- data.frame(pa.pos=taxa_sums(ps.pa.pos), pa.neg=taxa_sums(ps.pa.neg),
                        NOTcontaminant=data.frame(NOTcontamdf.prev)$NOTcontamdf.prev)
  return(ggplot(data=df.pa, aes(x=pa.neg, y=pa.pos, color=NOTcontaminant)) + geom_point(size = 3) +
    xlab("Prevalence (Negative Controls)") + ylab("Prevalence (True Samples + Pos Ctls)"))
}

#The figure object.
Decker1_decon_pub <- decon_pub_fig(Decker1_no0s, p_threshold = 0.5)
Decker1_decon_pub_mod <- Decker1_decon_pub + theme(panel.grid.major = element_blank(), 
                                                   panel.grid.minor = element_blank(),
  panel.background = element_blank(), 
  axis.line = element_line(colour = "black"), 
  strip.background = element_blank(), 
  legend.background = element_blank(), 
  legend.key = element_blank(), 
  panel.border = element_rect(color = "black", fill = NA, size = 1)) #Export size (inches): 5x7

```


#Some code to generate ridgeline plots of the seq depths of different burn severities.
```{r}

makeRidges <- function(decond_ps){
  
  #Parameters:
      #decond_ps (phyloseq object): The ps object that has already been decontaminated, and one wishes to examine the resulting sequencing depths.
  
  #Prints:
      #ggplot figures of distributions of sequencing depths, organized by sample type.

  # library
  library(ggridges)
  library(ggplot2)
   
  # Diamonds dataset is provided by R natively
  #head(diamonds)
  
  #Make the dataframe that we need.
  sample_data(decond_ps)$seq_depth <- sample_sums(decond_ps)
  ridge_df <- data.frame(Group = sample_data(decond_ps)$Gross_group_type, seq_depth = sample_data(decond_ps)$seq_depth)
  ridge_df$log10_seq_depth <- log10(ridge_df$seq_depth)
  ridge_df$log10_seq_depth[ridge_df$log10_seq_depth == -Inf] <- 0
   
  # # basic example
  # plot(ggplot(ridge_df, aes(x = log10_seq_depth, y = Group, fill = Group)) +
  #   geom_density_ridges() +
  #   theme_ridges() + 
  #   theme(legend.position = "none"))
  
  #Another set of ridgeline sequencing depth diagnostic plots.
  # library
  library(ggridges)
  library(ggplot2)
  library(viridis)
  library(hrbrthemes)
  # # Plot
  # print(ggplot(ridge_df, aes(x = log10_seq_depth, y = Group, fill = stat(x))) +
  #   geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  #   scale_fill_viridis_c(name = "seq_depth", option = "C") +
  #   labs(title = 'seq depth by sample type'))
  
  #More stuff.
  print(ggplot(ridge_df, aes(x = log10_seq_depth, y = Group, fill = Group)) +
    geom_density_ridges(
      aes(point_color = Group, point_fill = Group, point_shape = Group),
      alpha = .2, point_alpha = 1, jittered_points = TRUE
    ) +
    scale_point_color_hue(l = 40) +
    scale_discrete_manual(aesthetics = "point_shape", values = c(21, 22, 23, 24, 25, 26, 27)))
  
}


```


#Assessing the sequencing depth of decontaminated sampling campaigns.
```{r}

#One ridgeline plot per decontaminated sampling campaign.
makeRidges(F416_1_decon)
makeRidges(F416_2_decon)
makeRidges(F416_3_decon)
makeRidges(Decker1_decon)
makeRidges(Decker2_decon)
makeRidges(Decker3_decon)

##########
#Representative plot for publication.
##########

#Redefine the function to remove group types that do not exist in this particular sample (helps make clean plot without some extra rows).
makeRidges_pub <- function(decond_ps){
  
  #Parameters:
      #decond_ps (phyloseq object): The ps object that has already been decontaminated, and one wishes to examine the resulting sequencing depths.
  
  #Returns:
      #A clean ggplot object for publication.
  
  # library
  library(ggridges)
  library(ggplot2)
  #Make the dataframe that we need.
  sample_data(decond_ps)$seq_depth <- sample_sums(decond_ps)
  ridge_df <- data.frame(Group = sample_data(decond_ps)$Gross_group_type, seq_depth = sample_data(decond_ps)$seq_depth)
  ridge_df$log10_seq_depth <- log10(ridge_df$seq_depth)
  ridge_df$log10_seq_depth[ridge_df$log10_seq_depth == -Inf] <- 0
  
  ###Clean plate controls from the dataframe that clutter the plot with extra, empty, rows.
  ridge_df <- ridge_df[(ridge_df$Group != "PCR Negative") & (ridge_df$Group != "PCR Positive"),]
  
  #Another set of ridgeline sequencing depth diagnostic plots.
  # library
  library(ggridges)
  library(ggplot2)
  library(viridis)
  library(hrbrthemes)
  #More stuff.
  return(ggplot(ridge_df, aes(x = log10_seq_depth, y = Group, fill = Group)) +
    geom_density_ridges(
      aes(point_color = Group, point_fill = Group, point_shape = Group),
      alpha = .2, point_alpha = 1, jittered_points = TRUE
    ) +
    scale_point_color_hue(l = 40) +
    scale_discrete_manual(aesthetics = "point_shape", values = c(21, 22, 23, 24, 25, 26, 27)))
}

#The pub figure.
Decker1_decon_pubRidges <- makeRidges_pub(Decker1_decon) + theme(panel.grid.major = element_blank(), 
                                                   panel.grid.minor = element_blank(),
  panel.background = element_blank(), 
  axis.line = element_line(colour = "black"), 
  strip.background = element_blank(), 
  legend.background = element_blank(), 
  legend.key = element_blank(), 
  panel.border = element_rect(color = "black", fill = NA, size = 1)) #Export size (inches): 6x8

```

#Recombining all of the phyloseq objects into one large object such that we can generate one composite ampvis object.
```{r}

#Here, we combine all of the independently-decontaminated field sampling campaigns (as recommended by the authors of Decontam) into one object. We will use this single phyloseq object as the basis for all downstream analyses.
comp_ps <- merge_phyloseq(F416_1_decon, F416_2_decon, F416_3_decon, Decker1_decon, Decker2_decon, Decker3_decon)

```

#Removing all samples below a certain sequencing depth. This can be informed by the ridgeline plots that were generated earlier.
```{r}

comp_ps <- prune_samples(sample_sums(comp_ps)>0, comp_ps)

#The total dataset is 571 samples (575 - 4 dilution series samples).
#16 samples in the total dataset returned 0 sequenced reads, meaning that there are 555 viable samples (571 - 16).
#All 555 viable samples were passed into the decontamination algorithms.
#After decontamination, 542 of the 555 samples had > 0 reads (there are more reads than just contaminants in the sample).
#We retain all of the 542 decontaminated samples for downstream analyses.

#Note, one can type 'comp_ps' into the R Console, hit enter, and a summary of the phyloseq object will be printed.

```

#Breaking down the composite phyloseq object into Bacteria, Arachaea, and Eukarya subgroups for various downstream comparisons.
```{r}

comp_ps_BA <- subset_taxa(comp_ps, Kingdom!="Eukaryota")
comp_ps_Euks <- subset_taxa(comp_ps, Kingdom=="Eukaryota")
comp_ps_Bact <- subset_taxa(comp_ps, Kingdom=="Bacteria")
comp_ps_Arch <- subset_taxa(comp_ps, Kingdom=="Archaea")

```

##########################################################
### Statistical and Algorithmic Exploration ##############
##########################################################

################################################################################################
###################### Generating N x P dataframes of microbiome relative abundances ###########
################################################################################################

############################################################
### Taxonomy Heatmaps / Organized Data Objects  ############
############################################################

#Functions to generate Ampvis2 microbiome data management dataframes from phyloseq objects.
```{r}
make_amp_otu <- function(ps_object){
  
  #Parameters:
      #ps_object (a phyloseq object): The phyloseq object that one wishes to generate an Ampvis2 object from.
  
  #Returns:
      #An otu/taxa table compatible with ampvis2.
  
  #Making a data.frame with ASV and taxonomic data.
  ASV_tab <- data.frame(otu_table(ps_object))
  ASV_tab <- t(ASV_tab) #The ASV table needs to be transposed for Ampvis2.
  Tax_tab <- data.frame(tax_table(ps_object))
  Tax_tab$Species <- "NA"
  all.equal(row.names(ASV_tab), row.names(Tax_tab)) #This should come out as TRUE.
  export_tab <- data.frame(cbind(ASV_tab, Tax_tab))
  
  #Making some dataframe modifications so that ampvis can read the OTU/taxa dataframe.
  dat <- export_tab
  temp <- data.frame(row.names(dat))
  colnames(temp)[1] <- "OTU"
  dat_otu <- cbind(temp, dat)
  
  return(dat_otu)
}


make_amp_meta <- function(ps_object){
  
  #Parameters:
      #ps_object (a phyloseq object): The phyloseq object that one wishes to generate an Ampvis2 object from.
  
  #Returns:
      #A metadata table compatbile with ampvis2.
  
  #Some dataframe modifications so that ampvis can read the metadata dataframe.
  meta <- data.frame(sample_data(ps_object))
  temp <- data.frame(row.names(meta))
  colnames(temp)[1] <- "SampleID"
  meta_samIDs <- cbind(temp, meta)
  
  return(meta_samIDs)
}


```

#Reading in the .csv files from computer for usage in Ampvis2 (commented). OR, using functions to generate ampvis-compatible objects on the spot.
```{r}
#myotutable <- read.csv(paste0(path_to_data,"/Fire_data_science/export_tab.csv", check.names = FALSE))
#mymetadata <- read.csv(paste0(path_to_data,"/Fire_data_science/Samp_meta.csv", check.names = FALSE))

make_composite_amp_object <- function(ps_object){
  
  #Parameters:
      #ps_object (A phyloseq object): The phyloseq object that one wishes to generate an Ampvis2 object from.
  
  #Returns:
      #An ampvis2 object.

  #Creation of the Ampvis2 object.
  d <- amp_load(otutable = make_amp_otu(ps_object),
                metadata = make_amp_meta(ps_object)) #'d' can be called from the R console to get a summary of the data within the Ampvis2 object.
                
  return(d)
}


```

#Making ampvis2 objects for the total dataset (all three domains of life), as well as individual microbial domains.
```{r}

amp_all <- make_composite_amp_object(comp_ps)
amp_Arch <- make_composite_amp_object(comp_ps_Arch)
amp_BA <- make_composite_amp_object(comp_ps_BA)
amp_Euks <- make_composite_amp_object(comp_ps_Euks)

```


#Subsetting ampvis objects to exclude reads that do not have taxonomy called at a particular taxonomic rank. We do this to ensure that no erroneous column names are added in the downstream NxP dataframes due to 'no-call' taxonomic information.
```{r}
##Comments##

#Calling the ampvis object in the console will give a summary of the object including summary statistics of sequencing depth and the percentage of reads that were classified at each taxonomic rank.
#Prior to generating heatmaps (below), one should trim any reads that were not classified at the rank that you wish to examine. This will mitigate the issue of erroneous column names when we make a heatmap with a set number of taxa included.
#Options in the amp_subset_taxa() function allow for normalization (relative abundance) either before OR after the subsetting; this is important for the unknown taxa. Below, we choose to conduct the relative abundance normalization AFTER the subsetting has occurred. One can also choose to exclude certain taxa with the 'remove' argument. Note that when using a character vector to prune taxa, the vector will be used at all taxonomic ranks; beware that this will be an issue if the same taxon name is used at different taxonomic ranks.


#Takes an ampvis2_object 'composite_amp_object' and removes ASVs that had no taxonomy called at level 'tax_level_str'.
excludeNoCalls <- function(composite_amp_object, tax_level_str){
  #Parameters:
    #composite_amp_object (ampvis2 object): The target ampvis2 object.
    #tax_level_str (str): The desired taxonomy level to execute the function at (removes ASVs with no taxonomy called at that rank).
  
  #Returns:
      #An ampvis2 object that has been pruned of ASVs with no taxonomy called at the indicated rank.
  
  my_tax_vect <- unique(composite_amp_object$tax[[tax_level_str]])
  my_tax_vect <- my_tax_vect[which(my_tax_vect != "")]
  excluded_amp_object <- amp_subset_taxa(composite_amp_object, tax_vector = my_tax_vect, normalise = FALSE, remove = FALSE)
  
  return(excluded_amp_object)
  
}



```


#A function that generates a list of custom ampvis objects that focus on different taxa levels. We remove any reads that do not have taxonomy called at the desired rank.
```{r}

#Generates a list of ampvis objects, based upon the focus taxonomic rank supplied to excludeNoCalls().
make_ampTaxaRanks_list <- function(composite_ampvis_object){
#Parameters:
  #composite_ampvis_object: (ampvis object) The constructed ampvis object one wishes to break down into different taxonomic ranks.
  
#Returns:
  #A list of ampvis objects in the specified order of taxonomy (look at the list code, below).
  
amp_list <- list(
  excludeNoCalls(composite_ampvis_object, "Kingdom"),
  excludeNoCalls(composite_ampvis_object, "Phylum"),
  excludeNoCalls(composite_ampvis_object, "Class"),
  excludeNoCalls(composite_ampvis_object, "Order"),
  excludeNoCalls(composite_ampvis_object, "Family"),
  excludeNoCalls(composite_ampvis_object, "Genus")
)

return(amp_list)
  
}



```

#Making lists of samples by taxonomic focus level.
```{r}

ampTaxaRanks_list <- make_ampTaxaRanks_list(amp_all)
ampTaxaRanks_list_Arch <- make_ampTaxaRanks_list(amp_Arch)
ampTaxaRanks_list_BA <- make_ampTaxaRanks_list(amp_BA)
ampTaxaRanks_list_Euks <- make_ampTaxaRanks_list(amp_Euks)

```


#Ampvis2 heatmap objects. One can use these ampvis heatmap objects to recover data that have been nicely organized by variables, taxonomy, etc. Essentially, we use this as a nice function to organize the data in ways that are convenient for downstream statistical analyses. One can call out the raw data from any heatmap object by writing into the R Console 'amp_heatmap_obj$data', for example.
#Note that the 'tax_show' parameter will control how many taxa types make it into the output $data, so one needs to critically evaluate this value and ensure that everything that you want is getting output (for this manuscript, we have done so).
```{r}

make_heatmap_list <- function(ampTaxaRanks_list){
  
  #Parameters:
      #An object that is a list of ampvis2 objects, organized by taxonomic rank.
  
  #Returns:
      #A list of ampvis2 heatmap objects, in order of taxonomic rank (see the code for the list, below).

heatmap_list <- list(
  
amp_heatmap(ampTaxaRanks_list[[1]],
              tax_aggregate = "Kingdom",
              tax_show = length(unique(ampTaxaRanks_list[[1]]$tax[,1]))+1),
amp_heatmap(ampTaxaRanks_list[[2]],
              tax_aggregate = "Phylum",
              tax_show = length(unique(ampTaxaRanks_list[[2]]$tax[,2]))+1),
amp_heatmap(ampTaxaRanks_list[[3]],
              tax_aggregate = "Class",
              tax_show = length(unique(ampTaxaRanks_list[[3]]$tax[,3]))+1),
amp_heatmap(ampTaxaRanks_list[[4]],
              tax_aggregate = "Order",
              tax_show = length(unique(ampTaxaRanks_list[[4]]$tax[,4]))+1),
amp_heatmap(ampTaxaRanks_list[[5]],
              tax_aggregate = "Family",
              tax_show = length(unique(ampTaxaRanks_list[[5]]$tax[,5]))+1),
amp_heatmap(ampTaxaRanks_list[[6]],
              tax_aggregate = "Genus",
              tax_show = length(unique(ampTaxaRanks_list[[6]]$tax[,6]))+1),
amp_heatmap(ampTaxaRanks_list[[1]],
              tax_aggregate = "OTU",
              tax_show = dim(ampTaxaRanks_list[[1]]$abund)[1]+1)
)

return(heatmap_list)

}

```

#Making the heatmap lists that are aggregated to a specific taxonomy rank.
```{r}

## PAY ATTENTION TO THE RED OUTPUTS IN THE CONSOLE FROM THE BELOW CODE. There should always be a warning that there are less taxa than we wish to display, and so it will show everthing (this is what we want). We asked the code to display one more taxa than it is computed exists at each rank just to make sure we encapsulate everything. This is just a warning flag (no extra, empty, data is introduced since the code will default to just the maximum number of taxa). ##

all_TaxaRanks_heats <- make_heatmap_list(ampTaxaRanks_list)
all_TaxaRanks_heats_Arch <- make_heatmap_list(ampTaxaRanks_list_Arch)
all_TaxaRanks_heats_BA <- make_heatmap_list(ampTaxaRanks_list_BA)
all_TaxaRanks_heats_Euks <- make_heatmap_list(ampTaxaRanks_list_Euks)

```


#For NxP problems.
#Beginning with the heatmap data object generated above, we reshape the data to have N observations with P taxonomic groups that have a value of relative abundance.
```{r}

generateNPdf <- function(ampHeat_obj, taxa_rank_number){
  
  #Parameters:
      #ampHeat_obj (A list of ampvis2 heatmap objects): The desired list of ampvis2 heatmaps that has been generated from all samples, or some combination of the three domains of life.
      #taxa_rank_number (numeric): The ranked-order number of taxonomy that one wishes to generate the NxP dataframe from. 1 = Kingdom (by SILVA, Domain in practice), 2 = Phylum, ..., 6 = Genus, 7 = ASV.
  
  #Returns:
      #An N by P (NxP) design matrix with values of relative abundance. The dimensions of N and P are determined by ampHeat_obj; P will represent the number of unique taxa at the specified taxonomic rank taxa_rank_number.

amp_samples_df <- data.frame(ampHeat_obj[[taxa_rank_number]]$data)

NP_df <- pivot_wider(data = amp_samples_df, id_cols = Sample, names_from = Display, values_from = Abundance)
NP_df <- data.frame(NP_df)
row.names(NP_df) <- NP_df$Sample
NP_df <- NP_df[,-c(1)]

meta_df <- data.frame(sample_data(comp_ps))
meta_df$"Sample" <- meta_df$full_sam_name
NP_df$"Sample" <- row.names(NP_df)

joined_NP_df <- left_join(NP_df, meta_df, by.x = c("Sample"), by.y = c("Sample"))
row.names(joined_NP_df) <- joined_NP_df$Sample
joined_NP_df <-  joined_NP_df[ , !(names(joined_NP_df) %in% c("Sample", "sam_name", "...1"))]

return(joined_NP_df)
  
}


```


#Function to generate a list of NP dataframes where each element is an aggregate at a different taxonomic rank. The list order in the heatmap list will determine the list order in this function as well.
```{r}

make_TaxaRanksNP_list <- function(heatmap_list){
  
#Parameters:
    #heatmap_list (A list of ampvis2 heatmap objects): A target list of ampvis2 heatmap objects that were created earlier in the pipeline.
  
#Returns:
    #A list of NxP dataframes, by focus taxonomic rank. See the function definition for 'generateNPdf()', above, for a description of these matrices.

#Note that this function will fail if a subset heatmap list is supplied with only one domain of life (like if only Archaea were included). This is because something changes with the list structure for the 'kingdom' list when there is only one element. But all of the other taxonomic ranks below kingdom should work just fine with the function generateNPdf().
  
TaxaRanksNP_list <- list(
  generateNPdf(heatmap_list, 1),
  generateNPdf(heatmap_list, 2),
  generateNPdf(heatmap_list, 3),
  generateNPdf(heatmap_list, 4),
  generateNPdf(heatmap_list, 5),
  generateNPdf(heatmap_list, 6),
  generateNPdf(heatmap_list, 7)
) #Note that the order in the list above will be the order of the returned NxP dataframes in the returned list object.

return(TaxaRanksNP_list)

}



```

#Creating the list-object of NxP dataframes (function defined above).
#NOTE* In the NP dataframes, there are sometimes taxa named "Incertae_Sedis" with various ASVs and / or taxonomic names appended as well; "Incertae_Sedis" is latin for "uncertain placement" and the other taxonomic information appended are other defining features associated with that particular group of uncertainly placed taxa (in a phylogenetic sense). These labeled uncertainties are native to the SILVA taxonomic assignments used in this manuscript.
```{r}

NP_list <- make_TaxaRanksNP_list(all_TaxaRanks_heats)
NP_list_BA <- make_TaxaRanksNP_list(all_TaxaRanks_heats_BA)

#For the euks, just making the NP dataframes that we are interested in, one by one.
NP_Euks_Phylum <- generateNPdf(all_TaxaRanks_heats_Euks, 2)

```

##################################################
##### GENERALIZED STATS CODE and FUNCTIONS #######
##################################################

########################################
########## GEOCHEMISTRY ################
########################################

#Gathering the geochemsitry data from the pyloseq object along with all of the metadata.
#The result is a tidy geochemistry dataframe that we can use for plots, figures, etc.
```{r}

ps_sample_data <- data.frame(sample_data(comp_ps)) #All of our geochem data is in the phyloseq object.
gathered_geochem <- distinct(ps_sample_data, sam_name, .keep_all = TRUE) #Getting rid of the redundant R2, R3 samples (these exist because of the microbiome samples in the phyloseq object and are redundant when thinking about geochemistry alone). Geochemical measurements were taken in singlicate from composite samples.
geochem_samples <- gathered_geochem[which(gathered_geochem$field_SBS != 'NA'), ] #Subsetting to only geochem samples. Anything with a 'NA' field_SBS was a microbiome control with no associated geochem.

#Adding some log-transformed variables to the dataframe for easier plotting later.
geochem_samples$'log10_DOC' <- log10(geochem_samples$DOC)
geochem_samples$'log10_DTN' <- log10(geochem_samples$DTN)
geochem_samples$'log10_NH4' <- log10(geochem_samples$NH4)
geochem_samples$'log10_NO3' <- log10(geochem_samples$NO3)

#Factoring a metadata variable so that it plots in the desired order in ggplot().
geochem_samples$field_SBS <- factor(geochem_samples$field_SBS , levels=c("High", "Moderate", "Low", "No Burn Control"))

#Split into fires and time points.
geochem_Decker1 <- geochem_samples[which(geochem_samples$fire=="Decker Fire" & geochem_samples$time_point==1), ]
geochem_Decker2 <- geochem_samples[which(geochem_samples$fire=="Decker Fire" & geochem_samples$time_point==2), ]
geochem_Decker3 <- geochem_samples[which(geochem_samples$fire=="Decker Fire" & geochem_samples$time_point==3), ]
geochem_F416_1 <- geochem_samples[which(geochem_samples$fire=="416 Fire" & geochem_samples$time_point==1), ]
geochem_F416_2 <- geochem_samples[which(geochem_samples$fire=="416 Fire" & geochem_samples$time_point==2), ]
geochem_F416_3 <- geochem_samples[which(geochem_samples$fire=="416 Fire" & geochem_samples$time_point==3), ]

#Generate time-series lists for each fire.
Decker_geo_time <- list(geochem_Decker1, geochem_Decker2, geochem_Decker3)
F416_geo_time <- list(geochem_F416_1, geochem_F416_2, geochem_F416_3)

```

#Making a geochemistry data table.
```{r}
#Computing means and standard deviations.
piped_geochem <- geochem_samples %>%
  group_by(fire, time_point, field_SBS, depth_group) %>%
  dplyr::summarise(mean_pH = mean(pH), sd_pH = sd(pH), mean_ANC = mean(ANC), sd_ANC = sd(ANC), mean_EC = mean(EC), sd_EC = sd(EC), mean_DOC = mean(DOC), sd_DOC = sd(DOC), mean_DTN = mean(DTN), sd_DTN = sd(DTN), mean_Na = mean(Na), sd_Na = sd(Na), mean_NH4 = mean(NH4), sd_NH4 = sd(NH4), mean_K = mean(K), sd_K = sd(K), mean_Mg = mean(Mg), sd_Mg = sd(Mg), mean_Ca = mean(Ca), sd_Ca = sd(Ca), mean_Cl = mean(Cl), sd_Cl = sd(Cl), mean_NO3 = mean(NO3), sd_NO3 = sd(NO3), mean_PO4 = mean(PO4), sd_PO4 = sd(PO4), mean_SO4 = mean(SO4), sd_SO4 = sd(SO4), mean_NO3.N = mean(NO3.N), sd_NO3.N = sd(NO3.N), mean_NH4.N = mean(NH4.N), sd_NH4.N = sd(NH4.N), mean_DIN = mean(DIN), sd_DIN = sd(DIN), mean_DON = mean(DON), sd_DON = sd(DON)) #Note the explicit usage of dplyr; there are multiple 'summarise' functions. We do not include "F" here because we were unable to measure this variable (it is all NAs in the standard raw data table format).

#Rounding to 2 decimal points on each variable.
rounded_l <- data.frame(piped_geochem[,1:4])
rounded_r <- data.frame(lapply(piped_geochem[,5:40], round, 2))
rounded <- cbind(rounded_l, rounded_r)

#Combine means and SDs into one expression.
combo_mean_SD <- data.frame(paste(rounded$mean_pH, "+/-", rounded$sd_pH))
colnames(combo_mean_SD)[1] <- "pH"
combo_mean_SD$ANC <- paste(rounded$mean_ANC, "+/-", rounded$sd_ANC)
combo_mean_SD$EC <- paste(rounded$mean_EC, "+/-", rounded$sd_EC)
combo_mean_SD$DOC <- paste(rounded$mean_DOC, "+/-", rounded$sd_DOC)
combo_mean_SD$DTN <- paste(rounded$mean_DTN, "+/-", rounded$sd_DTN)
combo_mean_SD$Na <- paste(rounded$mean_Na, "+/-", rounded$sd_Na)
combo_mean_SD$NH4 <- paste(rounded$mean_NH4, "+/-", rounded$sd_NH4)
combo_mean_SD$K <- paste(rounded$mean_K, "+/-", rounded$sd_K)
combo_mean_SD$Mg <- paste(rounded$mean_Mg, "+/-", rounded$sd_Mg)
combo_mean_SD$Ca <- paste(rounded$mean_Ca, "+/-", rounded$sd_Ca)
combo_mean_SD$Cl <- paste(rounded$mean_Cl, "+/-", rounded$sd_Cl)
combo_mean_SD$NO3 <- paste(rounded$mean_NO3, "+/-", rounded$sd_NO3)
combo_mean_SD$PO4 <- paste(rounded$mean_PO4, "+/-", rounded$sd_PO4)
combo_mean_SD$SO4 <- paste(rounded$mean_SO4, "+/-", rounded$sd_SO4)
combo_mean_SD$NO3.N <- paste(rounded$mean_NO3.N, "+/-", rounded$sd_NO3.N)
combo_mean_SD$NH4.N <- paste(rounded$mean_NH4.N, "+/-", rounded$sd_NH4.N)
combo_mean_SD$DIN <- paste(rounded$mean_DIN, "+/-", rounded$sd_DIN)
combo_mean_SD$DON <- paste(rounded$mean_DON, "+/-", rounded$sd_DON)
combo_mean_SD <- cbind(rounded_l, combo_mean_SD)

#Separating by fire.
F416_combo_mean_SD <- combo_mean_SD[combo_mean_SD$fire == "416 Fire", ] #Subset by fire.
F416_combo_mean_SD <- F416_combo_mean_SD[,c(-1)] #Remove the fire variable.
Decker_combo_mean_SD <- combo_mean_SD[combo_mean_SD$fire == "Decker Fire", ] #Subset by fire.
Decker_combo_mean_SD <- Decker_combo_mean_SD[,c(-1)] #Remove the fire variable.

#Renaming values for better tables.
F416_combo_mean_SD_rename <- F416_combo_mean_SD #Copy of the 416 Fire table.
F416_combo_mean_SD_rename$depth_group[which(F416_combo_mean_SD$depth_group == 1)] <- "Organic"
F416_combo_mean_SD_rename$depth_group[which(F416_combo_mean_SD$depth_group == 2)] <- "Mineral 1"
F416_combo_mean_SD_rename$depth_group[which(F416_combo_mean_SD$depth_group == 3)] <- "Mineral 2"
F416_combo_mean_SD_rename$depth_group[which(F416_combo_mean_SD$depth_group == 4)] <- "Mineral 3"
F416_combo_mean_SD_rename$time_point[which(F416_combo_mean_SD$time_point == 1)] <- "2018"
F416_combo_mean_SD_rename$time_point[which(F416_combo_mean_SD$time_point == 2)] <- "2019"
F416_combo_mean_SD_rename$time_point[which(F416_combo_mean_SD$time_point == 3)] <- "2020"
Decker_combo_mean_SD_rename <- Decker_combo_mean_SD #Copy of the Decker Fire table.
Decker_combo_mean_SD_rename$depth_group[which(Decker_combo_mean_SD$depth_group == "NA")] <- "Organic"
Decker_combo_mean_SD_rename$time_point[which(Decker_combo_mean_SD$time_point == 1)] <- "November 2019"
Decker_combo_mean_SD_rename$time_point[which(Decker_combo_mean_SD$time_point == 2)] <- "May 2020"
Decker_combo_mean_SD_rename$time_point[which(Decker_combo_mean_SD$time_point == 3)] <- "July 2020"
#Renaming variables for better tables.
colnames(F416_combo_mean_SD_rename)[which(colnames(F416_combo_mean_SD_rename) == "depth_group")] <- "Soil Horizon"
colnames(F416_combo_mean_SD_rename)[which(colnames(F416_combo_mean_SD_rename) == "field_SBS")] <- "Soil Burn Severity"
colnames(Decker_combo_mean_SD_rename)[which(colnames(Decker_combo_mean_SD_rename) == "depth_group")] <- "Soil Horizon"
colnames(Decker_combo_mean_SD_rename)[which(colnames(Decker_combo_mean_SD_rename) == "field_SBS")] <- "Soil Burn Severity"

library(gt)
library(gtsummary)
library(r2rtf)
#Generating the base tables (416 Fire).
F416_base_table1 <- cbind(F416_combo_mean_SD_rename[,1:3], F416_combo_mean_SD[,4:9]) %>% 
  gt(groupname_col = c("time_point"))
F416_base_table2 <- cbind(F416_combo_mean_SD_rename[,1:3], F416_combo_mean_SD[,10:15]) %>% 
  gt(groupname_col = c("time_point"))
F416_base_table3 <- cbind(F416_combo_mean_SD_rename[,1:3], F416_combo_mean_SD[,16:21]) %>% 
  gt(groupname_col = c("time_point"))
#Generating the base tables (Decker Fire).
Decker_base_table1 <- cbind(Decker_combo_mean_SD_rename[,1:3], Decker_combo_mean_SD_rename[,4:9]) %>% 
  gt(groupname_col = c("time_point"))
Decker_base_table2 <- cbind(Decker_combo_mean_SD_rename[,1:3], Decker_combo_mean_SD_rename[,10:15]) %>% 
  gt(groupname_col = c("time_point"))
Decker_base_table3 <- cbind(Decker_combo_mean_SD_rename[,1:3], Decker_combo_mean_SD_rename[,16:21]) %>% 
  gt(groupname_col = c("time_point"))

###
#LaTex outputs: We have broken down the tables into smaller tables to manage horizontal spacing in the LaTex template. The way to get these tables into LaTex is to 1) Add everthing outputed from running the below chunks from '\begin{longtable}' to \end{longtable} and place it within a 'table' chunk in the PNAS template. To have multiple row-chunks in one SI Table, copy and paste everything from '\toprule' to '\bottomrule' immediately after the previous '\bottomrule', still within the 'longtable' chunk. If there are still row-chunks that need to be added and won't fit in one 'longtable', just repeat the above but as a new 'table' SI Figure.
#IMPORTANT: Change the {longtable} command once in LaTex to {tabular}. This will preserve the numbering conventions for table legends in the PNAS template. It will also revert the table to PNAS sizing / spacing which makes it look nice.
###

#416 Fire table, broken down.
F416_base_table1 %>%
  as_latex() %>%
  as.character() %>%
  cat()
F416_base_table2 %>%
  as_latex() %>%
  as.character() %>%
  cat()
F416_base_table3 %>%
  as_latex() %>%
  as.character() %>%
  cat()

#Decker Fire table, broken down.
Decker_base_table1 %>%
  as_latex() %>%
  as.character() %>%
  cat()
Decker_base_table2 %>%
  as_latex() %>%
  as.character() %>%
  cat()
Decker_base_table3 %>%
  as_latex() %>%
  as.character() %>%
  cat()

####
####
####

```

#Getting summary statistics of geochemistry variables.
```{r}

#Start a table that we will build on.
geo_summary <- data.frame()
var_list <- list("DTN", "DOC", "ANC", "PO4", "SO4", "K", "NH4", "NO3", "Ca", "Mg", "Na", "Cl", "pH")
col_vec <- c("Min.", "1st Qu.", "Median", "Mean", "3rd Qu.", "Max.")

#Add individual analyte summaries to the table.
for (i in var_list){
  j_count <- 0
  for (j in c(1,2,3,4,5,6)){
    geo_summary[i,j] <- summary(geochem_samples[,i])[[j]]
  }
}

#Name columns and print the table.
colnames(geo_summary) <- col_vec
geo_summary

#Making the same table as above, but log10 transformed (except pH).
geo_summary_log10 <- log10(geo_summary)
geo_summary_log10 <- geo_summary_log10[which(row.names(geo_summary_log10) != "pH"),] #Remove pH from this table since pH is, by definition, already in log space.

#For LaTex
xtable(geo_summary)
xtable(geo_summary_log10) #Same table as line above, but log10 transformed (pH is not included since it is already in log space by definition).


```

###########################################################
############ Microbiome and Geochemistry ##################
############ Composite Prediction Models ##################
###########################################################

#Generalized train / test splitting to generate matrices for various model types, comprised of data from different fire subsets.
```{r}
make_train_test_set <- function(NP_list, taxa_list_num, fire, time_point, biogeo, analyte, train_test_seed = 3, subset_abundance_group = FALSE, ifSubAbund_top10 = TRUE){
  
#Parameters:
    #NP_list (R object): An N by P matrix object that was generated earlier in the code (either the whole dataset, or could be just bactera + archaea or eukarya).
    #taxa_list_num (numeric): The number that corresponds to the taxa rank of interest. 1 = Domain, 2 = Phylum, ... , 7 = ASV.
    #fire (string): The desired fire; either "416 Fire" or "Decker Fire"
    #time_point (numeric): The time point of sampling (1, 2, or 3).
    #biogeo (string): Model type. One of "geo_to_geo", "geo_to_bio", "bio_to_geo", "biogeo_to_geo", or "bio_to_bio", or "biogeo_to_bio".
    #analyte (string): The target variable of interest; e.g., "DTN".
    #train_test_seed (numeric): The random seed used to split training and testing datasets. Note that "train_test_seed = 3" was chosen as the default (it will be used for scatter plot generation) because for both DTN and DOC models (manuscript main body) with 10X different random train/test sets, it was the seed that produced a TESTING score closest to the median across the 10X train/test sets.
    #subset_abundance_group (boolean): Default FALSE. If TRUE, the top-10 abundant taxa across the dataset are identified and stored in a vector.
    #ifSubAbund_top10 (boolean): Only comes into play if subset_abundance_group == TRUE. If ifSubAbund_top10 == TRUE, then only the most common 10 microbiota taxa will be included in the microbiome matrix; if FALSE, the inverse happens (only the microbiota that are NOT the most common 10 taxa will end up in the microbiome matrix). This parameter in conjunction with subset_abundance_group is useful for testing the relative contributions of different parts of the abundant biosphere to making predictions.
  
#Returns:
    #A list of various feature / target matrices and associated metadata to keep track of. The list is as follows: list(xmat_train, ymat_train, xmat_test, ymat_test, xdf_train, ydf_train, xdf_test, ydf_test, biogeo, trim_sub_NP, analyte, fire, time_point, taxa_list_num)
  
library(glmnet)
library(car)

####Make temporary subsets of the NxP design matrices.
##As specified by arguments supplied to the function.

#Branch depending on if we're looking at all datapoints or specific fires / time points.
if (fire == "All"){
sub_NP <- NP_list[[taxa_list_num]][which(NP_list[[taxa_list_num]]$'control_type'=='NA'),]
} else {
sub_NP <- NP_list[[taxa_list_num]][which(NP_list[[taxa_list_num]]$'fire'==fire & NP_list[[taxa_list_num]]$'time_point'==time_point & NP_list[[taxa_list_num]]$'control_type'=='NA'),]
}

#Pulling out taxonomy and geochemistry from the total dataframe. We do not make a special subset of metadata as we have already subsetted to the data of interest (see lines of code above).
sub_NP_geochem <- sub_NP[,(dim(sub_NP)[2]-43):(dim(sub_NP)[2])] #Just taking the geochemistry data.
sub_NP_geochem <- subset(sub_NP_geochem, select=-c(seq_depth, F)) #Removing the seq_depth variable because it is all NA values and will result in a 0 sample dataframe later on when we clean samples with any NA values. Also removing the F variable for the same reason.
sub_NP_geochem <- subset(sub_NP_geochem, select=-c(X.ION, X..COND, is.neg)) #Removing additional categorical variables that are unnecessary.
trim_sub_NP <- sub_NP[,1:(dim(sub_NP)[2]-64)] #Taking all rows from the dataframe and all columns (less 64 from the end which is the number of metadata variables stapled onto the end of the dataframe). The number of metadata variables that need to be trimmed off will change if more metadata is added to the raw design matrix (added to phyloseq objects in the preprocessing file), so be sure to keep an eye on this line of code. BUT, unless one changes the raw excel file used for the preprocessing .Rmd, this doesn't need to be worried about.

#Removing taxa from the dataframe that are no longer present in any samples after controls were removed. These 0 abundance taxa will cause problems with ranked-abundance plotting later on if they are not removed here.
no_counts <- names(which(colSums(trim_sub_NP) == 0))
trim_sub_NP <- trim_sub_NP[ , -which(names(trim_sub_NP) %in% c(no_counts))]

#Code to either only take the top-X most abundant taxa, or the inverse. This abundance-based subsetting will only happen if 'subset_abundance_group == TRUE'; the default is to consider all taxa in the model, irrespective of mean abundance. If 'subset_abundance_group == TRUE', the default will be to subset to the top-10 taxa.
if (subset_abundance_group == TRUE){
  mean_abunds <- data.frame(colSums(trim_sub_NP)/dim(trim_sub_NP)[1]) #Gets the mean abundance of each taxa across all samples.
  mean_abunds <- mean_abunds %>% arrange(desc(mean_abunds)) #Arranges taxa by descending order of the mean abundance.
  top10_names <- row.names(mean_abunds)[1:10] #Gets the names of the top-10 abundant taxa.
  if (ifSubAbund_top10 == TRUE){
  trim_sub_NP <- trim_sub_NP[ , which(names(trim_sub_NP) %in% top10_names)] #Subsets to only the top-10 abundant taxa.
  } else if (ifSubAbund_top10 == FALSE){
  trim_sub_NP <- trim_sub_NP[ , -which(names(trim_sub_NP) %in% top10_names)] #Conversely, takes only taxa that are NOT in the top 10.
  }
}

#Put the geochemistry and taxonomy back together so that we can clean any NA values from the data.
taxa_plus_geochem <- cbind(trim_sub_NP, sub_NP_geochem)
taxa_plus_geochem_clean <- na.omit(taxa_plus_geochem) #Removes all rows (samples) that have an NA in at least one column.

## Choosing 75% of the sample size as the training data size.
smp_size <- floor(0.75 * nrow(taxa_plus_geochem_clean))
## set the seed to make your partition reproducible
set.seed(train_test_seed) #This will determine all downstream sets of training and testing data. train_test_seed is supplied as an argument when the function is called.
train_ind <- sample(seq_len(nrow(taxa_plus_geochem_clean)), size = smp_size)
train <- taxa_plus_geochem_clean[train_ind, ]
test <- taxa_plus_geochem_clean[-train_ind, ]


#Take the taxa and geochem apart again now that the data are clean. Name the geochem and taxa tables such that they feed correctly into the code below.
taxa_only_train <- train[,1:(dim(train)[2]-39)]
geo_only_train <- train[,(dim(train)[2]-38):(dim(train)[2])]
taxa_only_test <- test[,1:(dim(train)[2]-39)]
geo_only_test <- test[,(dim(train)[2]-38):(dim(test)[2])]

#Adding a new variable: Carbon to Nitrogen ratio.
#Other new variables that are a function of various measurements could be created here in a similar fashion.
fun1 <- function(x, y) {x/y}
geo_only_train$CNratio <- mapply(fun1, geo_only_train$DOC, geo_only_train$DTN) #Make the variable in the train data.
geo_only_test$CNratio <- mapply(fun1, geo_only_test$DOC, geo_only_test$DTN) #Also make the variable in the test data.

#A list of extra geochem variables that want to remove from the feature space since they contain redundant information with the target variables (ueq, for example, is the same variable as other features but just with a different unit). This line is really important; THIS IS HOW WE PREVENT HAVING LEAKY DATA (information in the feature space that is exactly correlated with targets).
extra_list <- c("ANC_ueq", "H._ueq", "Ca_ueq", "Mg_ueq", "Na_ueq", "K_ueq", "NH4_ueq", "F_ueq", "CL_ueq", "NO3_ueq", "PO4_ueq", "SO4_ueq", "ANIONS", "CATIONS", "ION", "DIFF_AnionCation", "BASES", "ACIDS", "DIFF_IonsEC")
#extra_list <- colnames(geo_only_train)[19:length(colnames(geo_only_train))] #Another version of the extra list where we just trim a set amount from the RHS of the dataframe.
#extra_list <- colnames(geo_only_train)[2:length(colnames(geo_only_train))] #ONE CAN PLAY WITH THIS ALTERNATE VERSION OF 'EXTRA_LIST' TO SEE HOW BIOGEO_TO_GEO WORKS AS WE SYSTEMATICALLY TAKE AWAY MORE AND MORE GEO.
#Another set of geochem variables that could be confounding (exactly redundant information). Play with this line rather than the extra_list. Extra_list items are guaranteed to be redundant; this may not be so for some of the variables in confound_geo.
confound_geo <- c("DIN", "DON", "NO3.N", "NH4.N", "EC", "ALK", "COND", "CNratio")

#In the next segment of code (after this function definition) where we branch depending on the model type, we will need to modify geo_to_geo prediction dataframes to remove the replicate observations due to triplicate DNA sampling. Here, we define a function that will condense geo-only dataframes down into just one observation per sample.
trim_bio_reps <- function(df_to_mod){
  fullNames <- geochem_samples$full_sam_name
  shortNames_fromGeo <- geochem_samples$sam_name
  names_bind <- cbind(fullNames, shortNames_fromGeo)
  df_to_mod$fullNames <- row.names(df_to_mod)
  names_merged <- merge(df_to_mod, names_bind, by = "fullNames")
  row.names(names_merged) <- names_merged$shortNames_fromGeo
  names_merged <- subset(names_merged, select=-c(fullNames,shortNames_fromGeo))
  product_df <- names_merged
  return(product_df)
}

#Branch depending on what kind of model one wants to run (types of data used as both features and targets).
if (biogeo == "bio_to_geo"){
  #Making the train and test DFs.
  xdf_train <- taxa_only_train
  ydf_train <- geo_only_train[ , (names(geo_only_train) %in% c(analyte))]
  xdf_test <- taxa_only_test
  ydf_test <- geo_only_test[ , (names(geo_only_test) %in% c(analyte))]
} else if (biogeo == "geo_to_geo") {
  #An alternate set of train and test dfs.
  exclude_from_X <- append(extra_list, c(analyte))
  exclude_from_X <- append(exclude_from_X, confound_geo)
  use_as_y <- c(analyte)
  xdf_train <- geo_only_train[ , !(names(geo_only_train) %in% exclude_from_X)]
  ydf_train <- geo_only_train[ , (names(geo_only_train) %in% use_as_y)]
  ydf_train <- as.data.frame(ydf_train) #Needed for the singlicate geo_to_geo samples code.
  row.names(ydf_train) <- row.names(geo_only_train) #Need the rownames for geo_to_geo singlicate code.
  xdf_test <- geo_only_test[ , !(names(geo_only_test) %in% exclude_from_X)]
  ydf_test <- geo_only_test[ , (names(geo_only_test) %in% use_as_y)]
  ydf_test <- as.data.frame(ydf_test) #Needed for the singlicate geo_to_geo samples code.
  row.names(ydf_test) <- row.names(geo_only_test) #Need the rownames for geo_to_geo singlicate code.
  xdf_train <- trim_bio_reps(xdf_train) #Note this line and the three below it remove the replicate DNA observations from dataframes such that only the singlicate geochemistry observations are in the dataframe. This function is defined in the lines of code above these model type if-else branch statements.
  ydf_train <- trim_bio_reps(ydf_train)
  xdf_test <- trim_bio_reps(xdf_test)
  ydf_test <- trim_bio_reps(ydf_test)
} else if (biogeo == "biogeo_to_geo") {
  exclude_from_X <- append(extra_list, c(analyte))
  exclude_from_X <- append(exclude_from_X, confound_geo)
  use_as_y <- c(analyte)
  xdf_train <- cbind(taxa_only_train, geo_only_train)[ , !(names(cbind(taxa_only_train, geo_only_train)) %in% exclude_from_X)]
  ydf_train <- cbind(taxa_only_train, geo_only_train)[ , (names(cbind(taxa_only_train, geo_only_train)) %in% use_as_y)]
  xdf_test <- cbind(taxa_only_test, geo_only_test)[ , !(names(cbind(taxa_only_test, geo_only_test)) %in% exclude_from_X)]
  ydf_test <- cbind(taxa_only_test, geo_only_test)[ , (names(cbind(taxa_only_test, geo_only_test)) %in% use_as_y)]
} else if (biogeo == "bio_to_bio") {
  use_as_y <- c(analyte)
  xdf_train <- taxa_only_train[ , !(names(taxa_only_train) %in% use_as_y)]
  ydf_train <- taxa_only_train[ , (names(taxa_only_train) %in% use_as_y)]
  xdf_test <- taxa_only_test[ , !(names(taxa_only_test) %in% use_as_y)]
  ydf_test <- taxa_only_test[ , (names(taxa_only_test) %in% use_as_y)]
} else if (biogeo == "geo_to_bio") {
  exclude_from_X <- append(extra_list, confound_geo)
  use_as_y <- c(analyte)
  xdf_train <- geo_only_train[ , !(names(geo_only_train) %in% exclude_from_X)]
  ydf_train <- taxa_only_train[ , (names(taxa_only_train) %in% use_as_y)]
  xdf_test <- geo_only_test[ , !(names(geo_only_test) %in% exclude_from_X)]
  ydf_test <- taxa_only_test[ , (names(taxa_only_test) %in% use_as_y)]
} else if (biogeo == "biogeo_to_bio") {
  exclude_from_X <- append(extra_list, c(analyte))
  use_as_y <- c(analyte)
  xdf_train <- cbind(taxa_only_train, geo_only_train)[ , !(names(cbind(taxa_only_train, geo_only_train)) %in% exclude_from_X)]
  ydf_train <- taxa_only_train[ , (names(taxa_only_train) %in% use_as_y)]
  xdf_test <- cbind(taxa_only_test, geo_only_test)[ , !(names(cbind(taxa_only_test, geo_only_test)) %in% exclude_from_X)]
  ydf_test <- taxa_only_test[ , (names(taxa_only_test) %in% use_as_y)]
} else {
  stop("You need to choose a model type.")
}


#Converting feature and target dfs to matrices.
xmat_train <- as.matrix(xdf_train)
ymat_train <- as.matrix(ydf_train)
xmat_test <- as.matrix(xdf_test)
ymat_test <- as.matrix(ydf_test)

#Return the dataframes, matrices, and relevant variables for usage in different Stat / ML models.
return(list(xmat_train, ymat_train, xmat_test, ymat_test, xdf_train, ydf_train, xdf_test, ydf_test, biogeo, trim_sub_NP, analyte, fire, time_point, taxa_list_num))

}

```


#Building train / test split groups.
```{r}
#List order from the returned train_test_set construction:
#list(xmat_train, ymat_train, xmat_test, ymat_test, xdf_train, ydf_train, xdf_test, ydf_test, biogeo, trim_sub_NP, analyte, fire, time_point, taxa_list_num)

#Dissolved total nitrogen (DTN).
All_g2g_DTN <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_geo", analyte = "DTN")
All_Phy_bg2g_DTN <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DTN")
All_Cls_bg2g_DTN <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DTN")
All_Ord_bg2g_DTN <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DTN")
All_Fam_bg2g_DTN <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DTN")
All_Gen_bg2g_DTN <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DTN")
#b2g
All_Phy_b2g_DTN <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DTN")
All_Cls_b2g_DTN <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DTN")
All_Ord_b2g_DTN <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DTN")
All_Fam_b2g_DTN <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DTN")
All_Gen_b2g_DTN <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DTN")
All_ASV_b2g_DTN <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DTN")
All_Gen_bg2g_DTN_top10 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DTN", subset_abundance_group = TRUE, ifSubAbund_top10 = TRUE) #Make another Genus-level subset, but this time only include the top 10 most abundant taxa.
All_Gen_bg2g_DTN_NOTtop10 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DTN", subset_abundance_group = TRUE, ifSubAbund_top10 = FALSE) #Make another Genus-level subset, but this time only include the NOT top 10 most abundant taxa.
All_ASV_bg2g_DTN <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DTN")
DTN_hybrid_list <- list(All_Phy_bg2g_DTN, All_Cls_bg2g_DTN, All_Ord_bg2g_DTN, All_Fam_bg2g_DTN, All_Gen_bg2g_DTN, All_ASV_bg2g_DTN)
DTN_geo_list <- list(All_g2g_DTN)
DTN_bio_list <- list(All_Phy_b2g_DTN, All_Cls_b2g_DTN, All_Ord_b2g_DTN, All_Fam_b2g_DTN, All_Gen_b2g_DTN, All_ASV_b2g_DTN)
#Make a list of 10 train/test sets for Genus bg2g, g2g, top-10_bg2g, and b2g.
DTN_sets_bg2g <- list() #Instantiate an empty list for bg2g.
seed_list <- seq(1, 10, length.out=10)
for (i in seed_list){
  DTN_sets_bg2g[[i]] <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DTN", train_test_seed = i)
} #Note that DTN_sets_bg2g[[1]][[14]] is how one would access the 14th returned item from "make_train_test_set" for the the 1st random seed (random seed = 1).
DTN_sets_top10_bg2g <- list() #Instantiate an empty list for top10_bg2g.
seed_list <- seq(1, 10, length.out=10)
for (i in seed_list){
  DTN_sets_top10_bg2g[[i]] <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DTN", train_test_seed = i, subset_abundance_group = TRUE, ifSubAbund_top10 = TRUE)
}
DTN_sets_g2g <- list() #Instantiate an empty list for g2g.
for (i in seed_list){
  DTN_sets_g2g[[i]] <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_geo", analyte = "DTN", train_test_seed = i)
} #Note that DTN_sets_g2g[[1]][[14]] is how one would access the 14th returned item from "make_train_test_set" for the the 1st random seed (random seed = 1).
DTN_sets_b2g <- list() #Instantiate an empty list for b2g.
for (i in seed_list){
  DTN_sets_b2g[[i]] <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DTN", train_test_seed = i, subset_abundance_group = FALSE)
}

#Dissolved total carbon (DOC).
All_g2g_DOC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_geo", analyte = "DOC")
All_Phy_bg2g_DOC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DOC")
All_Cls_bg2g_DOC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DOC")
All_Ord_bg2g_DOC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DOC")
All_Fam_bg2g_DOC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DOC")
All_Gen_bg2g_DOC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DOC")
#b2g
All_Phy_b2g_DOC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DOC")
All_Cls_b2g_DOC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DOC")
All_Ord_b2g_DOC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DOC")
All_Fam_b2g_DOC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DOC")
All_Gen_b2g_DOC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DOC")
All_ASV_b2g_DOC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DOC")
All_Gen_bg2g_DOC_top10 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DOC", subset_abundance_group = TRUE, ifSubAbund_top10 = TRUE) #Make another Genus-level subset, but this time only include the top 10 most abundant taxa.
All_Gen_bg2g_DOC_NOTtop10 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DOC", subset_abundance_group = TRUE, ifSubAbund_top10 = FALSE) #Make another Genus-level subset, but this time only include the NOT top 10 most abundant taxa.
All_ASV_bg2g_DOC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DOC")
DOC_hybrid_list <- list(All_Phy_bg2g_DOC, All_Cls_bg2g_DOC, All_Ord_bg2g_DOC, All_Fam_bg2g_DOC, All_Gen_bg2g_DOC, All_ASV_bg2g_DOC)
DOC_geo_list <- list(All_g2g_DOC)
DOC_bio_list <- list(All_Phy_b2g_DOC, All_Cls_b2g_DOC, All_Ord_b2g_DOC, All_Fam_b2g_DOC, All_Gen_b2g_DOC, All_ASV_b2g_DOC)
#Make a list of 10 train/test sets for Genus bg2g, g2g, top-10_bg2g, and b2g.
DOC_sets_bg2g <- list() #Instantiate an empty list for bg2g.
seed_list <- seq(1, 10, length.out=10)
for (i in seed_list){
  DOC_sets_bg2g[[i]] <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DOC", train_test_seed = i)
} #Note that DOC_sets_bg2g[[1]][[14]] is how one would access the 14th returned item from "make_train_test_set" for the the 1st random seed (random seed = 1).
DOC_sets_top10_bg2g <- list() #Instantiate an empty list for top10_bg2g.
seed_list <- seq(1, 10, length.out=10)
for (i in seed_list){
  DOC_sets_top10_bg2g[[i]] <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "DOC", train_test_seed = i, subset_abundance_group = TRUE, ifSubAbund_top10 = TRUE)
}
DOC_sets_g2g <- list() #Instantiate an empty list for g2g.
for (i in seed_list){
  DOC_sets_g2g[[i]] <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_geo", analyte = "DOC", train_test_seed = i)
} #Note that DOC_sets_g2g[[1]][[14]] is how one would access the 14th returned item from "make_train_test_set" for the the 1st random seed (random seed = 1).
DOC_sets_b2g <- list() #Instantiate an empty list for b2g.
for (i in seed_list){
  DOC_sets_b2g[[i]] <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DOC", train_test_seed = i, subset_abundance_group = FALSE)
}

#Phosphate (PO4).
All_g2g_PO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_geo", analyte = "PO4")
All_Phy_bg2g_PO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "PO4")
All_Cls_bg2g_PO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "PO4")
All_Ord_bg2g_PO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "PO4")
All_Fam_bg2g_PO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "PO4")
All_Gen_bg2g_PO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "PO4")
All_ASV_bg2g_PO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "PO4")
#b2g
All_Phy_b2g_PO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "PO4")
All_Cls_b2g_PO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "PO4")
All_Ord_b2g_PO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "PO4")
All_Fam_b2g_PO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "PO4")
All_Gen_b2g_PO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "PO4")
All_ASV_b2g_PO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "PO4")
PO4_hybrid_list <- list(All_Phy_bg2g_PO4, All_Cls_bg2g_PO4, All_Ord_bg2g_PO4, All_Fam_bg2g_PO4, All_Gen_bg2g_PO4, All_ASV_bg2g_PO4)
PO4_geo_list <- list(All_g2g_PO4)
PO4_bio_list <- list(All_Phy_b2g_PO4, All_Cls_b2g_PO4, All_Ord_b2g_PO4, All_Fam_b2g_PO4, All_Gen_b2g_PO4, All_ASV_b2g_PO4)

#Acid neutralizing capacity (ANC).
All_g2g_ANC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_geo", analyte = "ANC")
All_Phy_bg2g_ANC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "ANC")
All_Cls_bg2g_ANC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "ANC")
All_Ord_bg2g_ANC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "ANC")
All_Fam_bg2g_ANC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "ANC")
All_Gen_bg2g_ANC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "ANC")
All_ASV_bg2g_ANC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "ANC")
#b2g
All_Phy_b2g_ANC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "ANC")
All_Cls_b2g_ANC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "ANC")
All_Ord_b2g_ANC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "ANC")
All_Fam_b2g_ANC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "ANC")
All_Gen_b2g_ANC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "ANC")
All_ASV_b2g_ANC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "ANC")
ANC_hybrid_list <- list(All_Phy_bg2g_ANC, All_Cls_bg2g_ANC, All_Ord_bg2g_ANC, All_Fam_bg2g_ANC, All_Gen_bg2g_ANC, All_ASV_bg2g_ANC)
ANC_geo_list <- list(All_g2g_ANC)
ANC_bio_list <- list(All_Phy_b2g_ANC, All_Cls_b2g_ANC, All_Ord_b2g_ANC, All_Fam_b2g_ANC, All_Gen_b2g_ANC, All_ASV_b2g_ANC)

#Sulfate (SO4).
All_g2g_SO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_geo", analyte = "SO4")
All_Phy_bg2g_SO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "SO4")
All_Cls_bg2g_SO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "SO4")
All_Ord_bg2g_SO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "SO4")
All_Fam_bg2g_SO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "SO4")
All_Gen_bg2g_SO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "SO4")
All_ASV_bg2g_SO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "SO4")
#b2g
All_Phy_b2g_SO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "SO4")
All_Cls_b2g_SO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "SO4")
All_Ord_b2g_SO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "SO4")
All_Fam_b2g_SO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "SO4")
All_Gen_b2g_SO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "SO4")
All_ASV_b2g_SO4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "SO4")
SO4_hybrid_list <- list(All_Phy_bg2g_SO4, All_Cls_bg2g_SO4, All_Ord_bg2g_SO4, All_Fam_bg2g_SO4, All_Gen_bg2g_SO4, All_ASV_bg2g_SO4)
SO4_geo_list <- list(All_g2g_SO4)
SO4_bio_list <- list(All_Phy_b2g_SO4, All_Cls_b2g_SO4, All_Ord_b2g_SO4, All_Fam_b2g_SO4, All_Gen_b2g_SO4, All_ASV_b2g_SO4)

#Potassium (K).
All_g2g_K <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_geo", analyte = "K")
All_Phy_bg2g_K <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "K")
All_Cls_bg2g_K <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "K")
All_Ord_bg2g_K <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "K")
All_Fam_bg2g_K <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "K")
All_Gen_bg2g_K <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "K")
All_ASV_bg2g_K <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "K")
#b2g
All_Phy_b2g_K <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "K")
All_Cls_b2g_K <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "K")
All_Ord_b2g_K <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "K")
All_Fam_b2g_K <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "K")
All_Gen_b2g_K <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "K")
All_ASV_b2g_K <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "K")
K_hybrid_list <- list(All_Phy_bg2g_K, All_Cls_bg2g_K, All_Ord_bg2g_K, All_Fam_bg2g_K, All_Gen_bg2g_K, All_ASV_bg2g_K)
K_geo_list <- list(All_g2g_K)
K_bio_list <- list(All_Phy_b2g_K, All_Cls_b2g_K, All_Ord_b2g_K, All_Fam_b2g_K, All_Gen_b2g_K, All_ASV_b2g_K)

#Ammonium (NH4).
All_g2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_geo", analyte = "NH4")
All_Phy_bg2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "NH4")
All_Cls_bg2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "NH4")
All_Ord_bg2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "NH4")
All_Fam_bg2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "NH4")
All_Gen_bg2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "NH4")
All_ASV_bg2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "NH4")
#b2g
All_Phy_b2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NH4")
All_Cls_b2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NH4")
All_Ord_b2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NH4")
All_Fam_b2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NH4")
All_Gen_b2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NH4")
All_ASV_b2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NH4")
NH4_hybrid_list <- list(All_Phy_bg2g_NH4, All_Cls_bg2g_NH4, All_Ord_bg2g_NH4, All_Fam_bg2g_NH4, All_Gen_bg2g_NH4, All_ASV_bg2g_NH4)
NH4_geo_list <- list(All_g2g_NH4)
NH4_bio_list <- list(All_Phy_b2g_NH4, All_Cls_b2g_NH4, All_Ord_b2g_NH4, All_Fam_b2g_NH4, All_Gen_b2g_NH4, All_ASV_b2g_NH4)

#Nitrate (NO3).
All_g2g_NO3 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_geo", analyte = "NO3")
All_Phy_bg2g_NO3 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "NO3")
All_Cls_bg2g_NO3 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "NO3")
All_Ord_bg2g_NO3 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "NO3")
All_Fam_bg2g_NO3 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "NO3")
All_Gen_bg2g_NO3 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "NO3")
All_ASV_bg2g_NO3 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "NO3")
#b2g
All_Phy_b2g_NO3 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NO3")
All_Cls_b2g_NO3 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NO3")
All_Ord_b2g_NO3 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NO3")
All_Fam_b2g_NO3 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NO3")
All_Gen_b2g_NO3 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NO3")
All_ASV_b2g_NO3 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NO3")
NO3_hybrid_list <- list(All_Phy_bg2g_NO3, All_Cls_bg2g_NO3, All_Ord_bg2g_NO3, All_Fam_bg2g_NO3, All_Gen_bg2g_NO3, All_ASV_bg2g_NO3)
NO3_geo_list <- list(All_g2g_NO3)
NO3_bio_list <- list(All_Phy_b2g_NO3, All_Cls_b2g_NO3, All_Ord_b2g_NO3, All_Fam_b2g_NO3, All_Gen_b2g_NO3, All_ASV_b2g_NO3)

#Calcium (Ca).
All_g2g_Ca <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_geo", analyte = "Ca")
All_Phy_bg2g_Ca <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Ca")
All_Cls_bg2g_Ca <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Ca")
All_Ord_bg2g_Ca <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Ca")
All_Fam_bg2g_Ca <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Ca")
All_Gen_bg2g_Ca <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Ca")
All_ASV_bg2g_Ca <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Ca")
#b2g
All_Phy_b2g_Ca <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Ca")
All_Cls_b2g_Ca <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Ca")
All_Ord_b2g_Ca <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Ca")
All_Fam_b2g_Ca <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Ca")
All_Gen_b2g_Ca <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Ca")
All_ASV_b2g_Ca <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Ca")
Ca_hybrid_list <- list(All_Phy_bg2g_Ca, All_Cls_bg2g_Ca, All_Ord_bg2g_Ca, All_Fam_bg2g_Ca, All_Gen_bg2g_Ca, All_ASV_bg2g_Ca)
Ca_geo_list <- list(All_g2g_Ca)
Ca_bio_list <- list(All_Phy_b2g_Ca, All_Cls_b2g_Ca, All_Ord_b2g_Ca, All_Fam_b2g_Ca, All_Gen_b2g_Ca, All_ASV_b2g_Ca)

#Magnesium (Mg).
All_g2g_Mg <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_geo", analyte = "Mg")
All_Phy_bg2g_Mg <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Mg")
All_Cls_bg2g_Mg <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Mg")
All_Ord_bg2g_Mg <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Mg")
All_Fam_bg2g_Mg <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Mg")
All_Gen_bg2g_Mg <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Mg")
All_ASV_bg2g_Mg <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Mg")
#b2g
All_Phy_b2g_Mg <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Mg")
All_Cls_b2g_Mg <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Mg")
All_Ord_b2g_Mg <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Mg")
All_Fam_b2g_Mg <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Mg")
All_Gen_b2g_Mg <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Mg")
All_ASV_b2g_Mg <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Mg")
Mg_hybrid_list <- list(All_Phy_bg2g_Mg, All_Cls_bg2g_Mg, All_Ord_bg2g_Mg, All_Fam_bg2g_Mg, All_Gen_bg2g_Mg, All_ASV_bg2g_Mg)
Mg_geo_list <- list(All_g2g_Mg)
Mg_bio_list <- list(All_Phy_b2g_Mg, All_Cls_b2g_Mg, All_Ord_b2g_Mg, All_Fam_b2g_Mg, All_Gen_b2g_Mg, All_ASV_b2g_Mg)

#Sodium (Na).
All_g2g_Na <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_geo", analyte = "Na")
All_Phy_bg2g_Na <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Na")
All_Cls_bg2g_Na <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Na")
All_Ord_bg2g_Na <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Na")
All_Fam_bg2g_Na <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Na")
All_Gen_bg2g_Na <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Na")
All_ASV_bg2g_Na <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Na")
#b2g
All_Phy_b2g_Na <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Na")
All_Cls_b2g_Na <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Na")
All_Ord_b2g_Na <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Na")
All_Fam_b2g_Na <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Na")
All_Gen_b2g_Na <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Na")
All_ASV_b2g_Na <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Na")
Na_hybrid_list <- list(All_Phy_bg2g_Na, All_Cls_bg2g_Na, All_Ord_bg2g_Na, All_Fam_bg2g_Na, All_Gen_bg2g_Na, All_ASV_bg2g_Na)
Na_geo_list <- list(All_g2g_Na)
Na_bio_list <- list(All_Phy_b2g_Na, All_Cls_b2g_Na, All_Ord_b2g_Na, All_Fam_b2g_Na, All_Gen_b2g_Na, All_ASV_b2g_Na)

#Chlorine (Cl).
All_g2g_Cl <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_geo", analyte = "Cl")
All_Phy_bg2g_Cl <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Cl")
All_Cls_bg2g_Cl <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Cl")
All_Ord_bg2g_Cl <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Cl")
All_Fam_bg2g_Cl <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Cl")
All_Gen_bg2g_Cl <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Cl")
All_ASV_bg2g_Cl <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "Cl")
#b2g
All_Phy_b2g_Cl <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Cl")
All_Cls_b2g_Cl <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Cl")
All_Ord_b2g_Cl <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Cl")
All_Fam_b2g_Cl <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Cl")
All_Gen_b2g_Cl <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Cl")
All_ASV_b2g_Cl <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "Cl")
Cl_hybrid_list <- list(All_Phy_bg2g_Cl, All_Cls_bg2g_Cl, All_Ord_bg2g_Cl, All_Fam_bg2g_Cl, All_Gen_bg2g_Cl, All_ASV_bg2g_Cl)
Cl_geo_list <- list(All_g2g_Cl)
Cl_bio_list <- list(All_Phy_b2g_Cl, All_Cls_b2g_Cl, All_Ord_b2g_Cl, All_Fam_b2g_Cl, All_Gen_b2g_Cl, All_ASV_b2g_Cl)

#pH (pH).
All_g2g_pH <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_geo", analyte = "pH")
All_Phy_bg2g_pH <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "pH")
All_Cls_bg2g_pH <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "pH")
All_Ord_bg2g_pH <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "pH")
All_Fam_bg2g_pH <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "pH")
All_Gen_bg2g_pH <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "pH")
All_ASV_bg2g_pH <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "biogeo_to_geo", analyte = "pH")
#b2g
All_Phy_b2g_pH <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "pH")
All_Cls_b2g_pH <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "pH")
All_Ord_b2g_pH <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "pH")
All_Fam_b2g_pH <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "pH")
All_Gen_b2g_pH <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "pH")
All_ASV_b2g_pH <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "pH")
pH_hybrid_list <- list(All_Phy_bg2g_pH, All_Cls_bg2g_pH, All_Ord_bg2g_pH, All_Fam_bg2g_pH, All_Gen_bg2g_pH, All_ASV_bg2g_pH)
pH_geo_list <- list(All_g2g_pH)
pH_bio_list <- list(All_Phy_b2g_pH, All_Cls_b2g_pH, All_Ord_b2g_pH, All_Fam_b2g_pH, All_Gen_b2g_pH, All_ASV_b2g_pH)

#Additional training and testing sets for other types of comparisons.
All_Phy_b2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NH4")
All_g2b_Crenarchaeota <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "geo_to_bio", analyte = "Crenarchaeota")
All_Gen_b2g_DOC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DOC")
All_Gen_b2g_DTN <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DTN")
All_Fam_b2g_DTN <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DTN")
All_Phy_b2g_DOC <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "DOC")
All_Phy_b2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 2, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NH4")
All_Cls_b2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 3, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NH4")
All_Ord_b2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 4, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NH4")
All_Fam_b2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 5, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NH4")
All_Gen_b2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 6, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NH4")
All_ASV_b2g_NH4 <- make_train_test_set(NP_list = NP_list, taxa_list_num = 7, fire = "All", time_point = "2", biogeo = "bio_to_geo", analyte = "NH4")

```

#MLR_lasso, LOG10 OPTION.
```{r}

MLR_lasso_fit_logOpt <- function(train_test_splits, log10_transform = FALSE, geo_only_set = FALSE, bio_only_set = FALSE, divider_analyte = "pH", rare_bio_thresh = 1, MSE_transform = FALSE, alt_axes = FALSE){
  
#Parameters:
    #train_test_splits (R object): A training / testing dataset split object as generated by make_train_test_set.
    #log10_transform (boolean): Log10 transform the target variable before modeling?
    #geo_only_set (boolean): Is the feature space geo-only? The function needs to know so that it can properly report the number of geo vs. bio variables that are selected.
    #bio_only_set (boolean): Is the feature space bio-only? The function needs to know so that it can properly report the number of geo vs. bio variables that are selected.
    #divider_analyte (string): This generally does not need to be changed. This is how we differentiate which parts of the feature space are bio vs. geo; for pH we can't use pH as the divider index so we have to use something else. The correct usage of this argument is automatically implemented in the code where it needs to happen. Only change this argument in specific cases where you want to model pH in a way that it has not already been modeled in the pipeline.
    #rare_bio_thresh (numeric): The % relative abundance below which one wishes to categorize microbiota as "rare". Default is that anything < 1% relative abundance is rare.
    #MSE_transform (boolean): If TRUE, 10^responses and 10^targets will be computed prior to the calculation of MSE. This is done to convert target variables back into non-log10 space if the log10_transform argument was TRUE. This is generally inadvisable because some outliers will DRAMATICALLY skew the MSE since we are taking 10^responses. The default is to leave MSE in the log10 space.
    #alt_axes (boolean): If TRUE, uses an alternate set of custom axes rather than forcing a square plot with an aspect ratio of 1 (the square axes if the default). This may be useful for examining particular regions of a model fit. Look below in the code for what the new alternate axes will be; one can change those values at that location in the code if desired.
  
#Returns:
    #A list of RMSEs and other information to auto-populate data tables when running many versions of this function. Returned list is as follows: list(train_RMSE, test_RMSE, geo_count, bio_count, rare_biosphere_frac)
    #Multiple plots will be printed (be sure to run the function in the R console, and not the RNotebook, if one wants the plots to end up in the Plots tab of RStudio). Plots: Diagnostic plots for checking normality assumptions, Cross validation scores, coefficient values as a function of lambda (LASSO penalty term), prediction coefficient vs. abunaance plot (if not a geo-only model), training data fit scatter plot, and testing data fit scatter plot.
    #The R console will also print some relevant information such as the coefficient values and the number of each type of variable that were selected (bio, geo, intercept).
  
#Reminder of the order of list items that are returned in the train_test_splits objects.
#return(list(xmat_train, ymat_train, xmat_test, ymat_test, xdf_train, ydf_train, xdf_test, ydf_test, biogeo, trim_sub_NP, analyte, fire, time_point, taxa_list_num))
  
biogeo <- train_test_splits[[9]] #Make a variable of the biogeo type that was used in the train / test split function so that it can be used later in this function.
trim_sub_NP <- train_test_splits[[10]] #Same comment.
analyte <- train_test_splits[[11]] #Same comment.
fire <- train_test_splits[[12]] #Same comment.
time_point <- train_test_splits[[13]] #Same comment.
taxa_list_num <- train_test_splits[[14]] #Same comment.

if (log10_transform == TRUE){
  #Take the log10 of all target values.
  train_test_splits[[2]] <- log10(train_test_splits[[2]]) #ymat_train
  train_test_splits[[4]] <- log10(train_test_splits[[4]]) #ymat_test
  train_test_splits[[6]] <- log10(train_test_splits[[6]]) #ydf_train
  train_test_splits[[8]] <- log10(train_test_splits[[8]]) #ydf_test
}

#Building the MLR lasso model.
lasso.model <- glmnet(train_test_splits[[1]],train_test_splits[[2]],alpha=1) # alpha=1 => lasso
plotres(lasso.model) #Plotting some diagnostics from the training data fit to think about the normality requirements of generalized linear models.

#Investigating the optimal lamba value via cross-validation.
set.seed(2) #This will standardize the initialization of the fold-sets during cross-validation.
cv.out <- cv.glmnet(train_test_splits[[1]],train_test_splits[[2]],alpha=1)
plot(cv.out)
lambda.lasso <- cv.out$lambda.min
lambda.lasso
print(paste("The optimal lambda value was:", lambda.lasso))
print(paste("The optimal log(lambda) value was:", log(lambda.lasso)))

#The fit model's coefficients, response predictions, and calculated MSE (on TESTING data).
predict1 <- predict(lasso.model,s=lambda.lasso,type="coefficient")
responses <- predict(lasso.model,s=lambda.lasso,type="response", newx = train_test_splits[[3]])
#Depending on if the log-transform argument was used or not, we could transform the response values to get back into non-log space (the default is to leave responses and targets in the log10 space, if applicable).
if (MSE_transform == TRUE){
  mse_test <- mean(((10^responses) - (10^train_test_splits[[4]]))^2)
}
if (MSE_transform == FALSE){
  mse_test <- mean((responses - train_test_splits[[4]])^2)
}

#df for the linear model of the predicted value vs. the observed value (TESTING data).
x <- train_test_splits[[8]]
y <- responses
df <- data.frame(x, y) #Make a dataframe.
colnames(df)[1] <- "x" #Need to force the column name so that it is compatible with code later on.

#Generating a dataframe that compares the relative abundance of microbial features with their respective coefficients in the prediction models.
if ((biogeo == "biogeo_to_geo") | (biogeo == "bio_to_geo") | (biogeo == "bio_to_bio")){
  predict1_copy <- data.frame(as.matrix(predict1)) #Getting the coefficients
  if (biogeo == "biogeo_to_geo"){
    bio_covs <- data.frame(cbind(row.names(predict1_copy)[2:(which(rownames(predict1_copy) == divider_analyte)-1)],predict1_copy[2:(which(rownames(predict1_copy) == divider_analyte)-1),])) #Pairing the taxa names with coefficients. Also excluding the geochem coeffs since these will be on a different scale; we're also only interested in bio for these figures.
  } else {
    bio_covs <- data.frame(cbind(row.names(predict1_copy)[2:(length(rownames(predict1_copy)))],predict1_copy[2:(length(rownames(predict1_copy))),]))
  }
  abunds <- data.frame(colMeans(trim_sub_NP)) #Getting the mean relative abundance of each taxa throughout all datapoints in the model.
  abunds$"taxa" <- row.names(abunds)
  abund_covs <- merge(bio_covs, abunds, by.x = "X1", by.y = "taxa")
  row.names(abund_covs) <- abund_covs$X1
  abund_covs <- subset(abund_covs, select = -c(X1) )
  colnames(abund_covs) <- c("Prediction Coefficient", "Relative Abundance")
  abund_covs <- abund_covs[order(-abund_covs$`Relative Abundance`),] #Ordering the dataframe by decreasing relative abundance.
  abund_covs$`Prediction Coefficient` <- as.numeric(abund_covs$`Prediction Coefficient`)
  abund_covs$`Prediction Coefficient` <- abs(abund_covs$`Prediction Coefficient`) #Taking the absolute value of the coefficient; some are negative and some are positive but are just interested in the magnitude here.
  abund_covs$index <- seq(1, dim(abund_covs)[1], 1) #Giving an index number to the rank-ordered relative abundances.
  abund_covs$index <- as.numeric(abund_covs$index)
  abund_covs$`log10relAbund` <- log10(abund_covs$`Relative Abundance`) #For plotting.
  
  ## Plot the coefficients of prediction vs. ranked abundance curve.
  scale_factor <- (max(abund_covs$`log10relAbund`)/max(abund_covs$`Prediction Coefficient`)) #Here we supply a scale factor such that the maximal value from each data series appear at the same height on the 2-y-axis chart.
  print(
    ggplot(abund_covs, aes(x=`index`)) + geom_line( aes(y=`log10relAbund`, colour = "Relative Abundance")) + geom_line(aes(y = `Prediction Coefficient`*scale_factor, colour = "Prediction Coefficient")) + scale_y_continuous(sec.axis = sec_axis(~./scale_factor, name = "abs(Prediction Coefficient)")) +
    theme(axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),  
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14)) +
    theme(panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(),
    panel.background = element_blank(), 
    axis.line = element_line(colour = "black"), 
    strip.background = element_blank(), 
    legend.background = element_blank(), 
    legend.key = element_blank(), 
    panel.border = element_rect(color = "black", fill = NA, size = 1),
    aspect.ratio = 1)
  ) #Note that we have taken the log10() value of relative abundances. This allows us to see in better detail the spread of coefficients as they relate to relative abundance of taxa.
}


#####################################
############ Plotting ###############
#####################################

### Looking at feature selection by lasso. ###
plot(lasso.model, xvar="lambda") #Generates two plots.
print(predict1) #Printing the coefficients.
##############

## Train data ###########
train_responses <- predict(lasso.model,s=lambda.lasso,type="response", newx = train_test_splits[[1]]) #Responses from training data fed to the model trained on said training data.
#Based on the log-option argument, we either need to just take the MSE as-is (no log transform), or we could take 10^responses and 10^targets (log transform) to get back into non-log space. The default is to leave responses and targets in the log10 space, if applicable.
if (MSE_transform == TRUE){
  mse_train <- mean(((10^train_responses) - (10^train_test_splits[[2]]))^2)
}
if (MSE_transform == FALSE){
  mse_train <- mean((train_responses - train_test_splits[[2]])^2)
}

#df for the linear model looking at the fit of the training data to the model learned on said training data.
xTRAIN <- train_test_splits[[6]]
yTRAIN <- train_responses
dfTRAIN <- data.frame(xTRAIN, yTRAIN) #Make a dataframe.
colnames(dfTRAIN)[1] <- "xTRAIN" #Need to force the column name so that it is compatible with code downstream.

###
### Plotting the train data fit. #####
###
#Calculate RMSE from MSE; RMSE is a nice number because it puts the errors in the same unit as the variable that we are trying to predict.
Rmse_train <- sqrt(mse_train)
print(ggplot(dfTRAIN, aes(x = xTRAIN, y = X1)) + 
  geom_point() + 
  theme(axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),  
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14)) +
  geom_abline(slope = 1, intercept = 0, colour = "blue") +
  #xlim(0, NA) + #Controls the limits of the plotted axes; NA means use ggplot default. With log-scale, sometimes there are negative values and so we don't want to miss these by setting the limit to 0.
  #ylim(0, NA) + #Controls the limits of the plotted axes; NA means use ggplot default. With log-scale, sometimes there are negative values and so we don't want to miss these by setting the limit to 0.
  theme(aspect.ratio = 1) + #Enforces a square plot.
  #coord_fixed(ratio = 1) + #Enforces that axes scales are equal (not that the plot is square).
  theme(panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(),
    panel.background = element_blank(), 
    axis.line = element_line(colour = "black"), 
    strip.background = element_blank(), 
    legend.background = element_blank(), 
    legend.key = element_blank(), 
    panel.border = element_rect(color = "black", fill = NA, size = 1)) +
  xlab("Observed") +
  ylab("Predicted") +
  ggtitle(paste("Training RMSE = ", format(round(Rmse_train, 2), nsmall = 2))) +
  theme(plot.title = element_text(size = 12, face = "bold"))
  )
############################

###
## Plotting the test data fit ################
###
if (alt_axes == TRUE){ #If TRUE, focus in on a subset of the data fit when plotting.
  #Calculate RMSE from MSE; RMSE is a nice number because it puts the errors in the same unit as the variable that we are trying to predict.
Rmse_test <- sqrt(mse_test)
print(ggplot(df, aes(x = x, y = X1)) + 
  geom_point() + 
  theme(axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),  
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14)) +
  geom_abline(slope = 1, intercept = 0, colour = "blue") +
  xlim(0, 2.2) + #Controls the limits of the plotted axes; NA means use ggplot default. With log-scale, sometimes there are negative values and so we don't want to miss these by setting the limit to 0.
  ylim(0, 1.8) + #Controls the limits of the plotted axes; NA means use ggplot default. With log-scale, sometimes there are negative values and so we don't want to miss these by setting the limit to 0.
  theme(aspect.ratio = 1) + #Enforces a square plot.
  #coord_fixed(ratio = 1) + #Enforces that axes scales are equal (not that the plot is square).
  theme(panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.line = element_line(colour = "black"),
    strip.background = element_blank(),
    legend.background = element_blank(),
    legend.key = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, size = 1)) +
  xlab("Observed") +
  ylab("Predicted") +
  ggtitle(paste("Testing RMSE = ", format(round(Rmse_test, 2), nsmall = 2))) +
  theme(plot.title = element_text(size = 12, face = "bold"))
  )
} else {
  #Calculate RMSE from MSE; RMSE is a nice number because it puts the errors in the same unit as the variable that we are trying to predict.
Rmse_test <- sqrt(mse_test)
print(ggplot(df, aes(x = x, y = X1)) + 
  geom_point() + 
  theme(axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),  
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14)) +
  geom_abline(slope = 1, intercept = 0, colour = "blue") +
  #xlim(0, NA) + #Controls the limits of the plotted axes; NA means use ggplot default. With log-scale, sometimes there are negative values and so we don't want to miss these by setting the limit to 0.
  #ylim(0, NA) + #Controls the limits of the plotted axes; NA means use ggplot default. With log-scale, sometimes there are negative values and so we don't want to miss these by setting the limit to 0.
  theme(aspect.ratio = 1) + #Enforces a square plot.
  #coord_fixed(ratio = 1) + #Enforces that axes scales are equal (not that the plot is square).
  theme(panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.line = element_line(colour = "black"),
    strip.background = element_blank(),
    legend.background = element_blank(),
    legend.key = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, size = 1)) +
  xlab("Observed") +
  ylab("Predicted") +
  ggtitle(paste("Testing RMSE = ", format(round(Rmse_test, 2), nsmall = 2))) +
  theme(plot.title = element_text(size = 12, face = "bold"))
  )
}
###############################################

###
#Getting the numbers and fractions of bio vs. geo parameters in the model. ########
###

#Using pH to mark the column index where covariates change from biological to geochemical (this is the default function argument); however, for predicting pH (since pH will not be a feature in those models), we need to use "ANC" instead as this marking index where covariates change from bio to geo. This is handled as a alternate argument when calling the prediction function.
if (bio_only_set == TRUE){
  split_index <- NA
} else {
  split_index <- which(rownames(predict1) %in% c(divider_analyte)) #Use 'pH' as a marker variable that denotes the beginning of geochem data in a list of variables.
}

#Subset out the variables by variable type.
if (bio_only_set == TRUE){
  geo_vars <- NA
  intercept_var <- predict1[1:1, ]
  bio_vars <- predict1[2:dim(predict1)[1], ]
  All_model_vars <- predict1
} else {
  geo_vars <- predict1[split_index:dim(predict1)[1], ]
  intercept_var <- predict1[1:1, ]
  bio_vars <- predict1[2:(split_index - 1), ]
  All_model_vars <- predict1
}

#Enforce dataframe structure.
geo_vars <- data.frame(as.matrix(geo_vars))
intercept_var <- data.frame(as.matrix(intercept_var))
bio_vars <- data.frame(as.matrix(bio_vars))
All_model_vars <- data.frame(as.matrix(All_model_vars))

#Function to get the number of non-zero coefficients from a dataframe of coefficients.
get_coef_count <- function(prediction_coefs){
  count <- 0
  for (i in 1:dim(prediction_coefs)[1]){
    if (prediction_coefs[i,1] != 0){
      count <- count + 1
    }
  }
  return(count)
}

#Get the counts of each variable type that are selected by the model.
if (bio_only_set == TRUE){
  geo_count <- 0
} else {
  geo_count <- get_coef_count(geo_vars)
}
intercept_count <- get_coef_count(intercept_var)
bio_count <- get_coef_count(bio_vars)

#If a geochem only dataset, set the bio count to 0 (the count will still be correct for geo and intercept).
if (geo_only_set == TRUE){
  bio_count <- 0
}

#Print the numbers of variables from each variable type used by the learned model.
print(paste("Numbers of variables selected in the model:", geo_count,"geochemical terms,", bio_count,"biological terms, and", intercept_count,"intercept term."))

##########################################################################################

### Getting the fractions of eASVs, ASVs, and geochem variables that end up as coefficients in the model ###
if (taxa_list_num == 7){
  coef_df <- predict1
  coef_df <- data.frame(as.matrix(coef_df))
  eASV_count <- 0
  ASV_count <- 0
  intercept_count <- 0
  geochem_count <- 0
  for (i in 1:dim(coef_df)[1]){
    if ((substring(row.names(coef_df)[i], 1, 4) == 'eASV') & (coef_df[i,1] != 0)){
      eASV_count <- eASV_count + 1
    } else if ((substring(row.names(coef_df)[i], 1, 3) == 'ASV') & (coef_df[i,1] != 0)){
      ASV_count <- ASV_count + 1
    } else if ((substring(row.names(coef_df)[i], 1, 1) == '(') & (coef_df[i,1] != 0)){
      intercept_count <- intercept_count + 1
    } else if (((substring(row.names(coef_df)[i], 1, 4) != 'eASV') | (substring(row.names(coef_df)[i], 1, 3) != 'ASV') | (substring(row.names(coef_df)[i], 1, 1) != '(')) & (coef_df[i,1] != 0)){
      geochem_count <- geochem_count + 1
    }
  }
  tot_coefs <- colSums(coef_df != 0)[[1]]
  print(paste0("There are ",eASV_count," eASVs, ",ASV_count," ASVs, ",intercept_count," intercept, and ",geochem_count," geochemistry terms in the model. There were ",tot_coefs," features in total that were used for predictions."))
}
###########################################################################################################

print(paste0("The training RMSE is ",Rmse_train,", and the testing RMSE is ",Rmse_test,"."))

#Tabulate the ratio of biological terms that come from the rare biosphere. The 'rare biosphere' can be user defined in the function, though the default is <1 (meaning less than 1% relative abundance across the total dataset).
rare_biosphere_frac <- NA #Set this ratio to NA so that it is the default output for models that do not have any bio data; models that DO have bio data will be shunted into the below if statement.
if ((biogeo == "biogeo_to_geo") | (biogeo == "bio_to_geo") | (biogeo == "bio_to_bio")){
  abund_covs_subset <- abund_covs[ which(abund_covs$'Prediction Coefficient'!=0 & abund_covs$'Relative Abundance' < rare_bio_thresh), ]
  rare_biosphere_frac <- dim(abund_covs_subset)[1]/bio_count
  print(paste0("The fraction of selected taxa that are rare is ",rare_biosphere_frac,"."))
}

#Explicitly name / create some variables that can be returned by the function for downstream applications.
train_RMSE <- Rmse_train
test_RMSE <- Rmse_test
num_covs <- bio_count + geo_count
bio_cov_frac <- bio_count/num_covs

#Return a list of information that can be used to automate the population of a data table across analytes and model types.
return(list(train_RMSE, test_RMSE, geo_count, bio_count, rare_biosphere_frac))

}

```

#Simple, one-taxa relative abundance vs. analyte of interest plots.
```{r}

#Phylum set.
#Combine the train / test sets so that we have all of the data for regression.
set_of_interest <- All_Phy_bg2g_NH4
bound_sets_X <- rbind(set_of_interest[[5]], set_of_interest[[7]])
set1_Y <- data.frame(set_of_interest[[6]]) #Get the ydf from training data.
set2_Y <- data.frame(set_of_interest[[8]]) #Get the ydf from testing data.
colnames(set1_Y) <- c("target") #Make the column names the same so that we can rbind them.
colnames(set2_Y) <- c("target") #Make the column names the same so that we can rbind them.
bound_sets_Y <- rbind(set1_Y, set2_Y) #Bind rows.
bound_sets_XY <- data.frame(cbind(bound_sets_X, bound_sets_Y)) #Put features and targets into one dataframe.

#Family set.
#Combine the train / test sets so that we have all of the data for regression.
set_of_interest <- All_Fam_bg2g_NH4
bound_sets_X <- rbind(set_of_interest[[5]], set_of_interest[[7]])
set1_Y <- data.frame(set_of_interest[[6]]) #Get the ydf from training data.
set2_Y <- data.frame(set_of_interest[[8]]) #Get the ydf from testing data.
colnames(set1_Y) <- c("target") #Make the column names the same so that we can rbind them.
colnames(set2_Y) <- c("target") #Make the column names the same so that we can rbind them.
bound_sets_Y <- rbind(set1_Y, set2_Y) #Bind rows.
bound_sets_XY_2 <- data.frame(cbind(bound_sets_X, bound_sets_Y)) #Put features and targets into one dataframe. Note the _2 since this is the second df of this kind.

#Phylum set.
#Plot w/ ammonium.
Crens_lm <- lm(log10(target) ~ Crenarchaeota, data = bound_sets_XY) #Linear regression of y vs. x.
Crens_lm_rmse <- sqrt(mean((Crens_lm$residuals)^2)) #Compute the RMSE of the linear fit.
print(ggplot(bound_sets_XY, aes(x = Crenarchaeota, y = log10(target))) + #Note that, here, 'target' = NH4.
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) + #Plot the linear fit.
  theme(axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),  
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14)) +
  #xlim(0, NA) + #Controls the limits of the plotted axes; NA means use ggplot default. With log-scale, sometimes there are negative values and so we don't want to miss these by setting the limit to 0.
  #ylim(0, NA) + #Controls the limits of the plotted axes; NA means use ggplot default. With log-scale, sometimes there are negative values and so we don't want to miss these by setting the limit to 0.
  #coord_fixed(ratio = 1) +
  theme(panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.line = element_line(colour = "black"),
    strip.background = element_blank(),
    legend.background = element_blank(),
    legend.key = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, size = 1)) +
  xlab("Crenarchaeota Relative Abundance") +
  ylab("log10(NH4)") +
  ggtitle(paste("RMSE = ", format(round(Crens_lm_rmse, 2), nsmall = 2))) + #Add the linear fit RMSE as a title.
  theme(plot.title = element_text(size = 12, face = "bold"))
  )

# #Phyla set.
# #Plot w/ ammonia (via Henderson-Hasselbalch conversion).
# pH_vector <- bound_sets_XY$pH #Get the pHs
# calculated_NH3 <- ((10^(-9.3)*bound_sets_XY$target)/(10^(-pH_vector))) #Use Henderson-Hasselbalch to determine NH3 from NH4+.
# bound_sets_XY_copy <- bound_sets_XY #Make a copy to play with so that we don't change the df used for other plots.
# bound_sets_XY_copy$target <- calculated_NH3 #Swap out the NH4+ concentrations for the calculated NH3 concentrations.
# print(ggplot(bound_sets_XY_copy, aes(x = Crenarchaeota, y = log10(target))) + #Note that, here, 'target' = NH3.
#   geom_point() + 
#   theme(axis.text.x = element_text(size = 14),
#         axis.text.y = element_text(size = 14),  
#         axis.title.x = element_text(size = 14),
#         axis.title.y = element_text(size = 14)) +
#   #xlim(0, NA) + #Controls the limits of the plotted axes; NA means use ggplot default. With log-scale, sometimes there are negative values and so we don't want to miss these by setting the limit to 0.
#   #ylim(0, NA) + #Controls the limits of the plotted axes; NA means use ggplot default. With log-scale, sometimes there are negative values and so we don't want to miss these by setting the limit to 0.
#   #coord_fixed(ratio = 1) +
#   theme(panel.grid.major = element_blank(),
#     panel.grid.minor = element_blank(),
#     panel.background = element_blank(),
#     axis.line = element_line(colour = "black"),
#     strip.background = element_blank(),
#     legend.background = element_blank(),
#     legend.key = element_blank(),
#     panel.border = element_rect(color = "black", fill = NA, size = 1)) +
#   xlab("Crenarchaeota Relative Abundance") +
#   ylab("log10(NH3)")
#   )

#Family set.
#Plot w/ ammonium.
Nitros_lm <- lm(log10(target) ~ Nitrosomonadaceae, data = bound_sets_XY_2) #Linear regression of y vs. x.
Nitros_lm_rmse <- sqrt(mean((Nitros_lm$residuals)^2)) #Compute the RMSE of the linear fit.
print(ggplot(bound_sets_XY_2, aes(x = Nitrosomonadaceae, y = log10(target))) + #Note that, here, 'target' = NH4.
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) + #Plot the linear fit.
  theme(axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),  
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14)) +
  #xlim(0, NA) + #Controls the limits of the plotted axes; NA means use ggplot default. With log-scale, sometimes there are negative values and so we don't want to miss these by setting the limit to 0.
  #ylim(0, NA) + #Controls the limits of the plotted axes; NA means use ggplot default. With log-scale, sometimes there are negative values and so we don't want to miss these by setting the limit to 0.
  #coord_fixed(ratio = 1) +
  theme(panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.line = element_line(colour = "black"),
    strip.background = element_blank(),
    legend.background = element_blank(),
    legend.key = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, size = 1)) +
  xlab("Nitrosomonadaceae Relative Abundance") +
  ylab("log10(NH4)") +
  ggtitle(paste("RMSE = ", format(round(Nitros_lm_rmse, 2), nsmall = 2))) + #Add the linear fit RMSE as a title.
  theme(plot.title = element_text(size = 12, face = "bold"))
  )

```

#Running models for publication of the lasso MLR model.
```{r}
######
#Run each of these functions in the RConsole individually to enable export as PDF.
######

#DOC
MLR_lasso_fit_logOpt(All_g2g_DOC, log10_transform = TRUE, geo_only_set = TRUE)
MLR_lasso_fit_logOpt(All_Gen_bg2g_DOC, log10_transform = TRUE, geo_only_set = FALSE)
MLR_lasso_fit_logOpt(All_Gen_bg2g_DOC_top10, log10_transform = TRUE, geo_only_set = FALSE) #Again, running the Genus hybrid model, but this time only considering top-10 taxa.
MLR_lasso_fit_logOpt(All_Gen_bg2g_DOC_NOTtop10, log10_transform = TRUE, geo_only_set = FALSE) #Again, running the Genus hybrid model, but this time only considering !top-10 taxa.
MLR_lasso_fit_logOpt(All_Gen_b2g_DOC, log10_transform = TRUE, geo_only_set = FALSE, bio_only_set = TRUE) #Running the bio-only model.
#Make a table of model outputs across different train/test splits (bg2g).
DOC_pred_table_bg2g <- data.frame()
for (i in seq(1, 10, length.out = 10)){
  pred_object <- MLR_lasso_fit_logOpt(DOC_sets_bg2g[[i]], log10_transform = TRUE, geo_only_set = FALSE, bio_only_set = FALSE)
  for (j in seq(1, 5, length.out = 5)){
    DOC_pred_table_bg2g[i,j] <- pred_object[[j]]
  }
}
colnames(DOC_pred_table_bg2g) <- c("train_RMSE", "test_RMSE", "geo_count", "bio_count", "rare_biosphere_frac")
DOC_pred_table_bg2g["median",] <- colMedians(as.matrix(DOC_pred_table_bg2g))
#Make a table of model outputs across different train/test splits (top10_bg2g).
DOC_pred_table_top10_bg2g <- data.frame()
for (i in seq(1, 10, length.out = 10)){
  pred_object <- MLR_lasso_fit_logOpt(DOC_sets_top10_bg2g[[i]], log10_transform = TRUE, geo_only_set = FALSE, bio_only_set = FALSE)
  for (j in seq(1, 5, length.out = 5)){
    DOC_pred_table_top10_bg2g[i,j] <- pred_object[[j]]
  }
}
colnames(DOC_pred_table_top10_bg2g) <- c("train_RMSE", "test_RMSE", "geo_count", "bio_count", "rare_biosphere_frac")
DOC_pred_table_top10_bg2g["median",] <- colMedians(as.matrix(DOC_pred_table_top10_bg2g))
#Make a table of model outputs across different train/test splits (g2g).
DOC_pred_table_g2g <- data.frame()
for (i in seq(1, 10, length.out = 10)){
  pred_object <- MLR_lasso_fit_logOpt(DOC_sets_g2g[[i]], log10_transform = TRUE, geo_only_set = TRUE, bio_only_set = FALSE)
  for (j in seq(1, 5, length.out = 5)){
    DOC_pred_table_g2g[i,j] <- pred_object[[j]]
  }
}
colnames(DOC_pred_table_g2g) <- c("train_RMSE", "test_RMSE", "geo_count", "bio_count", "rare_biosphere_frac")
DOC_pred_table_g2g["median",] <- colMedians(as.matrix(DOC_pred_table_g2g))
#Make a table of model outputs across different train/test splits (b2g).
DOC_pred_table_b2g <- data.frame()
for (i in seq(1, 10, length.out = 10)){
  pred_object <- MLR_lasso_fit_logOpt(DOC_sets_b2g[[i]], log10_transform = TRUE, geo_only_set = FALSE, bio_only_set = TRUE)
  for (j in seq(1, 5, length.out = 5)){
    DOC_pred_table_b2g[i,j] <- pred_object[[j]]
  }
}
colnames(DOC_pred_table_b2g) <- c("train_RMSE", "test_RMSE", "geo_count", "bio_count", "rare_biosphere_frac")
DOC_pred_table_b2g["median",] <- colMedians(as.matrix(DOC_pred_table_b2g))

#DTN
MLR_lasso_fit_logOpt(All_g2g_DTN, log10_transform = TRUE, geo_only_set = TRUE)
MLR_lasso_fit_logOpt(All_Gen_bg2g_DTN, log10_transform = TRUE, geo_only_set = FALSE)
MLR_lasso_fit_logOpt(All_Gen_bg2g_DTN_top10, log10_transform = TRUE, geo_only_set = FALSE) #Again, running the Genus hybrid model, but this time only considering top-10 taxa.
MLR_lasso_fit_logOpt(All_Gen_bg2g_DTN_NOTtop10, log10_transform = TRUE, geo_only_set = FALSE) #Again, running the Genus hybrid model, but this time only considering !top-10 taxa.
MLR_lasso_fit_logOpt(All_Gen_b2g_DTN, log10_transform = TRUE, geo_only_set = FALSE, bio_only_set = TRUE) #Running the bio-only model.
MLR_lasso_fit_logOpt(All_Gen_b2g_DTN, log10_transform = TRUE, geo_only_set = FALSE, bio_only_set = TRUE, alt_axes = TRUE) #Running the bio-only model again, but this time the testing data plot will focus in on the area without outliers (for inset in the manuscript).
#Make a table of model outputs across different train/test splits (bg2g).
DTN_pred_table_bg2g <- data.frame()
for (i in seq(1, 10, length.out = 10)){
  pred_object <- MLR_lasso_fit_logOpt(DTN_sets_bg2g[[i]], log10_transform = TRUE, geo_only_set = FALSE, bio_only_set = FALSE)
  for (j in seq(1, 5, length.out = 5)){
    DTN_pred_table_bg2g[i,j] <- pred_object[[j]]
  }
}
colnames(DTN_pred_table_bg2g) <- c("train_RMSE", "test_RMSE", "geo_count", "bio_count", "rare_biosphere_frac")
DTN_pred_table_bg2g["median",] <- colMedians(as.matrix(DTN_pred_table_bg2g))
#Make a table of model outputs across different train/test splits (top10_bg2g).
DTN_pred_table_top10_bg2g <- data.frame()
for (i in seq(1, 10, length.out = 10)){
  pred_object <- MLR_lasso_fit_logOpt(DTN_sets_top10_bg2g[[i]], log10_transform = TRUE, geo_only_set = FALSE, bio_only_set = FALSE)
  for (j in seq(1, 5, length.out = 5)){
    DTN_pred_table_top10_bg2g[i,j] <- pred_object[[j]]
  }
}
colnames(DTN_pred_table_top10_bg2g) <- c("train_RMSE", "test_RMSE", "geo_count", "bio_count", "rare_biosphere_frac")
DTN_pred_table_top10_bg2g["median",] <- colMedians(as.matrix(DTN_pred_table_top10_bg2g))
#Make a table of model outputs across different train/test splits (g2g).
DTN_pred_table_g2g <- data.frame()
for (i in seq(1, 10, length.out = 10)){
  pred_object <- MLR_lasso_fit_logOpt(DTN_sets_g2g[[i]], log10_transform = TRUE, geo_only_set = TRUE, bio_only_set = FALSE)
  for (j in seq(1, 5, length.out = 5)){
    DTN_pred_table_g2g[i,j] <- pred_object[[j]]
  }
}
colnames(DTN_pred_table_g2g) <- c("train_RMSE", "test_RMSE", "geo_count", "bio_count", "rare_biosphere_frac")
DTN_pred_table_g2g["median",] <- colMedians(as.matrix(DTN_pred_table_g2g))
#Make a table of model outputs across different train/test splits (b2g).
DTN_pred_table_b2g <- data.frame()
for (i in seq(1, 10, length.out = 10)){
  pred_object <- MLR_lasso_fit_logOpt(DTN_sets_b2g[[i]], log10_transform = TRUE, geo_only_set = FALSE, bio_only_set = TRUE)
  for (j in seq(1, 5, length.out = 5)){
    DTN_pred_table_b2g[i,j] <- pred_object[[j]]
  }
}
colnames(DTN_pred_table_b2g) <- c("train_RMSE", "test_RMSE", "geo_count", "bio_count", "rare_biosphere_frac")
DTN_pred_table_b2g["median",] <- colMedians(as.matrix(DTN_pred_table_b2g))

#Making a publication table of median model outputs across the 10 different train / test splits at the Genus taxonomic rank. 47.37% of all reads from the study have taxonomy assigned at the Genus rank.
prediction_metric_medians <- DOC_pred_table_g2g[11,]
#prediction_metric_medians[2,] <- DOC_pred_table_top10_bg2g[11,]
prediction_metric_medians[2,] <- DOC_pred_table_bg2g[11,]
prediction_metric_medians[3,] <- DOC_pred_table_b2g[11,]
prediction_metric_medians[4,] <- DTN_pred_table_g2g[11,]
#prediction_metric_medians[6,] <- DTN_pred_table_top10_bg2g[11,]
prediction_metric_medians[5,] <- DTN_pred_table_bg2g[11,]
prediction_metric_medians[6,] <- DTN_pred_table_b2g[11,]
row.names(prediction_metric_medians) <- c("DOC_g2g", "DOC_bg2g", "DOC_b2g", "DTN_g2g", "DTN_bg2g", "DTN_b2g")
xtable(prediction_metric_medians) #Export to LaTex.

```

#Generating a data table of various predictions using a loop.
```{r, include=FALSE}
#List of model lists for various analytes.
analyte_hybridModel_list <- list(DTN_hybrid_list, DOC_hybrid_list, ANC_hybrid_list, PO4_hybrid_list, SO4_hybrid_list, K_hybrid_list, NH4_hybrid_list, NO3_hybrid_list, Ca_hybrid_list, Mg_hybrid_list, Na_hybrid_list, Cl_hybrid_list)
analyte_geoModel_list <- list(DTN_geo_list, DOC_geo_list, ANC_geo_list, PO4_geo_list, SO4_geo_list, K_geo_list, NH4_geo_list, NO3_geo_list, Ca_geo_list, Mg_geo_list, Na_geo_list, Cl_geo_list)
analyte_bioModel_list <- list(DTN_bio_list, DOC_bio_list, ANC_bio_list, PO4_bio_list, SO4_bio_list, K_bio_list, NH4_bio_list, NO3_bio_list, Ca_bio_list, Mg_bio_list, Na_bio_list, Cl_bio_list)

row_strings_hybrid <- c("DTN", "DOC", "ANC", "PO4", "SO4", "K", "NH4", "NO3", "Ca", "Mg", "Na", "Cl")
row_strings_geo <- c("DTN", "DOC", "ANC", "PO4", "SO4", "K", "NH4", "NO3", "Ca", "Mg", "Na", "Cl")
row_strings_bio <- c("DTN", "DOC", "ANC", "PO4", "SO4", "K", "NH4", "NO3", "Ca", "Mg", "Na", "Cl")
col_strings_hybrid <- c("Phylum_train_RMSE", "Phylum_test_RMSE", "Phylum_geo_count", "Phylum_bio_count", "Phylum_rare_biosphere_frac", "Class_train_RMSE", "Class_test_RMSE", "Class_geo_count", "Class_bio_count", "Class_rare_biosphere_frac", "Order_train_RMSE", "Order_test_RMSE", "Order_geo_count", "Order_bio_count", "Order_rare_biosphere_frac", "Family_train_RMSE", "Family_test_RMSE", "Family_geo_count", "Family_bio_count", "Family_rare_biosphere_frac", "Genus_train_RMSE", "Genus_test_RMSE", "Genus_geo_count", "Genus_bio_count", "Genus_rare_biosphere_frac", "ASV_train_RMSE", "ASV_test_RMSE", "ASV_geo_count", "ASV_bio_count", "ASV_rare_biosphere_frac")
col_strings_geo <- c("Geo_train_RMSE", "Geo_test_RMSE", "Geo_geo_count", "Geo_bio_count", "Geo_rare_biosphere_frac")
col_strings_bio <- c("Phylum_train_RMSE", "Phylum_test_RMSE", "Phylum_geo_count", "Phylum_bio_count", "Phylum_rare_biosphere_frac", "Class_train_RMSE", "Class_test_RMSE", "Class_geo_count", "Class_bio_count", "Class_rare_biosphere_frac", "Order_train_RMSE", "Order_test_RMSE", "Order_geo_count", "Order_bio_count", "Order_rare_biosphere_frac", "Family_train_RMSE", "Family_test_RMSE", "Family_geo_count", "Family_bio_count", "Family_rare_biosphere_frac", "Genus_train_RMSE", "Genus_test_RMSE", "Genus_geo_count", "Genus_bio_count", "Genus_rare_biosphere_frac", "ASV_train_RMSE", "ASV_test_RMSE", "ASV_geo_count", "ASV_bio_count", "ASV_rare_biosphere_frac")

generate_hybridMod_df <- function(analyte_model_list){
  #Create the analyte-model data table through iteration.
  analyte_model_df <- data.frame() #Initialize an empty dataframe.
  row_counter <- 1 #Initialize a counter for indexing in the table.
  
  for (i in analyte_model_list){
    col_counter <- 1 #Initialize a counter for indexing in the table.
    for (j in i){
      model_outputs <- MLR_lasso_fit_logOpt(j, log10_transform = TRUE, geo_only_set = FALSE)
      out1 <- as.numeric(model_outputs[[1]])
      out2 <- as.numeric(model_outputs[[2]])
      out3 <- as.numeric(model_outputs[[3]])
      out4 <- as.numeric(model_outputs[[4]])
      out5 <- as.numeric(model_outputs[[5]])
      analyte_model_df[row_counter, col_counter + 0] <- out1
      analyte_model_df[row_counter, col_counter + 1] <- out2
      analyte_model_df[row_counter, col_counter + 2] <- out3
      analyte_model_df[row_counter, col_counter + 3] <- out4
      analyte_model_df[row_counter, col_counter + 4] <- out5
      col_counter <- col_counter + 5
    }
    row_counter <- row_counter + 1
  }
  return(analyte_model_df)
}

#Same function as above, but with one modification for pH since the way that we determine indexes needs to change (solved via a different argument in the actual modeling function).
generate_hybridMod_df_pHspecial <- function(analyte_model_list){
  #Create the analyte-model data table through iteration.
  analyte_model_df <- data.frame() #Initialize an empty dataframe.
  row_counter <- 1 #Initialize a counter for indexing in the table.
  
  for (i in analyte_model_list){
    col_counter <- 1 #Initialize a counter for indexing in the table.
    for (j in i){
      model_outputs <- MLR_lasso_fit_logOpt(j, log10_transform = FALSE, geo_only_set = FALSE, divider_analyte = "ANC")
      out1 <- as.numeric(model_outputs[[1]])
      out2 <- as.numeric(model_outputs[[2]])
      out3 <- as.numeric(model_outputs[[3]])
      out4 <- as.numeric(model_outputs[[4]])
      out5 <- as.numeric(model_outputs[[5]])
      analyte_model_df[row_counter, col_counter + 0] <- out1
      analyte_model_df[row_counter, col_counter + 1] <- out2
      analyte_model_df[row_counter, col_counter + 2] <- out3
      analyte_model_df[row_counter, col_counter + 3] <- out4
      analyte_model_df[row_counter, col_counter + 4] <- out5
      col_counter <- col_counter + 5
    }
    row_counter <- row_counter + 1
  }
  return(analyte_model_df)
}

generate_geoMod_df <- function(analyte_model_list){
  #Create the analyte-model data table through iteration.
  analyte_model_df <- data.frame() #Initialize an empty dataframe.
  row_counter <- 1 #Initialize a counter for indexing in the table.
  
  for (i in analyte_model_list){
    col_counter <- 1 #Initialize a counter for indexing in the table.
    for (j in i){
      model_outputs <- MLR_lasso_fit_logOpt(j, log10_transform = TRUE, geo_only_set = TRUE)
      out1 <- as.numeric(model_outputs[[1]])
      out2 <- as.numeric(model_outputs[[2]])
      out3 <- as.numeric(model_outputs[[3]])
      out4 <- as.numeric(model_outputs[[4]])
      out5 <- as.numeric(model_outputs[[5]])
      analyte_model_df[row_counter, col_counter + 0] <- out1
      analyte_model_df[row_counter, col_counter + 1] <- out2
      analyte_model_df[row_counter, col_counter + 2] <- out3
      analyte_model_df[row_counter, col_counter + 3] <- out4
      analyte_model_df[row_counter, col_counter + 4] <- out5
      col_counter <- col_counter + 5
    }
    row_counter <- row_counter + 1
  }
  return(analyte_model_df)
}

#Same function as above, but with one modification for pH since the way that we determine indexes needs to change (solved via a different argument in the actual modeling function).
generate_geoMod_df_pHspecial <- function(analyte_model_list){
  #Create the analyte-model data table through iteration.
  analyte_model_df <- data.frame() #Initialize an empty dataframe.
  row_counter <- 1 #Initialize a counter for indexing in the table.
  
  for (i in analyte_model_list){
    col_counter <- 1 #Initialize a counter for indexing in the table.
    for (j in i){
      model_outputs <- MLR_lasso_fit_logOpt(j, log10_transform = FALSE, geo_only_set = TRUE, divider_analyte = "ANC")
      out1 <- as.numeric(model_outputs[[1]])
      out2 <- as.numeric(model_outputs[[2]])
      out3 <- as.numeric(model_outputs[[3]])
      out4 <- as.numeric(model_outputs[[4]])
      out5 <- as.numeric(model_outputs[[5]])
      analyte_model_df[row_counter, col_counter + 0] <- out1
      analyte_model_df[row_counter, col_counter + 1] <- out2
      analyte_model_df[row_counter, col_counter + 2] <- out3
      analyte_model_df[row_counter, col_counter + 3] <- out4
      analyte_model_df[row_counter, col_counter + 4] <- out5
      col_counter <- col_counter + 5
    }
    row_counter <- row_counter + 1
  }
  return(analyte_model_df)
}

generate_bioMod_df <- function(analyte_model_list){
  #Create the analyte-model data table through iteration.
  analyte_model_df <- data.frame() #Initialize an empty dataframe.
  row_counter <- 1 #Initialize a counter for indexing in the table.
  
  for (i in analyte_model_list){
    col_counter <- 1 #Initialize a counter for indexing in the table.
    for (j in i){
      model_outputs <- MLR_lasso_fit_logOpt(j, log10_transform = TRUE, geo_only_set = FALSE, bio_only_set = TRUE)
      out1 <- as.numeric(model_outputs[[1]])
      out2 <- as.numeric(model_outputs[[2]])
      out3 <- as.numeric(model_outputs[[3]])
      out4 <- as.numeric(model_outputs[[4]])
      out5 <- as.numeric(model_outputs[[5]])
      analyte_model_df[row_counter, col_counter + 0] <- out1
      analyte_model_df[row_counter, col_counter + 1] <- out2
      analyte_model_df[row_counter, col_counter + 2] <- out3
      analyte_model_df[row_counter, col_counter + 3] <- out4
      analyte_model_df[row_counter, col_counter + 4] <- out5
      col_counter <- col_counter + 5
    }
    row_counter <- row_counter + 1
  }
  return(analyte_model_df)
}

#Same function as above, but with one modification for pH since the way that we determine indexes needs to change (solved via a different argument in the actual modeling function).
generate_bioMod_df_pHspecial <- function(analyte_model_list){
  #Create the analyte-model data table through iteration.
  analyte_model_df <- data.frame() #Initialize an empty dataframe.
  row_counter <- 1 #Initialize a counter for indexing in the table.
  
  for (i in analyte_model_list){
    col_counter <- 1 #Initialize a counter for indexing in the table.
    for (j in i){
      model_outputs <- MLR_lasso_fit_logOpt(j, log10_transform = FALSE, geo_only_set = FALSE, bio_only_set = TRUE, divider_analyte = "ANC")
      out1 <- as.numeric(model_outputs[[1]])
      out2 <- as.numeric(model_outputs[[2]])
      out3 <- as.numeric(model_outputs[[3]])
      out4 <- as.numeric(model_outputs[[4]])
      out5 <- as.numeric(model_outputs[[5]])
      analyte_model_df[row_counter, col_counter + 0] <- out1
      analyte_model_df[row_counter, col_counter + 1] <- out2
      analyte_model_df[row_counter, col_counter + 2] <- out3
      analyte_model_df[row_counter, col_counter + 3] <- out4
      analyte_model_df[row_counter, col_counter + 4] <- out5
      col_counter <- col_counter + 5
    }
    row_counter <- row_counter + 1
  }
  return(analyte_model_df)
}

#Generate dataframes with model results.
hybrid_models_df <- generate_hybridMod_df(analyte_hybridModel_list) #Hybrid models.
geo_models_df <- generate_geoMod_df(analyte_geoModel_list) #Geo-only models.
bio_models_df <- generate_bioMod_df(analyte_bioModel_list) #Bio models.
row.names(hybrid_models_df) <- row_strings_hybrid #Name rows on the dataframe.
colnames(hybrid_models_df) <- col_strings_hybrid #Name columns on the dataframe.
row.names(geo_models_df) <- row_strings_geo #Name rows on the dataframe.
colnames(geo_models_df) <- col_strings_geo #Name columns on the dataframe.
row.names(bio_models_df) <- row_strings_bio #Name rows on the dataframe.
colnames(bio_models_df) <- col_strings_bio #Name columns on the dataframe.
#Generate special dataframe with pH model results.
hybrid_models_df_pH <- generate_hybridMod_df_pHspecial(list(pH_hybrid_list)) #Hybrid models.
geo_models_df_pH <- generate_geoMod_df_pHspecial(list(pH_geo_list)) #Geo-only models.
bio_models_df_pH <- generate_bioMod_df_pHspecial(list(pH_bio_list)) #Bio models.
row.names(hybrid_models_df_pH) <- c("pH") #Name rows on the dataframe.
colnames(hybrid_models_df_pH) <- col_strings_hybrid #Name columns on the dataframe.
row.names(geo_models_df_pH) <- c("pH") #Name rows on the dataframe.
colnames(geo_models_df_pH) <- col_strings_geo #Name columns on the dataframe.
row.names(bio_models_df_pH) <- c("pH") #Name rows on the dataframe.
colnames(bio_models_df_pH) <- col_strings_bio #Name columns on the dataframe.

#Combine the geo-only, hybrid model, and bio model dataframes. Recall that these were computed separately since the total number of covariates used are calculated differently between the model types.
all_models_df <- cbind(geo_models_df, hybrid_models_df, bio_models_df)
pH_models_df <- cbind(geo_models_df_pH, hybrid_models_df_pH, bio_models_df_pH) #Column-binding the special pH table as well. Recall that the pH table had to be made separately because of the way that indexing covariates is calculated (see modeling function arguments).
all_models_df <- rbind(all_models_df, pH_models_df) #Finally, row-bind the special pH dataframe to the main dataframe to make the final dataframe with all variables.

#Breaking the total dataframe down into sub dataframes. This is useful for making tables in LaTex.
mods1 <- all_models_df[,1:5]
mods2 <- all_models_df[,6:10]
mods3 <- all_models_df[,11:15]
mods4 <- all_models_df[,16:20]
mods5 <- all_models_df[,21:25]
mods6 <- all_models_df[,26:30]
mods7 <- all_models_df[,31:35]
mods8 <- all_models_df[,36:40]
mods9 <- all_models_df[,41:45]
mods10 <- all_models_df[,46:50]
mods11 <- all_models_df[,51:55]
mods12 <- all_models_df[,56:60]
mods13 <- all_models_df[,61:65]

#Running the below lines individually in the console will produce LaTex code that can be used to make nice tables.
#Note: Additional modifications are done in LaTex to make these tables look nice. e.g., the removal of redundant column names for the same kind of model metric, the removal of extra hlines, renaming of columns, addition of N.A. characters, addition of a rotated box as a label, things like that. Refer to the working example in Overleaf for the modifications that need to be done.
xtable(mods1, digits=c(0,2,2,0,0,2)) #Geo-only
xtable(mods2, digits=c(0,2,2,0,0,2)) #Phylum hybrid
xtable(mods3, digits=c(0,2,2,0,0,2)) #Class hybrid
xtable(mods4, digits=c(0,2,2,0,0,2)) #Order hybrid
xtable(mods5, digits=c(0,2,2,0,0,2)) #Family hybrid
xtable(mods6, digits=c(0,2,2,0,0,2)) #Genus hybrid
xtable(mods7, digits=c(0,2,2,0,0,2)) #ASV hybrid
xtable(mods8, digits=c(0,2,2,0,0,2)) #Phylum bio
xtable(mods9, digits=c(0,2,2,0,0,2)) #Class bio
xtable(mods10, digits=c(0,2,2,0,0,2)) #Order bio
xtable(mods11, digits=c(0,2,2,0,0,2)) #Family bio
xtable(mods12, digits=c(0,2,2,0,0,2)) #Genus bio
xtable(mods13, digits=c(0,2,2,0,0,2)) #ASV bio

#NOTE* The random seed used to generate train / test datasets will always change the modeling outcome. Further, the random seed used to determine the initial cross-validated folds during model cross-validation will, similarly, change the model outcomes. Model outcomes should be considered for their aggregate behavior, and not the SPECIFIC numeric behavior of any one model for any one analyte. In this study, we have standardized all of our random seeds for reproducibilty. We also report on the effects of different random training and testing data splits in the manuscript.

```

#PCA regression w/ LASSO penalty on ALL data (YES train/test splits); LOG10 OPTION.
```{r}

PCA_lasso_fit_logOpt <- function(train_test_splits, log10_transform = FALSE, center_scale = TRUE, MSE_transform = FALSE){
  
#Parameters:
    #train_test_splits (R object): An R object that is a list of training and testing data sets / objects, as generated by make_train_test_set() earlier in the pipeline.
    #log10_transform (boolean): Log10 transform the target variable prior to modeling?
    #center_scale (boolean): Should centering and scaling be TRUE when using prcomp()?
    #MSE_transform (boolean): Should responses and targets be converted back to non-log space before MSE calculation? The default is FALSE, and we advise against chaning the default becuase outliers can have a MASSIVE effect on MSE when 10^responses and 10^targets is computed.
  
#Returns:
    #Prints RMSE information to the R console.
    #Prints a series of figures: A screeplot of PCs, cross-validation scores, coefficients as a function of lambda (LASSO penalty term), the model fit as a scatter plot, and a ranked PC vs. prediction coefficient plot.

  biogeo <- train_test_splits[[9]] #Make a variable of the biogeo type that was used in the train / test split function so that it can be used later in this function.
  trim_sub_NP <- train_test_splits[[10]] #Same comment.
  analyte <- train_test_splits[[11]] #Same comment.
  fire <- train_test_splits[[12]] #Same comment.
  time_point <- train_test_splits[[13]] #Same comment.
  taxa_list_num <- train_test_splits[[14]] #Same comment.
  
  #Row-bind the data into one dataset (combine the train and test datasets).
  Xbound_data <- rbind(train_test_splits[[1]], train_test_splits[[3]])
  Ybound_data <- rbind(train_test_splits[[2]], train_test_splits[[4]])
  Ybound_data_asDF <- as.data.frame(Ybound_data)
  
  if (log10_transform == TRUE){
    Ybound_data <- log10(Ybound_data)
    Ybound_data_asDF <- log10(Ybound_data_asDF)
  }
  
  #Generating the PCs WITHOUT THE LABEL!
  if (center_scale == TRUE){
    pr_comps <- prcomp(Xbound_data, center = TRUE, scale. = TRUE)
  } else {
    pr_comps <- prcomp(Xbound_data, center = FALSE, scale. = FALSE)
  }
  
  #Splitting prcomp matrix into training and testing data. Indexing is preserved during prcomp and so the same train / test set as used in other models can be replicated / split back out.
  pr_comps_train <- pr_comps$x[1:385,]
  pr_comps_test <- pr_comps$x[386:514,]
  Ybound_data_train <- Ybound_data[1:385,]
  Ybound_data_test <- Ybound_data[386:514,]
  Ybound_data_asDF_train <- Ybound_data_asDF[1:385,]
  Ybound_data_asDF_test <- Ybound_data_asDF[386:514,]
  
  #Scree plot (of PCs learned from the full dataset).
  screeplot(pr_comps, type = "l", npcs = dim(pr_comps$rotation)[2], main = "Screeplot of all PCs", col = "blue")
  
  #Building the MLR lasso model.
  lasso.model <- glmnet(pr_comps_train,Ybound_data_train,alpha=1) # alpha=1 => lasso
  
  #Investigating the optimal lamba value via cross-validation.
  set.seed(2) #This will determine the initialization of the fold-sets during cross-validation.
  cv.out <- cv.glmnet(pr_comps_train,Ybound_data_train,alpha=1)
  plot(cv.out)
  lambda.lasso <- cv.out$lambda.min
  #lambda.lasso <- 5 #Can also manually set lambda.
  lambda.lasso
  
  #The fit model's coefficients.
  predict1 <- predict(lasso.model,s=lambda.lasso,type="coefficient")
  
  #The fit model's response predictions (TRAIN data), and calculated MSE (on TRAIN data).
  responses_train <- predict(lasso.model,s=lambda.lasso,type="response", newx = pr_comps_train)
  #Depending on if the MSE_transform argument was used or not, one could convert the responses and targets back into non-log space.
  if (MSE_transform == TRUE){
    mse_train <- mean(((10^responses_train) - (10^Ybound_data_train))^2)
  }
  if (MSE_transform == FALSE){
    mse_train <- mean((responses_train - Ybound_data_train)^2)
  }
  #df for the linear model of the predicted value vs. the observed value (On TRAIN data).
  x_train <- Ybound_data_asDF_train
  y_train <- responses_train
  df_train <- data.frame(x_train, y_train) #Make a dataframe.
  colnames(df_train)[1] <- "x_train" #Need to force the column name so that it is compatible with code later on.
  
  #The fit model's response predictions (TEST data), and calculated MSE (on TEST data).
  responses_test <- predict(lasso.model,s=lambda.lasso,type="response", newx = pr_comps_test)
  #Depending on if the MSE_transform argument was used or not, one could convert the responses and targets back into non-log space.
  if (MSE_transform == TRUE){
    mse_test <- mean(((10^responses_test) - (10^Ybound_data_test))^2)
  }
  if (MSE_transform == FALSE){
    mse_test <- mean((responses_test - Ybound_data_test)^2)
  }
  #df for the linear model of the predicted value vs. the observed value (On TEST data).
  x_test <- Ybound_data_asDF_test
  y_test <- responses_test
  df_test <- data.frame(x_test, y_test) #Make a dataframe.
  colnames(df_test)[1] <- "x_test" #Need to force the column name so that it is compatible with code later on.
  
  #####################################
  ############ Plotting ###############
  #####################################
  
  ### Looking at feature selection by lasso. These are based on the TRAIN data. ###
  plot(lasso.model, xvar="lambda") #Generates two plots.
  print(predict1) #Printing the coefficients.
  ##############
  
  #Calculate RMSE from MSE; RMSE is a nice number because it puts the errors in the same unit as the variable that we are trying to predict.
  Rmse_train <- sqrt(mse_train)
  Rmse_test <- sqrt(mse_test)
  
  ## Plotting the data fit (TRAIN data) ################
  print(ggplot(df_train, aes(x = x_train, y = X1)) + 
  geom_point() + 
  theme(axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),  
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14)) +
  geom_abline(slope = 1, intercept = 0, colour = "blue") +
  #xlim(0, NA) + #Allowing default limits by commenting this line.
  #ylim(0, NA) + #Allowing default limits by commenting this line.
  coord_fixed(ratio = 1) +
  theme(panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(),
    panel.background = element_blank(), 
    axis.line = element_line(colour = "black"), 
    strip.background = element_blank(), 
    legend.background = element_blank(), 
    legend.key = element_blank(), 
    panel.border = element_rect(color = "black", fill = NA, size = 1)) +
  xlab("Observed") +
  ylab("Predicted") +
  ggtitle(paste("RMSE_train = ", format(round(Rmse_train, 2), nsmall = 2))) +
  theme(plot.title = element_text(size = 12, face = "bold"))
  )
  ###############################################
  
  ## Plotting the data fit (TEST data) ################
  print(ggplot(df_test, aes(x = x_test, y = X1)) + 
  geom_point() + 
  theme(axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),  
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14)) +
  geom_abline(slope = 1, intercept = 0, colour = "blue") +
  #xlim(0, NA) + #Allowing default limits by commenting this line.
  #ylim(0, NA) + #Allowing default limits by commenting this line.
  coord_fixed(ratio = 1) +
  theme(panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(),
    panel.background = element_blank(), 
    axis.line = element_line(colour = "black"), 
    strip.background = element_blank(), 
    legend.background = element_blank(), 
    legend.key = element_blank(), 
    panel.border = element_rect(color = "black", fill = NA, size = 1)) +
  xlab("Observed") +
  ylab("Predicted") +
  ggtitle(paste("RMSE_test = ", format(round(Rmse_test, 2), nsmall = 2))) +
  theme(plot.title = element_text(size = 12, face = "bold"))
  )
  ###############################################
  
  ####
  #### Plot the coeffecients of the PCs (learned on TEST data) ####
  ####
  
  #Generate a dataframe of the PCs and their indexes.
  coefs_df <- data.frame(as.matrix(predict1))
  pc_indexes <- seq(0, dim(pr_comps$rotation)[2], by= 1) #Note that 'PC0' is the intercept term.
  coefs_df$pc <- pc_indexes
  coefs_df$X1 <- abs(coefs_df$X1) #Taking the absolute value of the coefficients.
  coefs_df <- coefs_df[-c(1),] #Remove the intercept term.
  
  #PLot the PCs as indexes.
  print(
    ggplot(coefs_df, aes(x= pc, y = X1, colour = "red")) +
      geom_line() +
      theme(axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),  
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14)) +
      theme(panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.line = element_line(colour = "black"),
    strip.background = element_blank(),
    legend.background = element_blank(),
    legend.key = element_blank(),
    legend.position = "none",
    panel.border = element_rect(color = "black", fill = NA, size = 1),
    aspect.ratio = 0.7) +
    xlab("Principal Component") +
    ylab("abs(Prediction Coefficient)") +
    ggtitle(paste("Coefficients of the", count(coefs_df$X1!=0), "PCs selected.")) +
    theme(plot.title = element_text(size = 12, face = "bold"))
  )
  
  ##########################################
  
  print(paste0("The Training RMSE is ",Rmse_train,"."))
  print(paste0("The Testing RMSE is ",Rmse_test,"."))
  print(paste("There were", count(coefs_df$X1!=0), "PCs selected."))
  
}

```

#Generating the PC regression figures.
```{r}

#PC regression BIO-ONLY for the NH4 case-study.
PCA_lasso_fit_logOpt(All_Gen_b2g_NH4, log10_transform = TRUE, center_scale = TRUE)

```

#dPCR analyses.
```{r}
#Once the raw dPCR data files are imported from Excel, these code lines can be used to save them as a .RDS files for faster access. These lines will need to be rerun if changes to the Excel file are made and need to propagate to the rest of the pipeline.
# saveRDS(FirePlate2_Bacteria_10x, file = paste0(path_to_data,"/Metadata/dPCR/FirePlate2_Bacteria_10x.RDS"))
# saveRDS(FirePlate3_Archaea, file = paste0(path_to_data,"/Metadata/dPCR/FirePlate3_Archaea.RDS"))
# saveRDS(FirePlate4_Eukaryotes, file = paste0(path_to_data,"/Metadata/dPCR/FirePlate4_Eukaryotes.RDS"))

#Load the raw data.
FirePlate2_Bacteria_10x <- readRDS(file = paste0(path_to_data,"/Metadata/dPCR/FirePlate2_Bacteria_10x.RDS"))
FirePlate3_Archaea <- readRDS(file = paste0(path_to_data,"/Metadata/dPCR/FirePlate3_Archaea.RDS"))
FirePlate4_Eukaryotes <- readRDS(file = paste0(path_to_data,"/Metadata/dPCR/FirePlate4_Eukaryotes.RDS"))

#Merge the dPCR data with the metadata for the samples.
#Note that there are three dPCR samples that there is no metadata for in fire_ps: "P3_D1_R1_20", "PCR Water", and "Zymo Mock Community". This is because the PCR positive and negative controls for dPCR were the standards; the one sample that does not have metadata was not sequenced. So there is no data for that sample in the sequencing sample_data(). We will add the metadata for this sample manually.
FirePlate2_Bacteria_10x_merged <- merge(FirePlate2_Bacteria_10x, data.frame(sample_data(fire_ps)), by = "full_sam_name", all.x = TRUE)
FirePlate3_Archaea_merged <- merge(FirePlate3_Archaea, data.frame(sample_data(fire_ps)), by = "full_sam_name", all.x = TRUE)
FirePlate4_Eukaryotes_merged <- merge(FirePlate4_Eukaryotes, data.frame(sample_data(fire_ps)), by = "full_sam_name", all.x = TRUE)

#The values reported by the dPCR machine are not the actual concentrations of DNA in extractions. 2 uL of DNA extract was added to 10 uL of other reagents for a total of 12 uL in the dPCR reaction well. 10 of those 12 uL were actually pipetted into the wells (to avoid air bubbles). So, we must multiply the results by 6 to get the actual concentration of the DNA that was added to the reaction. Further, all fire dPCR plates used DNA extract that was 1:10 diluted, meaning that we will also need to multiply the results by 10. In total, the dPCR results must be multiplied by 60 to give the actual concentration of DNA extracts. Then, there are 100 uL of DNA extract per 0.25 g of soil. So, [DNA extract]*400 = copies / gram of soil. 60 * 400 = 24,000 as the multiplication factor to get to copies / gram as the unit.
Bacteria_actual <- FirePlate2_Bacteria_10x_merged$concentration_copiesPer_uL*24000
Archaea_actual <- FirePlate3_Archaea_merged$concentration_copiesPer_uL*24000
FirePlate4_Eukaryotes_merged <- FirePlate4_Eukaryotes_merged[which(FirePlate4_Eukaryotes_merged$concentration_copiesPer_uL != "NA"), ] #There was one sample that had insufficient wells that could be imaged during dPCR to return an accurate concentration. We remove this sample.
Euks_actual <- as.numeric(FirePlate4_Eukaryotes_merged$concentration_copiesPer_uL)*24000 #During NA removal, the remaining data was converted to character; here, we recast to numeric.
FirePlate2_Bacteria_10x_merged$concentration_copiesPer_g <- Bacteria_actual
FirePlate3_Archaea_merged$concentration_copiesPer_g <- Archaea_actual
FirePlate4_Eukaryotes_merged$concentration_copiesPer_g <- Euks_actual
#For the negative controls, which were not derived from soil, we prefer to have the concentration in copiesPer/uL of DNA extract as the unit. We create that variable below with the proper multiplication factor to convert raw dPCR concentration data.
FirePlate2_Bacteria_10x_merged$extract_copiesPer_uL <- FirePlate2_Bacteria_10x_merged$concentration_copiesPer_uL*60
FirePlate3_Archaea_merged$extract_copiesPer_uL <- FirePlate3_Archaea_merged$concentration_copiesPer_uL*60
FirePlate4_Eukaryotes_merged$extract_copiesPer_uL <- as.numeric(FirePlate4_Eukaryotes_merged$concentration_copiesPer_uL)*60 #Same comment as earlier on how removing one sample from this dataframe caused a datatype change; need to change it back to numeric here.

#####################
#Getting the mean copies per gram count from negatives for each primer type.
####################
#Determine the mean copy number in the negatives (Bacteria).
Bact_negative_countMean <- mean(c(FirePlate2_Bacteria_10x_merged[FirePlate2_Bacteria_10x_merged$full_sam_name == "C_7_7_20",]$concentration_copiesPer_g, FirePlate2_Bacteria_10x_merged[FirePlate2_Bacteria_10x_merged$full_sam_name == "C_8_1_20",]$concentration_copiesPer_g, FirePlate2_Bacteria_10x_merged[FirePlate2_Bacteria_10x_merged$full_sam_name == "Decker19_ex3_ctl",]$concentration_copiesPer_g, FirePlate2_Bacteria_10x_merged[FirePlate2_Bacteria_10x_merged$full_sam_name == "Extraction1_Control",]$concentration_copiesPer_g, FirePlate2_Bacteria_10x_merged[FirePlate2_Bacteria_10x_merged$full_sam_name == "PCR Water",]$concentration_copiesPer_g))
#Determine the mean copy number in the negatives (Archaea).
Arch_negative_countMean <- mean(c(FirePlate3_Archaea_merged[FirePlate3_Archaea_merged$full_sam_name == "C_7_7_20",]$concentration_copiesPer_g, FirePlate3_Archaea_merged[FirePlate3_Archaea_merged$full_sam_name == "C_8_1_20",]$concentration_copiesPer_g, FirePlate3_Archaea_merged[FirePlate3_Archaea_merged$full_sam_name == "Decker19_ex3_ctl",]$concentration_copiesPer_g, FirePlate3_Archaea_merged[FirePlate3_Archaea_merged$full_sam_name == "Extraction1_Control",]$concentration_copiesPer_g, FirePlate3_Archaea_merged[FirePlate3_Archaea_merged$full_sam_name == "PCR Water",]$concentration_copiesPer_g))
#Determine the mean copy number in the negatives (Euks).
Euks_negative_countMean <- mean(c(FirePlate4_Eukaryotes_merged[FirePlate4_Eukaryotes_merged$full_sam_name == "C_7_7_20",]$concentration_copiesPer_g, FirePlate4_Eukaryotes_merged[FirePlate4_Eukaryotes_merged$full_sam_name == "C_8_1_20",]$concentration_copiesPer_g, FirePlate4_Eukaryotes_merged[FirePlate4_Eukaryotes_merged$full_sam_name == "Decker19_ex3_ctl",]$concentration_copiesPer_g, FirePlate4_Eukaryotes_merged[FirePlate4_Eukaryotes_merged$full_sam_name == "Extraction1_Control",]$concentration_copiesPer_g, FirePlate4_Eukaryotes_merged[FirePlate4_Eukaryotes_merged$full_sam_name == "PCR Water",]$concentration_copiesPer_g))

#####################
#Remove the mean count of copies per gram that are in the negatives from real samples.
####################
#Bacteria
FirePlate2_Bacteria_10x_merged$concentration_copiesPer_g <- FirePlate2_Bacteria_10x_merged$concentration_copiesPer_g - Bact_negative_countMean
#Archaea
FirePlate3_Archaea_merged$concentration_copiesPer_g <- FirePlate3_Archaea_merged$concentration_copiesPer_g - Arch_negative_countMean
#Euks
FirePlate4_Eukaryotes_merged$concentration_copiesPer_g <- FirePlate4_Eukaryotes_merged$concentration_copiesPer_g - Euks_negative_countMean

#Remove the mock community positive control from each dataset.
FirePlate2_Bacteria_10x_merged <- FirePlate2_Bacteria_10x_merged[which(FirePlate2_Bacteria_10x_merged$full_sam_name != "Zymo Mock Community"), ] #Bacteria plate.
FirePlate3_Archaea_merged <- FirePlate3_Archaea_merged[which(FirePlate3_Archaea_merged$full_sam_name != "Zymo Mock Community"), ] #Archaea plate.
FirePlate4_Eukaryotes_merged <- FirePlate4_Eukaryotes_merged[which(FirePlate4_Eukaryotes_merged$full_sam_name != "Zymo Mock Community"), ] #Euks plate.

#Manually add Burn Severity data for dPCR extraction controls, and dPCR PCR control (Bacteria plate).
FirePlate2_Bacteria_10x_merged[which(FirePlate2_Bacteria_10x_merged$full_sam_name == "PCR Water"), c("field_SBS")] <- "dPCR Negative"
FirePlate2_Bacteria_10x_merged[which(FirePlate2_Bacteria_10x_merged$full_sam_name == "C_7_7_20"), c("field_SBS")] <- "DNA Extraction Negative"
FirePlate2_Bacteria_10x_merged[which(FirePlate2_Bacteria_10x_merged$full_sam_name == "C_8_1_20"), c("field_SBS")] <- "DNA Extraction Negative"
FirePlate2_Bacteria_10x_merged[which(FirePlate2_Bacteria_10x_merged$full_sam_name == "Decker19_ex3_ctl"), c("field_SBS")] <- "DNA Extraction Negative"
FirePlate2_Bacteria_10x_merged[which(FirePlate2_Bacteria_10x_merged$full_sam_name == "Extraction1_Control"), c("field_SBS")] <- "DNA Extraction Negative"
#Manually add Burn Severity data for dPCR extraction controls, and dPCR PCR control (Archaea plate).
FirePlate3_Archaea_merged[which(FirePlate3_Archaea_merged$full_sam_name == "PCR Water"), c("field_SBS")] <- "dPCR Negative"
FirePlate3_Archaea_merged[which(FirePlate3_Archaea_merged$full_sam_name == "C_7_7_20"), c("field_SBS")] <- "DNA Extraction Negative"
FirePlate3_Archaea_merged[which(FirePlate3_Archaea_merged$full_sam_name == "C_8_1_20"), c("field_SBS")] <- "DNA Extraction Negative"
FirePlate3_Archaea_merged[which(FirePlate3_Archaea_merged$full_sam_name == "Decker19_ex3_ctl"), c("field_SBS")] <- "DNA Extraction Negative"
FirePlate3_Archaea_merged[which(FirePlate3_Archaea_merged$full_sam_name == "Extraction1_Control"), c("field_SBS")] <- "DNA Extraction Negative"
#Manually add Burn Severity data for dPCR extraction controls, and dPCR PCR control (Euks plate).
FirePlate4_Eukaryotes_merged[which(FirePlate4_Eukaryotes_merged$full_sam_name == "PCR Water"), c("field_SBS")] <- "dPCR Negative"
FirePlate4_Eukaryotes_merged[which(FirePlate4_Eukaryotes_merged$full_sam_name == "C_7_7_20"), c("field_SBS")] <- "DNA Extraction Negative"
FirePlate4_Eukaryotes_merged[which(FirePlate4_Eukaryotes_merged$full_sam_name == "C_8_1_20"), c("field_SBS")] <- "DNA Extraction Negative"
FirePlate4_Eukaryotes_merged[which(FirePlate4_Eukaryotes_merged$full_sam_name == "Decker19_ex3_ctl"), c("field_SBS")] <- "DNA Extraction Negative"
FirePlate4_Eukaryotes_merged[which(FirePlate4_Eukaryotes_merged$full_sam_name == "Extraction1_Control"), c("field_SBS")] <- "DNA Extraction Negative"

#Manually add field_SBS data for one sample that does not have associated sequencing data (failure at barcoding step during seq. prep); we need to do this because metadata was not included for this sample in the sequencing data.
FirePlate2_Bacteria_10x_merged[which(FirePlate2_Bacteria_10x_merged$full_sam_name == "P3_D1_R1_20"), c("field_SBS")] <- "High"
FirePlate3_Archaea_merged[which(FirePlate3_Archaea_merged$full_sam_name == "P3_D1_R1_20"), c("field_SBS")] <- "High"
#Note that we do not need to do the above for the Euk plate because dPCR failed on this sample anyway. So, for Euks this sample failed during dPCR as well as sequencing; this may be one of those SUPER high humic-content samples that are hard to work with (would make sense in light of High burn severity, which this sample is).

#For the same reason as the lines above, manually add the time_point for this sample.
FirePlate2_Bacteria_10x_merged[which(FirePlate2_Bacteria_10x_merged$full_sam_name == "P3_D1_R1_20"), c("time_point")] <- "3"
FirePlate3_Archaea_merged[which(FirePlate3_Archaea_merged$full_sam_name == "P3_D1_R1_20"), c("time_point")] <- "3"

# #Create a "time_point" for the dPCR negative control so that it plots with the other samples.
# FirePlate2_Bacteria_10x_merged[which(FirePlate2_Bacteria_10x_merged$full_sam_name == "PCR Water"), c("time_point")] <- "dPCR Negative"
# FirePlate3_Archaea_merged[which(FirePlate3_Archaea_merged$full_sam_name == "PCR Water"), c("time_point")] <- "dPCR Negative"
# FirePlate4_Eukaryotes_merged[which(FirePlate4_Eukaryotes_merged$full_sam_name == "PCR Water"), c("time_point")] <- "dPCR Negative"

#Factor the field_SBS variable so that it plots in a logical order.
FirePlate2_Bacteria_10x_merged$field_SBS <- factor(FirePlate2_Bacteria_10x_merged$field_SBS , levels=c("High", "Moderate", "Low", "No Burn Control", "DNA Extraction Negative", "dPCR Negative"))
FirePlate3_Archaea_merged$field_SBS <- factor(FirePlate3_Archaea_merged$field_SBS , levels=c("High", "Moderate", "Low", "No Burn Control", "DNA Extraction Negative", "dPCR Negative"))
FirePlate4_Eukaryotes_merged$field_SBS <- factor(FirePlate4_Eukaryotes_merged$field_SBS , levels=c("High", "Moderate", "Low", "No Burn Control", "DNA Extraction Negative", "dPCR Negative"))

#Take the negative controls (both extraction and dPCR) from the datasets and store them as their own object for plotting.
Bact_negatives <- FirePlate2_Bacteria_10x_merged[which((FirePlate2_Bacteria_10x_merged$field_SBS == "dPCR Negative") | (FirePlate2_Bacteria_10x_merged$field_SBS == "DNA Extraction Negative")), ]
Arch_negatives <- FirePlate3_Archaea_merged[which((FirePlate3_Archaea_merged$field_SBS == "dPCR Negative") | (FirePlate3_Archaea_merged$field_SBS == "DNA Extraction Negative")), ]
Euks_negatives <- FirePlate4_Eukaryotes_merged[which((FirePlate4_Eukaryotes_merged$field_SBS == "dPCR Negative") | (FirePlate4_Eukaryotes_merged$field_SBS == "DNA Extraction Negative")), ]

#Remove the negative controls from the datasets used for sample plotting.
FirePlate2_Bacteria_10x_merged <- FirePlate2_Bacteria_10x_merged[-which((FirePlate2_Bacteria_10x_merged$field_SBS == "dPCR Negative") | (FirePlate2_Bacteria_10x_merged$field_SBS == "DNA Extraction Negative")), ] #Bacteria plate
FirePlate3_Archaea_merged <- FirePlate3_Archaea_merged[-which((FirePlate3_Archaea_merged$field_SBS == "dPCR Negative") | (FirePlate3_Archaea_merged$field_SBS == "DNA Extraction Negative")), ] #Archaea plate
FirePlate4_Eukaryotes_merged <- FirePlate4_Eukaryotes_merged[-which((FirePlate4_Eukaryotes_merged$field_SBS == "dPCR Negative") | (FirePlate4_Eukaryotes_merged$field_SBS == "DNA Extraction Negative")), ] #Euks plate

#Create a variable that is the log10() of the copy # concentration per gram; this is the value that we will plot.
FirePlate2_Bacteria_10x_merged$log10_copiesPer_g <- log10(FirePlate2_Bacteria_10x_merged$concentration_copiesPer_g)
FirePlate3_Archaea_merged$log10_copiesPer_g <- log10(FirePlate3_Archaea_merged$concentration_copiesPer_g)
FirePlate4_Eukaryotes_merged$log10_copiesPer_g <- log10(FirePlate4_Eukaryotes_merged$concentration_copiesPer_g)
#Turn -Inf into 0s from the log10() calculation.
FirePlate2_Bacteria_10x_merged$log10_copiesPer_g[FirePlate2_Bacteria_10x_merged$log10_copiesPer_g == -Inf] <- 0
FirePlate3_Archaea_merged$log10_copiesPer_g[FirePlate3_Archaea_merged$log10_copiesPer_g == -Inf] <- 0
FirePlate4_Eukaryotes_merged$log10_copiesPer_g[FirePlate4_Eukaryotes_merged$log10_copiesPer_g == -Inf] <- 0

#Split the dPCR samples into Decker and 416 Fires.
F416_Bacteria_dPCR <- FirePlate2_Bacteria_10x_merged[ which(FirePlate2_Bacteria_10x_merged$fire=='416 Fire'), ]
F416_Archaea_dPCR <- FirePlate3_Archaea_merged[ which(FirePlate3_Archaea_merged$fire=='416 Fire'), ]
F416_Euks_dPCR <- FirePlate4_Eukaryotes_merged[ which(FirePlate4_Eukaryotes_merged$fire=='416 Fire'), ]
Decker_Bacteria_dPCR <- FirePlate2_Bacteria_10x_merged[ which(FirePlate2_Bacteria_10x_merged$fire=='Decker Fire'), ]
Decker_Archaea_dPCR <- FirePlate3_Archaea_merged[ which(FirePlate3_Archaea_merged$fire=='Decker Fire'), ]
Decker_Euks_dPCR <- FirePlate4_Eukaryotes_merged[ which(FirePlate4_Eukaryotes_merged$fire=='Decker Fire'), ]

#Split the 416 Fire samples into deep (depth 3 or 4) or surface (depth 1).
F416_Bacteria_dPCR_deep <- F416_Bacteria_dPCR[ which(F416_Bacteria_dPCR$depth_group=='3' | F416_Bacteria_dPCR$depth_group=='4'), ]
F416_Archaea_dPCR_deep <- F416_Archaea_dPCR[ which(F416_Archaea_dPCR$depth_group=='3' | F416_Archaea_dPCR$depth_group=='4'), ]
F416_Euks_dPCR_deep <- F416_Euks_dPCR[ which(F416_Euks_dPCR$depth_group=='3' | F416_Euks_dPCR$depth_group=='4'), ]
F416_Bacteria_dPCR_surface <- F416_Bacteria_dPCR[ which(F416_Bacteria_dPCR$depth_group=='1'), ]
F416_Archaea_dPCR_surface <- F416_Archaea_dPCR[ which(F416_Archaea_dPCR$depth_group=='1'), ]
F416_Euks_dPCR_surface <- F416_Euks_dPCR[ which(F416_Euks_dPCR$depth_group=='1'), ]

################
## dPCR plots ##
################

# Libraries
library(tidyverse)
library(hrbrthemes)
library(viridis)
library(cowplot)

#Make plots of the extraction and dPCR negative controls.
set.seed(6) #For reproducing the x-axis point jitter.
Bact_dPCRnegatives_fig <- Bact_negatives %>%
  ggplot( aes(x=field_SBS, y=extract_copiesPer_uL, fill=field_SBS)) +
    geom_boxplot(outlier.shape = NA) +
    scale_fill_viridis(discrete = TRUE, alpha=0.7) +
    geom_jitter(color="black", size=4, alpha=0.9, height = 0) + #height = 0 means that the y-axis values will be preserved.
    theme_ipsum() +
    theme(
      legend.position="none",
      plot.title = element_text(size=11)
    ) +
    #ggtitle("Negative Controls") +
    xlab("") +
    #scale_y_log10(limits = as.numeric(c(-100, 1000000))) + #For some reason, 0 as a scale minimum does not work.
    theme(axis.text.x = element_text(angle = -90))
set.seed(6) #For reproducing the x-axis point jitter.
Arch_dPCRnegatives_fig <- Arch_negatives %>%
  ggplot( aes(x=field_SBS, y=extract_copiesPer_uL, fill=field_SBS)) +
    geom_boxplot(outlier.shape = NA) +
    scale_fill_viridis(discrete = TRUE, alpha=0.7) +
    geom_jitter(color="black", size=4, alpha=0.9, height = 0) + #height = 0 means that the y-axis values will be preserved.
    theme_ipsum() +
    theme(
      legend.position="none",
      plot.title = element_text(size=11)
    ) +
    #ggtitle("Negative Controls") +
    xlab("") +
    #scale_y_log10(limits = as.numeric(c(-100, 1000000))) + #Remember, this will toss 0s.
    theme(axis.text.x = element_text(angle = -90))
set.seed(6) #For reproducing the x-axis point jitter.
Euks_dPCRnegatives_fig <- Euks_negatives %>%
  ggplot( aes(x=field_SBS, y=extract_copiesPer_uL, fill=field_SBS)) +
    geom_boxplot(outlier.shape = NA) +
    scale_fill_viridis(discrete = TRUE, alpha=0.7) +
    geom_jitter(color="black", size=4, alpha=0.9, height = 0) + #height = 0 means that the y-axis values will be preserved.
    theme_ipsum() +
    theme(
      legend.position="none",
      plot.title = element_text(size=11)
    ) +
    #ggtitle("Negative Controls") +
    xlab("") +
    #scale_y_log10(limits = as.numeric(c(-100, 1000000))) +
    theme(axis.text.x = element_text(angle = -90))

#Decker Fire: Bacteria
DeckerBact_dPCR_fig <- Decker_Bacteria_dPCR %>%
  ggplot( aes(x=field_SBS, y=log10_copiesPer_g, fill=field_SBS)) +
    geom_boxplot() +
    facet_wrap(~time_point) +
    scale_fill_viridis(discrete = TRUE, alpha=0.7) +
    geom_jitter(color="black", size=2, alpha=0.9, height = 0) +
    theme_ipsum() +
    theme(
      legend.position="none",
      plot.title = element_text(size=11), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), strip.background = element_blank(), legend.background = element_blank(), legend.key = element_blank(), panel.border = element_rect(color = "black", fill = NA, size = 1)
    ) +
    #ggtitle("Decker Fire Bacteria") +
    ylab("log10(Copies per g of soil)") +
    xlab("") +
    #scale_y_log10() +
    theme(axis.text.x = element_text(angle = -90))
#Decker Fire: Archaea
DeckerArch_dPCR_fig <- Decker_Archaea_dPCR %>%
  ggplot( aes(x=field_SBS, y=log10_copiesPer_g, fill=field_SBS)) +
    geom_boxplot() +
    facet_wrap(~time_point) +
    scale_fill_viridis(discrete = TRUE, alpha=0.7) +
    geom_jitter(color="black", size=2, alpha=0.9, height = 0) +
    theme_ipsum() +
    theme(
      legend.position="none",
      plot.title = element_text(size=11), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), strip.background = element_blank(), legend.background = element_blank(), legend.key = element_blank(), panel.border = element_rect(color = "black", fill = NA, size = 1)
    ) +
    #ggtitle("Decker Fire Archaea") +
    ylab("log10(Copies per g of soil)") +
    xlab("") +
    #scale_y_log10() +
    theme(axis.text.x = element_text(angle = -90))
#Decker Fire: Euks
DeckerEuks_dPCR_fig <- Decker_Euks_dPCR %>%
  ggplot( aes(x=field_SBS, y=log10_copiesPer_g, fill=field_SBS)) +
    geom_boxplot() +
    facet_wrap(~time_point) +
    scale_fill_viridis(discrete = TRUE, alpha=0.7) +
    geom_jitter(color="black", size=2, alpha=0.9, height = 0) +
    theme_ipsum() +
    theme(
      legend.position="none",
      plot.title = element_text(size=11), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), strip.background = element_blank(), legend.background = element_blank(), legend.key = element_blank(), panel.border = element_rect(color = "black", fill = NA, size = 1)
    ) +
    #ggtitle("Decker Fire Euks") +
    ylab("log10(Copies per g of soil)") +
    xlab("") +
    #scale_y_log10() +
    theme(axis.text.x = element_text(angle = -90))

#416 Fire: Bacteria, Deep
F416BactDeep_dPCR_fig <- F416_Bacteria_dPCR_deep %>%
  ggplot( aes(x=field_SBS, y=log10_copiesPer_g, fill=field_SBS)) +
    geom_boxplot() +
    facet_wrap(~time_point) +
    scale_fill_viridis(discrete = TRUE, alpha=0.7) +
    geom_jitter(color="black", size=2, alpha=0.9, height = 0) +
    theme_ipsum() +
    theme(
      legend.position="none",
      plot.title = element_text(size=11), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), strip.background = element_blank(), legend.background = element_blank(), legend.key = element_blank(), panel.border = element_rect(color = "black", fill = NA, size = 1)
    ) +
    #ggtitle("416 Fire Bacteria, Deep") +
    ylab("log10(Copies per g of soil)") +
    xlab("") +
    #scale_y_log10() +
    theme(axis.text.x = element_text(angle = -90))
F416ArchDeep_dPCR_fig <- F416_Archaea_dPCR_deep %>%
  ggplot( aes(x=field_SBS, y=log10_copiesPer_g, fill=field_SBS)) +
    geom_boxplot() +
    facet_wrap(~time_point) +
    scale_fill_viridis(discrete = TRUE, alpha=0.7) +
    geom_jitter(color="black", size=2, alpha=0.9, height = 0) +
    theme_ipsum() +
    theme(
      legend.position="none",
      plot.title = element_text(size=11), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), strip.background = element_blank(), legend.background = element_blank(), legend.key = element_blank(), panel.border = element_rect(color = "black", fill = NA, size = 1)
    ) +
    #ggtitle("416 Fire Archaea, Deep") +
    ylab("log10(Copies per g of soil)") +
    xlab("") +
    #scale_y_log10() +
    theme(axis.text.x = element_text(angle = -90))
F416EuksDeep_dPCR_fig <- F416_Euks_dPCR_deep %>%
  ggplot( aes(x=field_SBS, y=log10_copiesPer_g, fill=field_SBS)) +
    geom_boxplot() +
    facet_wrap(~time_point) +
    scale_fill_viridis(discrete = TRUE, alpha=0.7) +
    geom_jitter(color="black", size=2, alpha=0.9, height = 0) +
    theme_ipsum() +
    theme(
      legend.position="none",
      plot.title = element_text(size=11), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), strip.background = element_blank(), legend.background = element_blank(), legend.key = element_blank(), panel.border = element_rect(color = "black", fill = NA, size = 1)
    ) +
    #ggtitle("416 Fire Euks, Deep") +
    ylab("log10(Copies per g of soil)") +
    xlab("") +
    #scale_y_log10() +
    theme(axis.text.x = element_text(angle = -90))
#416 Fire: Bacteria, Surface
F416BactSurface_dPCR_fig <- F416_Bacteria_dPCR_surface %>%
  ggplot( aes(x=field_SBS, y=log10_copiesPer_g, fill=field_SBS)) +
    geom_boxplot() +
    facet_wrap(~time_point) +
    scale_fill_viridis(discrete = TRUE, alpha=0.7) +
    geom_jitter(color="black", size=2, alpha=0.9, height = 0) +
    theme_ipsum() +
    theme(
      legend.position="none",
      plot.title = element_text(size=11), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), strip.background = element_blank(), legend.background = element_blank(), legend.key = element_blank(), panel.border = element_rect(color = "black", fill = NA, size = 1)
    ) +
    #ggtitle("416 Fire Bacteria, Surface") +
    ylab("log10(Copies per g of soil)") +
    xlab("") +
    #scale_y_log10() +
    theme(axis.text.x = element_text(angle = -90))
F416ArchSurface_dPCR_fig <- F416_Archaea_dPCR_surface %>%
  ggplot( aes(x=field_SBS, y=log10_copiesPer_g, fill=field_SBS)) +
    geom_boxplot() +
    facet_wrap(~time_point) +
    scale_fill_viridis(discrete = TRUE, alpha=0.7) +
    geom_jitter(color="black", size=2, alpha=0.9, height = 0) +
    theme_ipsum() +
    theme(
      legend.position="none",
      plot.title = element_text(size=11), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), strip.background = element_blank(), legend.background = element_blank(), legend.key = element_blank(), panel.border = element_rect(color = "black", fill = NA, size = 1)
    ) +
    #ggtitle("416 Fire Archaea, Surface") +
    ylab("log10(Copies per g of soil)") +
    xlab("") +
    #scale_y_log10() +
    theme(axis.text.x = element_text(angle = -90))
F416EuksSurface_dPCR_fig <- F416_Euks_dPCR_surface %>%
  ggplot( aes(x=field_SBS, y=log10_copiesPer_g, fill=field_SBS)) +
    geom_boxplot() +
    facet_wrap(~time_point) +
    scale_fill_viridis(discrete = TRUE, alpha=0.7) +
    geom_jitter(color="black", size=2, alpha=0.9, height = 0) +
    theme_ipsum() +
    theme(
      legend.position="none",
      plot.title = element_text(size=11), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), strip.background = element_blank(), legend.background = element_blank(), legend.key = element_blank(), panel.border = element_rect(color = "black", fill = NA, size = 1)
    ) +
    #ggtitle("416 Fire Euks, Surface") +
    ylab("log10(Copies per g of soil)") +
    xlab("") +
    #scale_y_log10() +
    theme(axis.text.x = element_text(angle = -90))


#Bacteria 3 fire type composite
plot_row <- plot_grid(DeckerBact_dPCR_fig, F416BactDeep_dPCR_fig, F416BactSurface_dPCR_fig, Bact_dPCRnegatives_fig, labels = c('Decker Fire, O/A-Horizon', '416 Fire, Subsoil', '416 Fire, O/A-Horizon', 'Negative Controls'), label_size = 12)
# now add the title
title <- ggdraw() + 
  draw_label(
    "Absolute biomass: Bacteria",
    fontface = 'bold',
    x = 0,
    hjust = 0
  ) +
  theme(
    # add margin on the left of the drawing canvas,
    # so title is aligned with left edge of first plot
    plot.margin = margin(0, 0, 0, 7)
  )
#And make the final plot
boxes_BactDPCR <- plot_grid(
  title, plot_row,
  ncol = 1,
  # rel_heights values control vertical title margins
  rel_heights = c(0.1, 1)
)

#Archaea 3 fire type composite
plot_row <- plot_grid(DeckerArch_dPCR_fig, F416ArchDeep_dPCR_fig, F416ArchSurface_dPCR_fig, Arch_dPCRnegatives_fig, labels = c('Decker Fire, O/A-Horizon', '416 Fire, Subsoil', '416 Fire, O/A-Horizon', 'Negative Controls'), label_size = 12)
# now add the title
title <- ggdraw() + 
  draw_label(
    "Absolute biomass: Archaea",
    fontface = 'bold',
    x = 0,
    hjust = 0
  ) +
  theme(
    # add margin on the left of the drawing canvas,
    # so title is aligned with left edge of first plot
    plot.margin = margin(0, 0, 0, 7)
  )
#And make the final plot
boxes_ArchDPCR <- plot_grid(
  title, plot_row,
  ncol = 1,
  # rel_heights values control vertical title margins
  rel_heights = c(0.1, 1)
)

#Euks 3 fire type composite
plot_row <- plot_grid(DeckerEuks_dPCR_fig, F416EuksDeep_dPCR_fig, F416EuksSurface_dPCR_fig, Euks_dPCRnegatives_fig, labels = c('Decker Fire, O/A-Horizon', '416 Fire, Subsoil', '416 Fire, O/A-Horizon', 'Negative Controls'), label_size = 12)
# now add the title
title <- ggdraw() + 
  draw_label(
    "Absolute biomass: Eukarya (fungi)",
    fontface = 'bold',
    x = 0,
    hjust = 0
  ) +
  theme(
    # add margin on the left of the drawing canvas,
    # so title is aligned with left edge of first plot
    plot.margin = margin(0, 0, 0, 7)
  )
#And make the final plot
boxes_EuksDPCR <- plot_grid(
  title, plot_row,
  ncol = 1,
  # rel_heights values control vertical title margins
  rel_heights = c(0.1, 1)
)

#Negative controls composite plot
plot_row <- plot_grid(Bact_dPCRnegatives_fig, Arch_dPCRnegatives_fig, Euks_dPCRnegatives_fig, labels = c('Bacteria', 'Archaea', 'Eukarya'), label_size = 12)
# now add the title
title <- ggdraw() + 
  draw_label(
    "dPCR negative controls",
    fontface = 'bold',
    x = 0,
    hjust = 0
  ) +
  theme(
    # add margin on the left of the drawing canvas,
    # so title is aligned with left edge of first plot
    plot.margin = margin(0, 0, 0, 7)
  )
#And make the final plot
boxes_dPCR_negatives <- plot_grid(
  title, plot_row,
  ncol = 1,
  # rel_heights values control vertical title margins
  rel_heights = c(0.1, 1)
)


############################
#dPCR publication plots
###########################

#Bacteria individual plot construction.
plot_row <- plot_grid(DeckerBact_dPCR_fig, F416BactDeep_dPCR_fig, F416BactSurface_dPCR_fig, labels = c('Decker Fire, O/A-Horizon', '416 Fire, Subsoil', '416 Fire, O/A-Horizon'), label_size = 12)
# now add the title
title <- ggdraw() + 
  draw_label(
    "Absolute biomass: Bacteria",
    fontface = 'bold',
    x = 0,
    hjust = 0
  ) +
  theme(
    # add margin on the left of the drawing canvas,
    # so title is aligned with left edge of first plot
    plot.margin = margin(0, 0, 0, 7)
  )
#And make the final plot
boxes_BactDPCR_PUB <- plot_grid(
  title, plot_row,
  ncol = 1,
  # rel_heights values control vertical title margins
  rel_heights = c(0.1, 1)
) #Export size (inches): 9.5x14

#Archaea individual plot construction.
plot_row <- plot_grid(DeckerArch_dPCR_fig, F416ArchDeep_dPCR_fig, F416ArchSurface_dPCR_fig, labels = c('Decker Fire, O/A-Horizon', '416 Fire, Subsoil', '416 Fire, O/A-Horizon'), label_size = 12)
# now add the title
title <- ggdraw() + 
  draw_label(
    "Absolute biomass: Archaea",
    fontface = 'bold',
    x = 0,
    hjust = 0
  ) +
  theme(
    # add margin on the left of the drawing canvas,
    # so title is aligned with left edge of first plot
    plot.margin = margin(0, 0, 0, 7)
  )
#And make the final plot
boxes_ArchDPCR_PUB <- plot_grid(
  title, plot_row,
  ncol = 1,
  # rel_heights values control vertical title margins
  rel_heights = c(0.1, 1)
) #Export size (inches): 9.5x14

#Euks individual plot construction.
plot_row <- plot_grid(DeckerEuks_dPCR_fig, F416EuksDeep_dPCR_fig, F416EuksSurface_dPCR_fig, labels = c('Decker Fire, O/A-Horizon', '416 Fire, Subsoil', '416 Fire, O/A-Horizon'), label_size = 12)
# now add the title
title <- ggdraw() + 
  draw_label(
    "Absolute biomass: Eukarya (fungi)",
    fontface = 'bold',
    x = 0,
    hjust = 0
  ) +
  theme(
    # add margin on the left of the drawing canvas,
    # so title is aligned with left edge of first plot
    plot.margin = margin(0, 0, 0, 7)
  )
#And make the final plot
boxes_EuksDPCR_PUB <- plot_grid(
  title, plot_row,
  ncol = 1,
  # rel_heights values control vertical title margins
  rel_heights = c(0.1, 1)
) #Export size (inches): 9.5x14

```

#Microbial diversity.
```{r}
#Libraries
library("microbiome") # data analysis and visualization packageVersion("microbiome")
library("phyloseq"); #packageVersion("phyloseq")
library("tidyverse")
library("RColorBrewer") #; display.brewer.all()
library("wesanderson")
library("DT") # interactive data table
library("data.table") # alternative to data.frame
library("svglite") # saving svgs
library("vegan") # doing ecological analysis
library("grid") 
library("picante") 
library("gridExtra") # multi plots

#A holding variable for phyloseq data. Note that for these plots, we only work with the Bacteria and Archaea.
hold_ps <- comp_ps_BA

#Alpha diversity.
fl2.div <- microbiome::alpha(hold_ps, index = c("observed", "diversity_shannon", "diversity_gini_simpson")) #Compute
fl2.div$samp_name <- rownames(fl2.div) #Add the rownames to diversity table
fl2.div$q1 <- exp(fl2.div$diversity_shannon) #Add hill numbers for plot div.fl2.df
fl2.div$q2 <- 1/(1-fl2.div$diversity_gini_simpson) #Add hill numbers for plot div.fl2.df
colnames(fl2.div) <- c("Observed_Species", "Shannon", "Gini-Simpson", "Sample_ID", "q=1", "q=2") #Replacing the names.

#Map metadata from the base phyloseq object to the new dataframe.
mapping <- as.data.frame(sample_data(hold_ps))

#Add metadata from mapping file to diversity table
fl2.div$fire <- mapping$fire
fl2.div$year_sampled <- mapping$year_sampled
fl2.div$time_point <- mapping$time_point
fl2.div$depth_group <- mapping$depth_group
fl2.div$field_SBS <- mapping$field_SBS
fl2.div$finalMap_SBS <- mapping$finalMap_SBS
fl2.div <- as_tibble(fl2.div)
fl2.div <- relocate(fl2.div, Sample_ID)

#Now lets transform our table into long format using melt
fl2.div.g <- gather(fl2.div, key = "variable", value = "value", 
               Observed_Species,`q=1`, `q=2`)
fl2.div.gg <- fl2.div.g %>% 
  group_by(`variable`,fire, year_sampled,depth_group, field_SBS, time_point) %>% 
  dplyr::summarise(mean = mean(`value`),
            sd = sd(`value`))
hold_ps_416 = subset(fl2.div.gg, (fire=="416 Fire"))
hold_ps_416.na.rm = subset(hold_ps_416, depth_group != "NA")
hold_ps_416.na.rm$depth_group <- as.integer(hold_ps_416.na.rm$depth_group)
hold_ps_Deck = subset(fl2.div.gg, (fire=="Decker Fire"))
hold_ps_Deck = subset(hold_ps_Deck, field_SBS != "NA")
hold_ps_Deck$field_SBS <- factor(hold_ps_Deck$field_SBS, levels = c("High", "Moderate", "Low", "No Burn Control")) #Making the field_SBS a factor so that it can be plotted.

#Subsetting the alpha diversity dataframe for some smaller plots.
hold_ps_416_q1 = subset(hold_ps_416.na.rm, variable=="q=1")

#Now use this data frame to plot Alpha diversities by Sample type (416 Fire).
ggplot(hold_ps_416.na.rm, aes(x=depth_group, y=mean, color = as.character(year_sampled), shape = as.character(year_sampled))) +
  scale_x_reverse() +
  facet_grid(factor(field_SBS, levels = c("High", "Moderate", "Low", "No Burn Control"))~variable, scales = "free_x") +
  coord_flip() +
  geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width=0.25, size = 0.25) +
  geom_point(size = 3) +
  #geom_jitter() +
  geom_line(aes(x=depth_group, y=mean)) +
  scale_color_brewer(palette = "Dark2") +
  theme(axis.text.y = element_text(colour = "black", size = 12),
        axis.text.x = element_text(colour = "black", size = 12, angle = 85, hjust = 0.35, vjust = 0.5),
        axis.title = element_text(colour = "black", size = 15), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), strip.background = element_blank(), legend.background = element_blank(), legend.key = element_blank(), panel.border = element_rect(color = "black", fill = NA, size = 1))

#Now use this data frame to plot Alpha diversities by Sample type (Decker Fire).
ggplot(hold_ps_Deck, aes(x = field_SBS, y=mean, color = field_SBS)) +
  #scale_x_reverse() +
  facet_grid(time_point~variable, scales = "free_x") +
  coord_flip() +
  geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width=0.25, size = 0.25) +
  geom_point(size = 3) +
  #geom_jitter() +
  #geom_line(aes(x=depth_group, y=mean)) +
  scale_color_brewer(palette = "Dark2") +
  theme(axis.text.y = element_text(colour = "black", size = 12),
        axis.text.x = element_text(colour = "black", size = 12, angle = 85, hjust = 0.35, vjust = 0.5),
        axis.title = element_text(colour = "black", size = 15), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), strip.background = element_blank(), legend.background = element_blank(), legend.key = element_blank(), panel.border = element_rect(color = "black", fill = NA, size = 1), legend.position = "none") + scale_color_manual(values=c("red2", "darkorange", "forestgreen", "cornflowerblue"))

###Export dimensions:
#416_diversity: 6 x 8
#Decker_diversity: 6 x 8

```

#Generating a massive heatmap with all samples, by Phyla (all three domains of life).
```{r}
library(heatmaply)

#Previously in the code we have already generated NxP dataframes that are well suited to this task.
giant_NP <- NP_list[[2]] #This will still have metadata in it.
giant_NP <- giant_NP[which(giant_NP$field_SBS != "NA"),] #Removes negative and positive extraction / sequencing controls from the data. The number of samples in this dataframe now equals the number of samples regressed in all SL models.
giant_NP <- arrange(giant_NP, factor(field_SBS, levels = c("High", "Moderate", "Low", "No Burn Control"))) #Ordering the samples by field_SBS so that samples will group according to SBS in the heatmap.

giant_NP_SBSvector <- giant_NP$field_SBS #Getting the field_SBS as a vector so that it can be used to color-code rows in the heatmap by SBS. Note that the manual colors supplied here are colorblind-friendly.
SBS_color = rep(NA, length=length(giant_NP_SBSvector))
SBS_color[which(giant_NP_SBSvector=="High")] = "#D55E00"
SBS_color[which(giant_NP_SBSvector=="Moderate")] = "#F0E442"
SBS_color[which(giant_NP_SBSvector=="Low")] = "#009E73"
SBS_color[which(giant_NP_SBSvector=="No Burn Control")] = "#999999"

giant_NP_noMeta <- as.matrix(giant_NP[,1:86]) #This line removes metadata.
log10_giant_NP_noMeta <- log10(giant_NP_noMeta) #Taking the log10 has a nice intuitive representation.
log10_giant_NP_noMeta <- replace(log10_giant_NP_noMeta, log10_giant_NP_noMeta == -Inf, NA) #-Inf will take the place of a 0 relative abundance. Here, we turn those 0s into NA so that we can color them specifically in the heatmap.

########
###Instructions for generating figure from the below code...
#1) Uncomment the 'file=' line and run the code in the console. This will save a pdf file, but annoyingly the color scale is missing in Preview. But when the file is imported to Adobe Illustrator the color scale shows up.
#Leave the code as-is below and the heatmap will plot in the RMarkdown.
########
heatmaply(
  log10_giant_NP_noMeta,
  scale_fill_gradient_fun = ggplot2::scale_fill_gradient2(
    low = "blue",
    high = "red",
    midpoint = 0,
    limits = c(-2.5, 2.5)
  ), #Custom scale that bounds the limits of the log10(relative_abundance) dataframe.
  na.value = "white", #0 relative abundance values will be represented as blank on the figure.
  Rowv = FALSE, #Remove the dendrograms / reordering.
  Colv = FALSE, #Remove the dendrograms / reordering.
  showticklabels = c(TRUE, FALSE), #No row names.
  fontsize_col = 7,
  column_text_angle = 90,
  RowSideColors = SBS_color
  #, file = "/Users/alexhoneyman/Desktop/log10_giant_NP_noMeta.pdf"
)

```

#Making a large ridgeline set of data for geochemistry (all samples).
```{r}
#Variables to include in the geochemistry overview.
vars_for_bars <- c("DOC", "DTN", "Na", "NH4", "K", "Mg", "Ca", "Cl", "NO3", "PO4", "SO4")
vars_for_SBS <- c("field_SBS", "finalMap_SBS")
geochem_samples_forBars <- geochem_samples[,vars_for_bars] #Subset to these variables.

#Generating a reshaped table of samples paired with their field_SBS. We need this to plot points as colors by field_SBS in the figure.
geochem_samples_forSBS <- geochem_samples[,vars_for_SBS]
geochem_samples_forSBS$field_SBS <- as.numeric(geochem_samples_forSBS$field_SBS) #Note here that High = 1, Moderate = 2, Low = 3, and No Burn Control = 4.
geochem_samples_forSBS$sample <- row.names(geochem_samples_forSBS) #Make a variable with sample names.
geochem_samples_forSBS <- geochem_samples_forSBS[,-c(2)] #Remove the finalMap_SBS variable which we do not need.
geochem_samples_forSBS_reshape <- geochem_samples_forSBS %>% 
  pivot_longer(!sample, names_to = "var", values_to = "count") #Reshape the dataframe so that it is in the same format as the geochem dataframe that will be plotted.

#Making lists of samples by SBS type. This will be used to I.D. samples by SBS and populate the reshaped geochem table with that information.
SBSlist_High <- geochem_samples_forSBS_reshape[which(geochem_samples_forSBS_reshape$count == 1),]
SBSlist_Moderate <- geochem_samples_forSBS_reshape[which(geochem_samples_forSBS_reshape$count == 2),]
SBSlist_Low <- geochem_samples_forSBS_reshape[which(geochem_samples_forSBS_reshape$count == 3),]
SBSlist_NoBurnControl <- geochem_samples_forSBS_reshape[which(geochem_samples_forSBS_reshape$count == 4),]

#Reshaping the dataframe so that we can make ridgeline plots.
geochem_samples_forBars$sample <- row.names(geochem_samples_forBars)
geochem_reshape <- geochem_samples_forBars %>% 
  pivot_longer(!sample, names_to = "var", values_to = "count")
geochem_reshape$log10_count <- log10(geochem_reshape$count) #Making a new variable that is the log10() of concentrations.
geochem_reshape$field_SBS <- NA #Making a new variable that will house field_SBS.
geochem_reshape$field_SBS <- as.numeric(geochem_reshape$field_SBS) #Making the new variable numeric so that it works with the SBS factors.
for (i in geochem_reshape$sample){ #These looped 'if' statements populate the field_SBS variable in the reshaped geochemistry table. Note that the numeric factor values that we apply here have the same meaning as previously in this code chunk.
  if (i %in% SBSlist_High$sample){
    geochem_reshape[which(geochem_reshape$sample == i), ]$field_SBS <- 1
  }
  if (i %in% SBSlist_Moderate$sample){
    geochem_reshape[which(geochem_reshape$sample == i), ]$field_SBS <- 2
  }
  if (i %in% SBSlist_Low$sample){
    geochem_reshape[which(geochem_reshape$sample == i), ]$field_SBS <- 3
  }
  if (i %in% SBSlist_NoBurnControl$sample){
    geochem_reshape[which(geochem_reshape$sample == i), ]$field_SBS <- 4
  }
}

# Plot ridgelines.
geochem_overview <- ggplot(geochem_reshape, aes(x = log10_count, y = var, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01, alpha = 0.7) + 
  scale_fill_gradient2(low = "white", mid = "white", high = "white") +
  geom_point(shape = "|", size = 3, aes(colour = factor(field_SBS))) + #"colour" determines what color each hash mark will be. We will color hash marks by the field_SBS of that sample. We need to factor the numeric representations of SBS (1 -> 4) here so that the custom discrete color scale can map to discrete levels (as opposed to continuous values).
  scale_colour_manual(values = c("#D55E00", "#F0E442", "#009E73", "#999999")) + #The manual colors here (colorblind-friendly) corresponds, in order, to factor levels 1 -> 4 for SBS. We manually verified that the numeric factors translate colors to SBS correctly. E.g., "#D55E00" = High, "#F0E442" = Moderate, "#009E73" = Low, and "#999999" = No Burn Control.
  theme_ipsum() +
    theme(
      legend.position="none",
      panel.spacing = unit(0.1, "lines"),
      strip.text.x = element_text(size = 8)
    ) +
  theme(axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),  
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14)) +
  theme(
    #panel.grid.major = element_blank(),
    #panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.line = element_line(colour = "black"),
    strip.background = element_blank(),
    legend.background = element_blank(),
    legend.key = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, size = 1)) +
  xlab("log10(Concentration) (mg / L)") +
  ylab("")

```

#Making a comparative plot of ammonium by SBS. Running statistics on ammonium by SBS.
```{r}
geochem_dat_toPlot <- geochem_samples[,c("NH4", "field_SBS", "time_point")]
geochem_dat_toPlot$field_SBS <- factor(geochem_dat_toPlot$field_SBS)
geochem_dat_toPlot$time_point <- factor(geochem_dat_toPlot$time_point)
geochem_dat_toPlot$log10_NH4 <- log10(geochem_dat_toPlot$NH4)

#Box plot.
NH4_boxplot <- geochem_dat_toPlot %>%
  ggplot( aes(x=field_SBS, y=log10_NH4, fill=field_SBS)) +
    geom_boxplot() +
    scale_fill_manual(values = c("#D55E00", "#F0E442", "#009E73", "#999999")) + #Note that these colors are colorblind-friendly.
    geom_jitter(color="black", size=0.4, alpha=0.9) +
    theme_ipsum() +
    theme(
      legend.position="none",
      plot.title = element_text(size=11)
    ) +
    xlab("Soil Burn Severity") +
    ylab("log10 NH4 mg/L") +
    theme_ipsum() +
    theme(
      legend.position="none",
      panel.spacing = unit(0.1, "lines"),
      strip.text.x = element_text(size = 8)
    ) +
  theme(axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),  
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14)) +
  theme(
    #panel.grid.major = element_blank(),
    #panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.line = element_line(colour = "black"),
    strip.background = element_blank(),
    legend.background = element_blank(),
    legend.key = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, size = 1))

one_way_AOV <- aov(log10_NH4 ~ field_SBS, data = geochem_dat_toPlot)
summary(one_way_AOV)
#Print out of summary(one_way_AOV) below:
#              Df Sum Sq Mean Sq F value   Pr(>F)    
# field_SBS     3  14.53   4.843   7.055 0.000167 ***
# Residuals   174 119.44   0.686                     
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


```

#Using the median value by SBS to make predictions for NH4.
```{r}
#Get the median value for each SBS; these are the center line values plotted on the SBS box and whisker plots for NH4.
High_median <- median(geochem_dat_toPlot[which(geochem_dat_toPlot$field_SBS == "High"),]$log10_NH4)
Moderate_median <- median(geochem_dat_toPlot[which(geochem_dat_toPlot$field_SBS == "Moderate"),]$log10_NH4)
Low_median <- median(geochem_dat_toPlot[which(geochem_dat_toPlot$field_SBS == "Low"),]$log10_NH4)
NBC_median <- median(geochem_dat_toPlot[which(geochem_dat_toPlot$field_SBS == "No Burn Control"),]$log10_NH4)

#Assign the computed median value to each sample (dependent upon SBS).
geochem_dat_toPlot$median_log10NH4 <- NA #Starting a new variable that we will populate.
geochem_dat_toPlot[which(geochem_dat_toPlot$field_SBS == "High"),]$median_log10NH4 <- High_median
geochem_dat_toPlot[which(geochem_dat_toPlot$field_SBS == "Moderate"),]$median_log10NH4 <- Moderate_median
geochem_dat_toPlot[which(geochem_dat_toPlot$field_SBS == "Low"),]$median_log10NH4 <- Low_median
geochem_dat_toPlot[which(geochem_dat_toPlot$field_SBS == "No Burn Control"),]$median_log10NH4 <- NBC_median

#Compute the RMSE for median-based predictions.
median_SBS_NH4_RMSE <- sqrt(mean((geochem_dat_toPlot$log10_NH4 - geochem_dat_toPlot$median_log10NH4)^2))

#Plot a prediction vs. observed value plot for NH4 where the prediction for NH4 is based solely upon the median NH4 for each SBS.
NH4_SBS_prediction <- ggplot(geochem_dat_toPlot, aes(x = log10_NH4, y = median_log10NH4)) + 
geom_point(aes(colour = factor(field_SBS))) + #Need to factor the SBS variable so that colors can be assigned to data points. 
scale_colour_manual(values = c("#D55E00", "#F0E442", "#009E73", "#999999")) + #Note that these colors are colorblind-friendly.
theme(axis.text.x = element_text(size = 14),
      axis.text.y = element_text(size = 14),  
      axis.title.x = element_text(size = 14),
      axis.title.y = element_text(size = 14)) +
geom_abline(slope = 1, intercept = 0, colour = "blue") + #A 1:1 reference line for prediction vs. observation.
#xlim(0, NA) + #Allowing default limits by commenting this line.
#ylim(0, NA) + #Allowing default limits by commenting this line.
#coord_fixed(ratio = 1) + #By commenting this line we allow the axes to be on different scales (for this particular plot the presentation is better).
theme(panel.grid.major = element_blank(), 
  panel.grid.minor = element_blank(),
  panel.background = element_blank(), 
  axis.line = element_line(colour = "black"), 
  strip.background = element_blank(), 
  legend.background = element_blank(), 
  legend.key = element_blank(), 
  panel.border = element_rect(color = "black", fill = NA, size = 1)) +
xlab("Observed") +
ylab("Predicted") +
ggtitle(paste("RMSE = ", format(round(median_SBS_NH4_RMSE, 2), nsmall = 2))) +
theme(plot.title = element_text(size = 12, face = "bold"))

```

#End the timing clock for running the entire workbook.
```{r}

full_pipe_end <- Sys.time()

full_pipe_time <- full_pipe_end - full_pipe_start
#Result of the above, as of 6/30/21: Time difference of 53.39205 mins.

```












